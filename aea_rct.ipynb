{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ba26864-3c63-4ad3-a083-04bbc7077ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "304106c6-056b-45a7-841a-d5044e7a47bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data (replace 'data.json' with the actual file path)\n",
    "with open(\"trials.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adcd0439-75d0-487b-b46d-9c0d6fc24e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{\n",
    "    \"RCT_ID\": item.get(\"RCT ID\", None),\n",
    "    \"Title\": item.get(\"Title\", None),\n",
    "    \"Status\": item.get(\"Status\", None),\n",
    "    \"Start_Date\": item.get(\"Start date\", None),\n",
    "    \"End_Date\": item.get(\"End date\", None),\n",
    "    \"Country\": \", \".join([c[\"Country\"] if isinstance(c, dict) else str(c) for c in item.get(\"Countries\", [])]) if \"Countries\" in item else None,\n",
    "    \"Region\": \", \".join([c[\"Region\"] if isinstance(c, dict) and isinstance(c[\"Region\"], str) else str(c[\"Region\"]) if isinstance(c[\"Region\"], list) else \"\" for c in item.get(\"Countries\", [])]) if \"Countries\" in item else None,\n",
    "    \"PI_Name\": item.get(\"Primary PI\", {}).get(\"Name\", None),\n",
    "    \"PI_Affiliation\": item.get(\"Primary PI\", {}).get(\"Affiliation\", None),\n",
    "    \"Keywords\": \", \".join(item.get(\"Keywords\", [])) if item.get(\"Keywords\") else None,\n",
    "    \"Additional_Keywords\": \", \".join(item.get(\"Additional Keywords\", [])) if item.get(\"Additional Keywords\") else None,\n",
    "    \"JEL_Codes\": \", \".join(item.get(\"JEL code(s)\", [])) if item.get(\"JEL code(s)\") else None,\n",
    "    \"Secondary_IDs\": \", \".join(item.get(\"Secondary IDs\", [])) if item.get(\"Secondary IDs\") else None,\n",
    "    \"Abstract\": item.get(\"Abstract\", None),\n",
    "    \"External_Links\": \", \".join(item.get(\"External Link(s)\", {}).get(\"Link\", [])) if isinstance(item.get(\"External Link(s)\"), dict) else None,\n",
    "    \"Citation\": item.get(\"Citation\", None),\n",
    "    \"Former_Citation\": item.get(\"Former Citation\", None),\n",
    "    \"Intervention\": item.get(\"Intervention(s)\", None),\n",
    "    \"Intervention_Hidden\": item.get(\"Intervention (Hidden)\", None),\n",
    "    \"Intervention_Start_Date\": item.get(\"Intervention Start Date\", None),\n",
    "    \"Intervention_End_Date\": item.get(\"Intervention End Date\", None),\n",
    "    \"Primary_Outcomes\": \", \".join(item.get(\"Primary Outcomes (end points)\", [])) if item.get(\"Primary Outcomes (end points)\") else None,\n",
    "    \"Primary_Outcomes_Explanation\": item.get(\"Primary Outcomes (explanation)\", None),\n",
    "    \"Secondary_Outcomes\": \", \".join(item.get(\"Secondary Outcomes (end points)\", [])) if item.get(\"Secondary Outcomes (end points)\") else None,\n",
    "    \"Secondary_Outcomes_Explanation\": item.get(\"Secondary Outcomes (explanation)\", None),\n",
    "    \"Experimental_Design\": item.get(\"Experimental Design\", None),\n",
    "    \"Experimental_Design_Details\": item.get(\"Experimental Design Details\", None),\n",
    "    \"Randomization_Method\": item.get(\"Randomization Method\", None),\n",
    "    \"Randomization_Unit\": item.get(\"Randomization Unit\", None),\n",
    "    \"Treatment_Clustered\": item.get(\"Was the treatment clustered?\", None),\n",
    "    \"Planned_Clusters\": item.get(\"Sample size: planned number of clusters\", None),\n",
    "    \"Planned_Observations\": item.get(\"Sample size: planned number of observations\", None),\n",
    "    \"Sample_By_Treatment_Arms\": item.get(\"Sample size (or number of clusters) by treatment arms\", None),\n",
    "    \"Minimum_Detectable_Effect\": item.get(\"Minimum detectable effect size for main outcomes (accounting for sampledesign and clustering)\", None),\n",
    "    \"Intervention_Completed\": item.get(\"Is the intervention completed?\", None),\n",
    "    \"Data_Collection_Complete\": item.get(\"Data Collection Complete\", None),\n",
    "    \"Public_Data_Available\": item.get(\"Is public data available?\", None),\n",
    "    \"Program_Files\": item.get(\"Program Files\", None)\n",
    "} for item in json_data.values()])\n",
    "\n",
    "# Extract multiple investigators separately\n",
    "df_pis = pd.concat([\n",
    "    pd.DataFrame({\n",
    "        \"RCT_ID\": item.get(\"RCT ID\", None),\n",
    "        \"PI_Name\": [pi.get(\"Name\", None) for pi in item.get(\"Other Primary Investigators\", [])],\n",
    "        \"PI_Affiliation\": [pi.get(\"Affiliation\", None) for pi in item.get(\"Other Primary Investigators\", [])]\n",
    "    }) for item in json_data.values() if \"Other Primary Investigators\" in item\n",
    "], ignore_index=True)\n",
    "\n",
    "# Extract IRB approvals separately\n",
    "df_irbs = pd.concat([\n",
    "    pd.DataFrame({\n",
    "        \"RCT_ID\": item.get(\"RCT ID\", None),\n",
    "        \"IRB_Name\": [irb.get(\"Name\", None) for irb in item.get(\"IRBs\", [])],\n",
    "        \"IRB_Approval_Date\": [irb.get(\"Approval Date\", None) for irb in item.get(\"IRBs\", [])],\n",
    "        \"IRB_Approval_Number\": [irb.get(\"Approval Number\", None) for irb in item.get(\"IRBs\", [])]\n",
    "    }) for item in json_data.values() if \"IRBs\" in item\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eee6099-c06d-4e0f-889b-bcfe057ccff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RCT_ID', 'Title', 'Status', 'Start_Date', 'End_Date', 'Country',\n",
       "       'Region', 'PI_Name', 'PI_Affiliation', 'Keywords',\n",
       "       'Additional_Keywords', 'JEL_Codes', 'Secondary_IDs', 'Abstract',\n",
       "       'External_Links', 'Citation', 'Former_Citation', 'Intervention',\n",
       "       'Intervention_Hidden', 'Intervention_Start_Date',\n",
       "       'Intervention_End_Date', 'Primary_Outcomes',\n",
       "       'Primary_Outcomes_Explanation', 'Secondary_Outcomes',\n",
       "       'Secondary_Outcomes_Explanation', 'Experimental_Design',\n",
       "       'Experimental_Design_Details', 'Randomization_Method',\n",
       "       'Randomization_Unit', 'Treatment_Clustered', 'Planned_Clusters',\n",
       "       'Planned_Observations', 'Sample_By_Treatment_Arms',\n",
       "       'Minimum_Detectable_Effect', 'Intervention_Completed',\n",
       "       'Data_Collection_Complete', 'Public_Data_Available', 'Program_Files'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9657d44c-c8c9-4fbc-a04e-5ef1a9d21e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_single_number(text):\n",
    "    numbers = re.findall(r'\\b\\d{1,3}(?:[, ]\\d{3})*\\b', text)  # Extract numbers formatted with commas or spaces\n",
    "    numbers = [int(num.replace(',', '').replace(' ', '')) for num in numbers]  # Convert to integers\n",
    "\n",
    "    return numbers[0] if len(numbers) == 1 else None  # Return only if there's exactly one number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e8f510-a136-40e9-b475-6fba8fcf32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sample_size'] = [extract_single_number(text) for text in df['Planned_Observations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef85e654-28ce-42b2-be0a-0b09b23d12e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Treatment was randomly assigned at the individ...\n",
       "1    The study is a clustered randomized controlled...\n",
       "2    This is a three group design:\\r-control (98 sc...\n",
       "3    Panchayats in randomly selected blocks will ei...\n",
       "4    We randomly selected 62 villages participating...\n",
       "Name: Experimental_Design, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Experimental_Design'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f9dc70c-cdf7-4148-baf4-854543ddd4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        4676.00\n",
       "mean        34517.91\n",
       "std        961062.49\n",
       "min             1.00\n",
       "25%           300.00\n",
       "50%           686.50\n",
       "75%          3000.00\n",
       "max      50000000.00\n",
       "Name: sample_size, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sample_size'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab9cd5f7-4e34-4b84-a200-c145d8c0002a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "United States of America                                       2014\n",
       "Germany                                                         711\n",
       "India                                                           531\n",
       "China                                                           350\n",
       "United Kingdom of Great Britain and Northern Ireland            281\n",
       "                                                               ... \n",
       "Azerbaijan                                                        1\n",
       "India, Norway                                                     1\n",
       "Germany, Denmark, Estonia, Spain, Finland, Italy, Lithuania       1\n",
       "Serbia, Turkey, Ukraine                                           1\n",
       "Netherlands, United States of America                             1\n",
       "Name: count, Length: 498, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43202cdf-3d36-4539-a896-51b5a91f18dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19                          Approximately 5 million people\n",
       "63                                9 households per village\n",
       "517      4096 individuals. See Section 3 of our (public...\n",
       "619                                                      2\n",
       "650      The total sample size is approximately 3000 wo...\n",
       "                               ...                        \n",
       "9912                                                     1\n",
       "9913            3000 (3 scenario responses by respondent).\n",
       "9934                             7 households per village.\n",
       "9973              10000 observations; 5 rounds per subject\n",
       "10008    13500: 4500 individuals times 3 choice sets each \n",
       "Name: Planned_Observations, Length: 94, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Planned_Observations'][df['sample_size'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed628665-9a3c-4575-bfec-4b3c8de2d224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      N/A\n",
       "1                                24 clusters per study arm\n",
       "2        98 school campuses control, 93 school campuses...\n",
       "3                   69 treatment blocks,127 control blocks\n",
       "4        2821 individuals free DFS,  3224 individuals n...\n",
       "                               ...                        \n",
       "10051    1,900 control, 744 ESG messages, 736 E message...\n",
       "10052                                                    \\\n",
       "10053                                                   76\n",
       "10054    The number of participants for each round is a...\n",
       "10055          750 students per group (treatment, control)\n",
       "Name: Sample_By_Treatment_Arms, Length: 10056, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sample_By_Treatment_Arms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f226a2c4-8fba-4ed1-b01b-c953796f298e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MDE=5% change in perceived leakage, sd=28.8667, power=0.80, alpha=0.05',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.7 g/dL among elderly subgroup',\n",
       " '',\n",
       " '',\n",
       " '0.2 SD, 80%',\n",
       " '0.2 SD, 89%',\n",
       " 'Please see the separate Power Calculations document under Supporting Documents &amp; Materials.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'With alpha = 0.05, within cluster correlation of 0.10, 1 Standard Deviation and 12 control cluster and 24 treatment cluster, our Minimum Detectable Effect Size for Main Outcomes would be 0.396 ',\n",
       " 'For Part II: MDE is 7.7 ppt increase in voting across party lines with alpha 0.05 and power 0.80; Part III: same MDE as in II for T versus C as well as continuous outcome MDE of 0.5 point shift on 10 point likeability scale across T arms',\n",
       " '',\n",
       " '',\n",
       " '1.5 percentage points in voter turnout',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '80% power for all:  Violent Arrests (0.058 arrests, 0.364 SD); Property Arrests (0.043 arrests, 0.266 SD); Drug Arrests (0.091 arrests, 0.570 SD); Other Arrests (0.121 arrests, 0.759 SD); School Engagement Index (0.109 points, 0.683 SD)',\n",
       " 'we can detect an effect of 0.16 standard deviations with 80% power for the main outcomes (employment, income, cortisol)',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '.27 SD for the measure of amount paid to the police for the violation, at 80% power, with an estimated 420 stops for helmet violations and .448 correlation between baseline and followup',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'See pre-analysis plan',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'If we assume perfect compliance with random assignment, we should expect between a 0.26 and a 0.28 effect size.  However, we expect take-up to be around 80% or less.',\n",
       " 'See protocol attached',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Percentage: 80 percent power used for all calculations.  1 Year Enrollment: .022 (2.2 percentage point) difference, SD: .15; Credit hours in year 1: 1.2 credit hours, SD: 7.02; GPA in year 1: .15 GPA points, SD: .91',\n",
       " '',\n",
       " 'not available',\n",
       " 'The study is powered to detect an increase in farm production value of 10% (ITT).',\n",
       " '',\n",
       " 'given preliminary data on available intracluster correlation and likely available nets as of September 2010, the MDE on was estimated to be 7$ in absolute terms. see protocol for details. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'power of 80% (with a 5% confidence interval) ',\n",
       " '',\n",
       " \"MDE's for Monthly Exposure to Improved Equipment:\\r\\n\\r\\nUpper bound: 0.01 std. deviations for Skills Test scores; 0.42% Employment change; 1.7 USD monthly income change\\r\\n\\r\\nLower Bound: 0.0056 Std. deviations for skills test scores; 0.24% Employment change and 0.94 USD monthly income change \",\n",
       " '',\n",
       " 'effect size: 0.15 standard deviations; power: 0.8, size 0.05; baseline to endline correlation: 0.6; intra-cluster correlation: 0.1; 8 firms per cluster.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We design the sample to detect a minimum effect of 33% of one standard deviation (SD) of cognitive development on a child development scale (i.e. Bayley-III) for the home visiting intervention against the control group. The level of significance is fixed at 5%, power is fixed at 80%, and the intra cluster correlation at 0.025. This is based in previous estimates from work done by members of the research team in Colombia (intra-class correlation (conditional on observables) between 0.01 and 0.04, depending on the domain of development as assessed by the Bayley-III) and in the more similar context of Bangladesh (conditional intra-class correlation on Bayley-III cognitive development has been found to be 0.01).\\r\\n\\r\\nSample size requirements are 27 slums per treatment arm (54 total) and 7.5 children per slum on average. We are including 8 children per slum on average to allow for some sample loss between baseline and first follow up. Stratifying the sample by slum size before randomization will also increase statistical power. \\r\\n',\n",
       " '',\n",
       " '',\n",
       " 'With the sample size above: a) Interventions 1 &amp; 2: Effect size: 0.20 of a standard deviation; 80% power; 5% significance ; b)Intervention 3: Effect size: 0.14 of a standard deviation; 80% power; 5% significance',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '15 percentage points in knowledge score, power 0.9, alpha 0.05, intraclass correlation of 0.05, 30 students per cluster.',\n",
       " '',\n",
       " '0.10 standard deviations of test scores',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'MDE of 0.2 s.d. for private-labeling treatment and of 0.3 s.d. for public-labeling treatment',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '23.1 standard deviation (rho=5%, full compliance)',\n",
       " '',\n",
       " '29% of a standard deviation (full compliance, ICC on overal first grade test score 7.4%)',\n",
       " 'Setting the p-value at 0.05 and the power of the test at 80 percent, we should be able to detect an 8.9 percentage point rise in the one-semester persistence rate and a 10.8 percentage point increase in the one-year persistence rate.',\n",
       " '23.1% of a standard deviation (on volunteer, full compliance, ICC absenteism)',\n",
       " 'Detectable effect  - £41,000 increase in turnover. Mean = 106,937, Variance = £377,000',\n",
       " '',\n",
       " '',\n",
       " '20% of a sd full compliance, ICC=10%',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"For a continuous composite score that measures adoption and use of electronic health records systems (see Outcomes section above), the MDE was 9.9 percent of the control group mean.  The MDE assumes a response rate of 85 percent to the Office Systems Survey; an intracluster correlation coefficient of 0.037; a coefficient of variation of 2.2; a significance level of 0.10 for a two-sided test; and 80 percent power; and a regression R-squared of 0.3. \\r\\n\\r\\nFor binary variables, the MDE was 10 percentage points with a mean of 0.5 also assuming a regression R-squared of 0.3.\\r\\n\\r\\nFor both outcomes, the sample size was 267 control group and 314 intervention respondents.\\r\\n\\r\\nThe impacts of the demonstration on practices's use of health IT were generally much larger than the MDEs, suggesting the evaluation was well powered for these outcome measures.\",\n",
       " '',\n",
       " 'Target Effect Size: 15% increase in sales or employment.\\r\\n\\r\\nRequired Sample Size: 291 entrepreneurs per group (T1, T2, C).\\r\\n\\r\\nAssumptions for Power Calculations:\\r\\n80% power\\r\\nα = .05\\r\\nρ = 0.50  (auto-correlation in firm outcomes)\\r\\n1 pre-treatment survey round and 3 post-treatment survey rounds.\\r\\nCoefficient of Variation (CV) of 1.0 \\r\\nEqual Group Sizes, e.g. T1 (n=291) versus T2 (n=291) versus Control (n=291).\\r\\n[Used \"sampsi\" command in Stata for calculations.]\\r\\n',\n",
       " 'Target Effect Size: 15% improvement in Coefficient of Variation or Adjustment Factors.\\r\\n\\r\\nRequired Sample Size: 291 entrepreneurs per group (T, C).\\r\\n\\r\\nAssumptions for Power Calculations:\\r\\n80% power\\r\\nα = .05\\r\\nρ = 0.50  (auto-correlation in firm outcomes)\\r\\n1 pre-treatment survey round and 3 post-treatment survey rounds.\\r\\nCoefficient of Variation (CV) of 1.0 \\r\\nEqual Group Sizes, e.g. Treatment (n=291) versus Control (n=291).\\r\\n[Used \"sampsi\" command in Stata for calculations.]',\n",
       " '',\n",
       " '',\n",
       " 'The sample size was chosen based on extensive power calculations under the assumption that the minimum detectable effect size is .3 of a standard deviation for the agricultural loan. Based on other data available on Mali, we expected that to be a roughly 20% increase in per capita consumption. Under additional assumptions, we had an 85% probably that would detect this effect with a 5% significance level.',\n",
       " 'Our power calculations suggest that we will be able to detect a 1 percentage point difference at a significance level of 5 percent and at 80 percent power for the overall treatment, and 1.5 percentage points for key subgroups.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Savings status is likely to be a highly persistent outcome, so we assume a moderate scenario with an autocorrelation parameter of 0.7: Under this assumption and with 400 treatments and 400 controls, we can achieve power of 0.8 with a treatment effect of 0.132 standard deviations. In a more restrictive setting in which we have only a baseline and endline observation for every worker, we would need a treatment effect of approximately 0.2 standard deviations.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'See pre-analysis plan',\n",
       " '',\n",
       " 'Statistical power is highly contingent on the strength of the first-stage relationship, i.e., the effectiveness of the incentive in inducing students to participate in the program.',\n",
       " \"We use Optimal Design Software for all power calculations. We originally assumed an intra-cluster correlation of 0.1 (that is the intra-cluster correlation for value added) and that 30% of the variation can be explained by baseline test scores and other covariates (such as age, gender, school and teacher characteristics) and district fix effects. \\r\\n\\r\\nOur main outcomes (the effect of capitation grants and cash on delivery) have a total of 280 clusters (140 controls schools and 140 treatment schools - 70 with the pure treatment and 70 with the combination treatment). In other words to estimate the effect of the capitation grant we have 140 control schools and 140 schools that recieve the capitation grant, 70 from Treatment 1 and 70 from Treatment 3. Similarly, we have 140 schools that receive Cash on Delivery. To estimate the interaction between the two main treatments we only have 70 treatment schools (Treatment 3) and 140 controls schools.\\r\\n\\r\\nWith 280 clusters (i.e. to estimate the effect of the Capitation Grant or the Cash on Delivery) and a significance level of 5% we have: minimum detectable effect size  of 0.2 with power of 99.9%,  minimum detectable effect size  of 0.15 with power of 97%, and minimum detectable effect size  of 0.1 with power of 75%.\\r\\n\\r\\nWith 210 clusters (i.e. to estimate the effect of the interaction between the Capitation Grant and Cash on Delivery) and a significance level of 5% we have: minimum detectable effect size  of 0.2 with power of 99.5%,  minimum detectable effect size  of 0.15 with power of 92%, and minimum detectable effect size  of 0.1 with power of 62.5%.\\r\\n\\r\\nWe are aware that the numbers for the interaction assume symmetry and so the true numbers will be slightly lower, but the difference won't be first order.\\r\\n\\r\\nIn practice, based on the first year data, we have that the intra-cluster correlation is 0.15 for Kiswahili, 0.06 for English and 0.14 for Math. The proportion of the variation can be explained by baseline test scores and other covariates (such as age, gender, school and teacher characteristics) and district fix effects. is 40% for Kiswahili, 36% for English and 37% for Math.  Using the most conservative estimates (0.15 intra-cluster correlation and 36% of the variance explained by baseline characteristics) we have the following numbers:\\r\\n\\r\\nWith 280 clusters (i.e. to estimate the effect of the Capitation Grant or the Cash on Delivery) and a significance level of 5% we have: minimum detectable effect size of 0.2 with power of 99%,  minimum detectable effect size of 0.15 with power of 94%, and minimum detectable effect size  of 0.1 with power of 65%.\\r\\n\\r\\nWith 210 clusters (i.e. to estimate the effect of the interaction between the Capitation Grant and Cash on Delivery) and a significance level of 5% we have: minimum detectable effect size  of 0.2 with power of 98.5%,  minimum detectable effect size  of 0.15 with power of 86%, and minimum detectable effect size  of 0.1 with power of 53%.\",\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Sample size was determined to ensure an 80 percent probability of rejecting the null of no effect at the 5 percent significant level, assuming a baseline contraceptive rate of 6 percent (estimated from the 2000 Demographic and Health Survey of Ethiopia), an intra-class correlation of 0.05 and a 12 percentage points difference in contraceptive\\r\\nbehavior between any two of the four experimental arms.',\n",
       " '18.5% standard deviation.',\n",
       " 'Minimum detectable effect size for: \\r\\nAdoption rate of SRI: a 8% increase (from 40 to 48 percent)\\r\\nYields: A 10% increase in yields\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We determined that with 80% power and a test size of 0.05, a sample size of 800 would provide the statistical power to detect a 30% reduction in our primary outcome: 180-day hospital readmission. Compared to the mean 180-day readmission rate of 0.30, this means that we would have the power to detect a drop to 0.21. Although this is a large effect, it is within the set of estimates found in the literature for intensive case management featuring home visits described in the literature review.\\r\\n\\r\\nAnother 180-day outcome where we would have the power to detect a 30% decline is the likelihood of 2 or more “hospital visits”, defined as outpatient ED visits plus inpatient readmissions, which averages 0.32. Other 180-day outcomes where we have the power to detect a 20% change include any hospital visit (an outcome that averages 0.54) and the likelihood of any outpatient ED visit (an average of 0.42).\\r\\n\\r\\nIf we have the power to detect a given percentage change in an outcome at six months, we have the power to detect an effect at twelve months as well (e.g. 365-day readmission). Other outcomes where we have the power to detect a 30% decline over the following 365 days include the number of hospital visits (which averages 2.7) and the likelihood of 3 or more visits (which averages 0.33).\\r\\n\\r\\nAs a result of these power calculations, we plan to recruit until we attain a sample size of 800 subjects. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We expect the following MDIs (percentage points) with an endline sample size of 32 households with children 0-35 months per kecamatan, and 16 households with pregnant women in the second or third trimester per kecematan:\\r\\n\\r\\nStunting (31.0%): 5.2\\r\\nAnemia (38.3%): 7.4\\r\\nDiarrhea in past month (17.2%): 3.7 \\r\\nLow birth weight (7.2%): 1.9\\r\\n\\r\\nLow maternal BMI (11.6%): 3.7\\r\\nAnemia in second and third trimester (46.0%): 5.6\\r\\n\\r\\nBaseline prevalences are shown in parentheses. MDIs are for a two-tailed test with 80 percent power at a 95 percent significance level. Calculations also assume an R2 of 0.05 and a response rate of 95 percent.',\n",
       " '',\n",
       " 'We will have 80% power to detect effects of 9 percentage point increase in course credit earning, assuming 60% of control group earns course credit, using alpha of 5%.  This does not account for possible precision gains from the covariates we intend to include (age, gender, and education level).',\n",
       " '',\n",
       " 'The minimum detectable standardized effect size for this study depends on the value of intra-cluster correlation (rho). We estimate that the value of rho is between 0.05 and 0.2, which corresponds to an MDES of 0.17 to 0.27 with power of 0.9 and significance level of 0.05.  ',\n",
       " '[This may need changing]\\r\\n\\r\\nThe survey sample will be 6,000 surveys across the three treatment groups, with 2000 surveys per arm. \\r\\n\\r\\nWe will have two outcome  variables for which we rely on results from survey data. \\r\\n\\r\\n1. The first is increase in total savings (i.e. bank savings and reported savings in other areas). \\r\\n\\r\\nAt district level (i.e. for a comparison between those who received agents and those who did not) we need to see an increase of S./37.5, assuming a control group mean of S./59.5 and a standard deviation of S/.320.03, power of 80% and intracluster correlation of 0.01. \\r\\n\\r\\nAt village level (i.e. for a comparison of those who received the training intervention on top of the agent intervention and those who received solely the agent intervention), we need to see an increase of S/.36.5 assuming the same means, SD and power as above but with an ICC of 0.02.\\r\\n\\r\\n2. The second is we need to see an increase in the spending on durable goods. \\r\\n\\r\\nAt district level we need to see an increase of S/.61.08 in spending on durables within a year, assuming a control group mean of  S/.272.92, a standard deviation of S/.523.73 and an ICC of 0.01. \\r\\n\\r\\nAt village level we expect to see an effect of S./59.08 when there is an ICC of 0.02, but with SD, power and control group means the same as above. \\r\\n\\r\\nFor budgeting purposes, we assume that only 90% of attempted surveys will be successfully administered, and we will therefore attempt a total of 6,600 surveys. Some 220 per district. ',\n",
       " 'Assumptions:\\r\\n\\r\\nAssume a minimum detectable effect size of .2 standard deviations when standardizing the mean values of the outcome variables of interest.\\r\\n\\r\\nAssume a take-up rate for the invitation to attend the financial education workshops of 90%. This is based on Gibson, McKenzie, and Zia (2012) and Doi, McKenzie, and Zia (2012) who also run financial literacy training workshops for migrants.\\r\\n\\r\\nAssume take-up rates for offered financial products to be 80%. In other words, 80% of study participants use some financial product, whether credit or savings, when offered to them. The assumption is based on a midrange of take-up rates for field experiments that study random provision of credit or savings products.\\r\\n\\r\\nEffect 1: The impact of the financial education workshop (b1)\\r\\nPower = 0.9684  \\r\\n\\r\\nEffect 2: The impact of financial services (b2)\\r\\nPower = 0.9242 \\r\\n\\r\\nEffect 3: The joint impact of financial education and financial services (b3)\\r\\nPower = 0.8508 \\r\\n\\r\\nUltimately, even beyond these power calculations, we are confident that 1800 households is an adequate sample size to detect our main effects, even for our mini-experiment in Singapore and Hong Kong where the financial education treatment group involves training migrants abroad. The study by Doi, McKenzie, and Zia (2012), who look at similar outcomes, had enough power to detect statistically significant effects even with a sample of only 400 migrant households randomized into three treatment groups. According to administrative data by OWWA, 19.7% of migrants departing for abroad from Cabanatuan City went to Singapore and Hong Kong in 2013. Hence, we expect to obtain a similar subsample of around 355 for the mini experiment.',\n",
       " '',\n",
       " 'Cluster-level randomized treatments (the public / private treatment and the learning from others treatment), as well as the individually randomized earmarking treatment, have an MDES of 0.17. The commitment deposit treatment has an MDES of 0.14, and the spillover estimation has an MDES of 0.13.',\n",
       " 'See attached pre-analysis plan.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'My data set is already given, and I have selected my tests in advance, so I cannot manipulate my power unless by including and removing covariates. My regression discontinuity design should provide a balance without matching or controlling for covariates if the design works.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Significance level: 0.05; \\r\\nPower level: 0.8;\\r\\nAverage children per school: 31;\\r\\nNumber of school: 109;\\r\\nMinimum detectable effect: 0.23 standard deviation.',\n",
       " '0.1 s.d.',\n",
       " 'We made the following assumptions: a power of 0.8 and a significance level of 0.05; an intra-cluster correlation of 0.006;* and an average take-up rate of the savings account denominated for emergencies and savings by default of 25% (based on take-up rates of other savings accounts in developing countries**). We consider as outcome variable self-reported savings in BANSEFI by Oportunidades beneficiaries who were given a debit card to manage their transfers. The data comes from INSP (2012). On average, beneficiaries report having MX$12.48 (standard deviation MX$271.67) saved in their accounts. We assume this to be the level of savings for the control group. Under the assumptions above, in order to detect a statistically significant difference of 0.2 standard deviations, considering 59 clusters (15 for the control group and 22 for each treatment group), we would need at least 20 complying households in each cluster.***\\r\\n\\r\\nConsidering the control group and assuming a 15% non-response rate at baseline, the number of households to be surveyed in each control locality is 24 (20/0.85). In addition, assuming a 15% attrition rate between baseline and endline, the number of households to be surveyed in each control locality is 29 (24/0.85 = 28.24 ≈ 29). Now, turning to the treatment groups, following the same reasoning and assuming a take-up rate of 25%, the number of households to be surveyed in each treatment locality is 113 (28.24/0.25 = 112.96 ≈ 113).\\r\\n\\r\\nThus, we will interview 435 beneficiaries in the control group (29*15) and 4,972 in the two treatment groups (113*22*2). Hence, our total sample will be of 5,407 beneficiaries.\\r\\n\\r\\nFootnotes:\\r\\n*    This value was obtained using the loneway command in STATA. The data used are self-reported savings kept in BANSEFI by Oportunidades beneficiaries who were given a debit card to manage their funds. The data comes from INSP (2012).\\r\\n**   Ashraf, Karlan and Yin (2006) find that for the Philippines, 28% of current bank’s clients opened an additional (commitment) account when offered one. Other studies offering a savings account to individuals that had no previous access find higher take up rates (e.g. Dupas and Robinson (2013a) find a 53% take-up rate in Kenya, Prina (2013) fins ad 78% take-up rate in Nepal).\\r\\n*** The number of 59 localities in the study was determined considering the maximum number of localities with a BANSEFI branch within 10 km and with a distance from other localities of at least 3 kilometers.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'As the Targeted Science Education program will be working with the same schools in the metropolitan Lima area as did the 2012 science education pilot, power calculations rely on the 2012 sample. Specifically, we expect that among the 48 participating schools in metropolitan Lima, there will be approximately 1100 students that place in the lowest half of the baseline achievement distribution. Among these 1100 students, half will be randomly assigned to treatment and the other half will be assigned to control conditions. The attrition rate during the 2012 Science Education pilot was 13 percent, and a more conservative 15 percent is used for these power size calculations. A correlation of 0.576 between baseline and end line was calculated, based on the 2012 sample of students. Assuming a five percent level of significance and 80 percent statistical power, the expected minimum detectable treatment effect is (MDE) 0.16 standard deviations. As the randomization will be stratified by school, this reduces the MDE holding all other parameters constant, making this MDE likely a conservative estimate. We find it is reasonable to conduct an empirical study in which the MDE is 0.16 given the results of previous remedial and tracking programs, ranging from .14 to .28 standard deviations.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We have 32 households per village, or 576 households in total',\n",
       " '',\n",
       " '',\n",
       " 'Assuming rho = 0.1, power = 0.8\\r\\n0.16 sd for pooled analysis \\r\\n0.19 sd for heterogeneous analysis\\r\\n\\r\\nAssuming rho = 0.1, power = 0.9\\r\\n0.18 sd for pooled analysis\\r\\n0.22 sd for heterogeneous analysis\\r\\n',\n",
       " 'Minimum detectable effect of main treatment (overall farmer trainer program, irrespective of variations): increase by 21% of a standard deviation on milk production. \\r\\n(Two-sided test at 5% level, with 80% power, and intra-cluster coefficient equal to 0.24)',\n",
       " '',\n",
       " 'Our estimated Minimum Detectable Effect Size is 0.22 standard deviations in literacy test scores.\\r\\n\\r\\nThis assumes a power of 80%, an alpha value of 95%, a cluster size of 28 pupils, a correlation between pre-test and post-test scores of 0.7, and an Intra Class Correlation Coefficient of 0.24.  It is based on a ratio of control-to-treatment groups of 1.5.',\n",
       " '',\n",
       " '',\n",
       " 'see uploaded \"Pre-analysis Plan for Pay by Design Teacher Performance Pay Experiment in Rural China FINAL.docx\"',\n",
       " 'There will be a range, depending on the hypothesis being tested. The most powerful test will involve all 180 sites. Surveying 7 farmers per agent, the test would involve 5,040 observations, yielding minimum detectable size effects around 0.15 at 80% power, given our assumptions on intra-cluster correlation and available covariates. Other tests will be less powerful, however. The least well-powered will rely on comparisons among 30 sites, yielding minimum detectable sizes of around 0.35. ',\n",
       " '',\n",
       " 'Treatment effects identify a behavioral parameter. Using values from Augenblck et al. (2014) a 0.25 standard deviation treatment effect would be recovered with 80% power with a sample size of around 250. ',\n",
       " '',\n",
       " '',\n",
       " 'Optimal design shows that 6200 individuals per treatment will give us power of 0.8 to detect a significant effect at the 5% level.\\r\\nGiven we have a sample of 43,389 we can therefore have 7 arms consisting of 6198 or 6199 individuals. This will give us the power to detect a standardized effect size of 0.05 or roughly a 2 percentage point difference between the arms.\\r\\n',\n",
       " 'Based on our calculations, a 7 arm trial will be powered to detect a rise in tax liability declared of 1% with approximately 1,687,000 observations. This is a very conservative effect size, and could be detected with roughly 4 months of data for this tax type. We will therefore run the trial for 4 months. Power may be reduced due to a lack of strict independence between observations.',\n",
       " 'No baseline data is available for this trial, and Ns were not available prior to launch, making power calculations impractical.',\n",
       " 'This section details the power calculations that we performed to determine the minimum detectable effect sizes for this trial design.\\r\\nWe expect that approximately 36 schools will take part in the trial, with and average of 30 participating students from each school. If this will be the case, 20 schools (600 students) will be randomly assigned to the treatment group and 16 schools (480 students) to the control group.\\r\\nFor conservative estimates of the minimum detectable effect size, we chose a baseline mean for binary and continuous outcomes of 50% - the point at which the baseline variance is at its greatest for first type of outcome. For continuous outcomes, we chose a baseline variance of 0.04 (a standard deviation of 0.2). This is suitable for outcomes such as test scores out of 100, where a standard deviation of 20% about a mean of 50% is conservative.\\r\\nThe table below shows our calculation of the minimum detectable effect size for this trial design for a power of 80%. We also assume a significance level of 5% and an intra-cluster correlation rate of 0.02 (as is standard for trials in schools). This table also includes more and less conservative calculations using intra-cluster correlation rates of 0.025 and 0.015 respectively.\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We assume a two level cluster randomized trial 2-CRT with level 1 being the student and level 2 being the class/teacher and level 3 being the school. \\r\\n\\r\\nThe key parameters are the share of between school variance (rho_S). We have no prior data on which to draw this estimate so we assume conservative range of [0.05 0.2]. \\r\\nWe assume that net recruitment at the school produces 20 parents who sign up for the savings products. \\r\\n\\r\\nWe also assume that baseline data can explain about 30% of the variance of the outcome (we test for sensitivity to this assumption by showing the MDE-sample size locus when there are no covariates).\\r\\n\\r\\nGiven the assumptions above and a total sample size of 120 schools per arm, we have 80% power to distinguish effect sizes as small as 0.105 (at the low end of the ICC) or 0.156 at the high end of the ICC.\\r\\n\\u2003\\r\\nTwo possible scenarios:\\r\\nFirstly that uptake or compliance is considerably lower than the 20 student/families. We revise our cluster size assumptions to 10 students per cluster maintaining the baseline ICC and baseline covariate explanatory power assumptions. \\r\\n\\r\\nOur MDE now has the following range [0.132 0.171].\\r\\n\\r\\nSecondly, if we assume an even more conservative scenario; no baseline covariates and an ICC of 0.4, then our MDE increases to 0.24.\\r\\n',\n",
       " '',\n",
       " 'Our MDES for each study arm, for each round, is 0.30 SDs of the outcome variable. For detecting differences between each cell of the 2x2 cross-randomization, our MDES is 0.43 SDs. Pooling the data across rounds will increase our power (and decrease our MDES); exact calculations will depend on the ICC of the outcome variable in question.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Using the TAPRA data, collected by Tegemeo Institute in 2010, our power calculations suggest the following Minimum Detectable Effects (MDEs): in Western/ Nyanza,  δ_yield∈ (0.5, 0.3) and δ_income∈ (0.4, 0.3), where δ denotes the standardized effect size.* Given the means and standard deviations of yield and income respectively, this translates into MDEs for yields of 15-26% of the average 2010 yield, and 25-35% of the average 2010 household income, depending on the amount of variation in the outcome variables that can be explained by baseline values of covariates.** In Central/Eastern, δ_yield∈ (0.6, 0.45) and δ_income∈ (0.6, 0.45), implying MDEs corresponding to 30-35% increases in yields and incomes. These should be conservative estimates of MDEs, as they are calculated using formulas for a 3-level cluster-randomized trial, while the liquidity treatment arm will be randomized at the individual level.\\r\\n\\r\\n* Using Optimal Design’s notation, the statistics used for power calculations in Western/Nyanza province are as follows: n (the number of households in each village) in each treatment arm is 9 (17 households are sampled in each village, but that number will be halved by the voucher-treatment); J (the number of clusters per site) equals 3, and there are 24 sites, K; the intra-class correlations for level-2 and level-3 in Western are ρ_π=0.083,ρ_β=0.072 (yields) and ρ_π=0.059,ρ_β=0.043 (income). In Central/Eastern, n=17, J=3, K=12, ρ_π=0.085,ρ_β=0.076 (yields) and  ρ_π=0.09,ρ_β=0.07 (income).\\r\\n** In the TAPRA panel data, level-3 covariates from the previous round explain between 15-40% of the variation in current-period outcome variable.',\n",
       " '25% of a standard deviation of student test scores',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.25 standard deviations. ',\n",
       " '',\n",
       " 'Please see detailed pre-analysis plan.',\n",
       " 'Since the extremely high prevalence of stunting in Northern Nigeria is one of the main concerns that the CDGP aims to address, the power calculation detailed below is based on the measurement of changes in child height-for-age z scores (HAZ). They are measured in standard deviations and calculated as follows:\\r\\n\\r\\nHAZ=measured height-median height in reference population for same age and sex/standard deviation of reference population\\r\\n\\r\\nThe reference population used here is the 2006 WHO Multi-Centre Growth Reference Study, which combines observations from a range of different ethnic groups from six countries to construct a universal growth standard. A HAZ of 0 means that the child’s height is normal for their age and sex. According to global convention a score of less than -2 indicates stunting and a score of less than -3 indicates severe stunting.\\r\\n\\r\\nIn order to predict the likely size of the effect that the CDGP may have on HAZ, we conducted a review of other impact evaluations of unconditional and conditional cash transfer programs and nutrition education interventions. Based on existing evidence, we have conducted our power calculations with the aim of detecting a 0.2 SD change in HAZ or children in target households in the three years between baseline and endline. This is the expected change between Treatment Group 1 and the control group. Similarly, we aim to detect a 0.2 SD change in HAZ between Treatment Group 1 and Treatment Group 2.\\r\\n\\r\\nWe have estimated the required sample size per cluster assuming 210 clusters. As we have two treatment groups and one control group, this translates to 70 clusters per treatment type. All calculations are based on a power of 0.8 and significance level of 0.05.\\r\\n\\r\\nWith a MDE of .2, and an assumed ICC of .1 (.05), we require 12(8) pregnant women per cluster to be surveyed. This gives a total of 2520 (1680) pregnant women in total to include in the evaluation.\\r\\n\\r\\nUsing estimates derived from the NDHS for Nigeria (2008) we expect to be able to find such numbers of pregnant women at baseline in the surveyed states.\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       " 'Malawi:\\r\\nWe will sample 13 individuals in 120 farmer groups registered with NASFAM in the Ntchisi and Dowa districts, yielding a total sample size of 1,560 individuals. Farmer groups range in size from 10 to 15, with an average size of approximately 13. The intraclass correlation coefficient varies considerably depending on the outcome of interest one is using. Using IHS 2010/11 data this ranges from 0.04 (amount of acreage dedicated to maize) to 0.24 (number of different crops). For agricultural productivity measures with a reasonably low correlation coefficient we will be able to detect reasonable effect sizes even in this pilot study that will help determine which interventions to focus on in future larger scale interventions. For all power calculations we assume a correlation coefficient of 0.05, power of 0.8, and a 5 percent significance level. For the intensive extension service treatments we are able to detect a standardized effect size of 0.18; for the production transfer modality treatments we are able to detect a standardized effect size of 0.22. We do not anticipate that take-up will be low given that the benefits to the farmers are substantial. Assuming compliance of 90 percent, the estimated standardized effect size is 0.28. \\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'A priori we conducted a power calculation assuming an intra-cluster correlation coefficient of 0.1 and an average school size of 83, which suggested that 48 schools would give 80% power to detect a 0.3 difference in outcomes using a two-tailed test at α=0.05.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The probabilities of assignment to each group varied locally so as to maximize the statistical power of the evaluation while complying with the quantitative objectives of each program (each local area had targets in terms of recipients of the two programs). This often implied very high probabilities of assignment to the private program (up to 85 percent), and much lower probabilities of assignment to the public program (down to 6 percent) and control (down to 9 percent).',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'A.\\tPower calculation: Power to Detect Differences in Take-up\\r\\nIn these power calculations, we first focus on power to detect differences between a treatment arm and the control schools (where we expect zero take-up). We calculate a minimum detectable effect (MDE) of 2.19 mg/kg for zinc and 25.13 mcg/100g for vitamin A. These calculations assume an intra-cluster correlation of 0.2 and a standard deviation of 6.18 mg/kg for zinc and 70.91 mcg/100g for vitamin A. We estimated these standard deviations by collecting 2 food samples each from 4 schools, fortifying one of each pair with the mix and sending all 8 samples for laboratory testing. This exercise also gave us a sense of the difference in the amount of zinc and vitamin A we should expect between a fortified meal and an unfortified meal: The mean difference in nutrient content between the fortified samples and the non-fortified samples was 61.14 mg/kg for zinc and 219.43 mcg/100g for vitamin A, 95% and 46% of the amount of each nutrient in the mix. However, we have since changed the mix due to pressure from the government; with the new mix, we expect an effect of approximately 37 mg/kg for zinc and 107 mcg/100g for vitamin A, respectively. With 100% take-up, the MDE is still substantially below the expected effect size. In fact, we would be able to detect a significant difference in zinc content even if take-up was as low as 6% and in vitamin A content if take-up was as low as 24%. Based on our previous experience with the schools during the pilot, we expect much higher levels of take-up.\\r\\n\\r\\nWe next test whether we have sufficient power to detect differences between multiple treatment arms. Here we assumed a higher standard deviation based on our pilot test results. With this higher variation, we should be able to detect a 4.35 mg/kg difference in zinc content and 50.25 mcg/100g in vitamin A if the difference in take-up was 100%. This large difference in take-up is unlikely, but we should still be able to detect a difference as long as the difference in take-up is higher than 12 percentage points for zinc and 47 percentage points for vitamin A.\\r\\n\\r\\nB.\\tPower to Detect Differences in Haemoglobin\\r\\nWe next turn to our ability to detect differences in haemoglobin. With a sample size of approximately 14 students per school surveyed, our MDE (Intention to Treat) is approximately 0.20 g/dL. Even with a take-up rate of 50% (during our pilot interventions we experienced even higher take-up rates), we can detect an effect (Treatment on the Treated) of 0.40 g/dL. Due to financing constraints, we may have to reduce our endline sample to 10.5 surveyed students per school; in this event, our MDE (Intention to Treat) will be approximately 0.22 g/dL. Even with a take-up rate of 50%, we will be able to detect an effect (Treatment on the Treated) of 0.44 g/dL. We compared our MDE to expected effect sizes we drew from the literature, specifically, from two studies that looked at the impact of providing a micronutrient mix that did not contain iron (Fawzi et al. 2007 and Mehta et al. 2011). The mean effect size across the two studies was 0.62 g/dL, higher than our MDE estimates.\\r\\n',\n",
       " 'In pilot data, in the treatment group where the insurance is offered with upfront premium payment at an actuarially fair value, the take-up is around 10 percent (s.d. 0.35). With sample size of 200 plots per group (upfront actuarially fair vs. deduction payment vs. upfront discounted), we have a minimum detectable effect of around 10 percentage points. Note that these calculations do not take into account field fixed effects and therefore, as long as field have predictive power, are likely to be conservative\\r\\n\\r\\nAt the time of registering the first version of this trial, we do not have reliable data on the power of the regressions by baseline covariates. This will depend on i) the distribution of the covariates in the population of interest; ii) the impact of the covariate in the cash group. We will report power calculations for these heterogeneous effects in an appendix and will only report the heterogeneities for which we have power in the main paper. The rest will be reported in the appendix.',\n",
       " '',\n",
       " \"With 400 businesses recruited, it will be possible to detect an additional impact of 9 percentage points on treated firms' turnover 3 years after the firms complete the support.\",\n",
       " '',\n",
       " 'NA',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Based on data from the first two factories in which the intervention started, on average, efficiency on the first day a line produces a style is increased by 7 percentage points if another line has already produced the garment before. I assume an effect of an additional 3 percentage points due to our intervention. Standard deviation of first-day efficiency is 20 percentage points. I assume per cluster on average 20 observations of a garment being started for the first time on that line (or floor). Based again on the first two factories, I calculate an intra-cluster correlation of 0.075. To detect an effect of a size of 3 additional percentage points on a significance level of 5%, I therefore need at least 227 clusters.  ',\n",
       " 'First randomization (e-mails)\\r\\nAccidentability rate: 0,71%\\r\\nPercentage: 12,95%\\r\\nCompleting training courses: 1,74%\\r\\nPercentage: 26,33%\\r\\nLegal plan accomplishment:1,72%\\r\\nPercentage: 2,35%\\r\\n\\r\\nSecond randomization (printed material)\\r\\nAccidentability rate: 0,65%\\r\\nPercentage: 11,88%\\r\\nCompleting training courses: 1,59%\\r\\nPercentage: 24,16%\\r\\nLegal plan accomplishment:1,58%\\r\\nPercentage: 2,15%',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The standardized minimum detactable effect is 0.3. See the full pdf document for details.',\n",
       " 'Based on budgetary restrictions, we calculated we can afford to include 80 clusters (urban locations) in the sample. These were split into \\u200b\\u200b2 treatment groups of 27 clusters each and 1 control group of 26 clusters.  Using sumstats \\u200b (mean, standard deviations and intracluster correlations)\\u200b from DHS 2008 for \\u200bthe project states \\u200b\\u200b, we selected several measures of\\u200b:\\u200b \\u200b\\u200b\\r\\n\\r\\n\\u200b\\u200b- prevalence of STDs \\u200b: used condom during last intercourse, has ever been tested for AIDs, has had an STD in past 12 months and\\r\\n- domestic violence: spouse pushed, shook or threw something at you, spouse has slapped you, spouse threatened with knife, gun or weapon\\r\\n\\u200b\\r\\nWe set power at 80% and the significance level at 5%, and performed two-sided tests.  Assuming different cluster sizes and an equal division of males and females within each cluster, we computed the minimum detectable effect (MDE) of (1) being treated (any treatment) and (2) of being in a specific treatment group. Taking into consideration budget limitations and the need to maximize MDE, we concluded that the optimal cluster size would be 63. This results in an MDE of 0.2 standard deviations for all selected measures (0.15 for some), and allows us to examine heterogeneous effects by gender.',\n",
       " '',\n",
       " 'The sample size was powered to detect changes in pregnancy rate, which is the most demanding variable to measure and therefore serves as a conservative estimate for the other variables of interest. \\r\\n\\r\\nWe do not presently have pregnancy rates broken down by school (which is the relevant cluster unit), but data from the DHS 2010 combined with our qualitative insights from discussions with local partners indicate that pregnancy rates among past students from Form IV should be between 15% and 35% one year after the completion of Form IV. Taking into account the effect of clustering and the fact that we have three different treatment groups in addition to a control group, we have with the planned sample a power of 80% (with a 5% confidence interval) to detect a decrease in pregnancy rate from 25% to 20% (using the approach of Hayes and Moulton, 2009). \\r\\n',\n",
       " 'The sample size of 3,600 firms has been calculated to meet two goals: \\r\\n• High statistical power to detect small changes in formalization rates;\\r\\n• Sufficient statistical power to analyze the effect of being formal on firm performances, assuming that the program has an effect on formalization (i.e., formal businesses increase at least by 25 percentage point).\\r\\n\\r\\nAssuming that at most 10% of the businesses in the control group formalize during the study period, a sample size of 1,000 in each treatment group would give us a power of 91.3% to detect a 5 percentage point increase in the formalization rate. Our target is a 25 percentage point increase in formalization, in order to get sufficient take-up of formality and examine impacts of being formal on other firm outcomes.\\r\\n\\r\\nIt would also yield the same power to detect a 5 percentage point increase in the proportion of firms paying taxes or receiving a bank loan. To examine power for continuous outcomes like firm profitability, or amount of sales, we use the data collected during the listing/baseline survey. In this data, standard deviations of both profits and sales are equal to the mean. It means that if the treatment leads to a 25 percentage point increase in the formalization rate, with a baseline and two rounds of follow-up data, using ANCOVA, we will have 81.2% power to detect a 36% increase in firm profits from formalizing. \\r\\n\\r\\nThe above power calculations assume a 100% take up rate and no attrition, but these assumptions may be unrealistic given the context. However, program take-up is likely to be very high because the organization in charge of the program is likely to be able to get in touch with most of the informal businesses to deliver the different treatments. If we expect to reach 95% of informal businesses with our intervention (the “take up-rate”), then we would need a sample of 1,108 in order to detect a 5 percentage points increase in formalization rates [1/(0.95)^2)*1000].\\r\\n\\r\\nIn addition, we may “lose” part of the sample due to attrition (i.e. businesses that we cannot survey during the follow-up surveys). We think that we will be able to keep the attrition rate below 10% (since we are only targeting businesses with a fixed location it seems a realistic assumption). \\r\\n\\r\\nWith 10% attrition and a take-up rate of 95%, we get our sample size of 1,200 informal businesses in each of the three groups, two treatment groups and one control (and one treatment group further split in two sets of 300 and 900 businesses), for a total number of 3,600 informal businesses.\\r\\n',\n",
       " 'The minimum effect size of interest in this study is 3%. The current systems indicate that 14% of people fail to turn up to their appointments. G*power has been used to calculate minimum required effect sizes.\\r\\n\\r\\nTo test whether or not the message received has had an impact on attendance, a chi squared text shall be used with 7 degrees of freedom. This will be able to find a very small effect (w&gt;0.52). \\r\\n\\r\\nIf this test is significant, 7 logistic regression shall be used. This method shall be used instead of a bonferroni correction, which is deemed too conservative. This shall test whether or not any of the message variants perform better than the control message. These tests will each include roughly 2000 observations (1000 from treatment variant n and 1000 from the control) and will be able to find an odds ratio of 1.24, based on analysis from g*power with alpha=0.05 and beta= 0.05. If beta is increased to 0.2, then the study will be powered to find an odds ratio of 1.17. These effect sizes are smaller than the minimum effect size of interest.\\r\\n\\r\\nReferences\\r\\n\\r\\nFaul, F., Erdfelder, E., Lang, A. G., &amp; Buchner, A. (2007). G* Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behavior research methods, 39(2), 175-191.',\n",
       " 'Because the randomization takes places a the individual level, we will apply the list experiment with the sensitive question to 500 women and the rest will answer the shorter list and the DHS-style questions about violence. This guarantees a MDE of 25% of a standard deviation with a power of 80%.',\n",
       " 'The target group of this study is children who are initially in the age group of 8-14 years, following the requirements of the MBF program. To calculate the sample size we assume that 60 children (two MBF intervention sessions of size 35 each, 5 children are lost to follow up per session) are enrolled from each treatment village. After analysing various child outcomes such as educational attainment, school enrolment, and test scores from secondary data sources, our final sample size is calculated on the basis of India Human Development Survey (2004-05) mathematics test scores. Assuming an intracluster correlation coefficient of 0.10, in order to detect a 15% difference of maths scores (effect size = 0.21) between treatment and control group children (Duflo et. al 2008 show that average effect sizes in educational outcomes/test scores tend to vary between 0.22 and 0.65), we need roughly 40 villages per group per district, based on a two-sided test having 5% level of significance and 80% power.\\r\\nAt baseline, a random sample of 200 eligible children (or all children if there are less than 200) in each treatment village, and a random sample of 70 eligible children in each control village will be surveyed. A larger sample is purposely targeted in treatment villages during baseline to estimate the determinants of enrolment in the program later. Then, following their standard operational procedure, MBF will spend two months in each treatment village advertising and encouraging parents to ask their children (and directly children too) to enrol in the 3 year sports-based program. Thereafter, eligible children in treatment villages are expected to self-select into the program. During the enrolment period, no eligible child will be denied participation. However, once enough children are enrolled, there will be no new enrolees during the subsequent 3 years, during which the program will meet weekly with enrolled children. \\r\\nOur sample size calculations assume a 15% attrition rate. Consequently, our follow up survey rounds will therefore cover approximately 60 enrolled children in each treatment and 60 children from each control village. To evaluate program spillover effects of the program on eligible children in treatment villages who do not participate in the program, in addition to the 70 enrolled children (reduced to 60 later because of attrition), we would survey 60 randomly selected, non-enrolled, eligible children in each treatment village during subsequent survey rounds. Therefore, each follow-up survey round will cover on average 120 children (60 enrolled + 60 non-enrolled) in each treatment village and 60 children in each control village.\\r\\n',\n",
       " '',\n",
       " 'Role Model: assuming a 80% power, an ICC of 0,05, attrition rate of 10%, a compliance rate with the treatment assigned of 95% and a correlation between base line and follow-up of 0,5 , the power estimations reveal that the available sample allows us to detect with enough statistic confidence a minimum detectable effect (MDE) of 0,267 standard deviations. \\r\\nTechnical assistance: assuming a power of 80%, an ICC of 0,05; attrition rate of 10% and a compliance rate with the treatment assigned of 90%, the power estimations reveal that the available sample allows us to detect with enough statistic confidence a minimum detectable effect (MDE) of 0,206 standard deviations. \\r\\n',\n",
       " 'We constructed a sample of outlier prescribers that replicated the method used in the study but was built from a more limited dataset. Using these prescribers we estimated that at a significance level of 5% and a power of 80%, we could detect a change in the number of schedule II prescription drug events of 136.9 (baseline mean level: 1,556.7; standard deviation: 1,231.2; effect as a share of baseline mean: 8.8%) and a change in the dollar value of schedule II prescriptions of $34,069 (baseline mean level: $217,204; standard deviation: $239,759; effect as a share of baseline mean: 15.7%).\\r\\n\\r\\nSince we will have access to richer data with better control variables, we believe that these estimates are conservative.',\n",
       " 'The proposed study details with a single industry, and collects very detailed data at a monthly frequency. These two features help to ensure we have sufficient power to detect meaningful treatment effects of interest. In particular, we have more than 5 times the number of firms in each treatment group as was the case in the Bloom et al. (2013) study, which was still able to detect significant impacts.\\r\\nFirst consider our power to detect a change in management practices. During the diagnostic phase, the index collected by CNP of all management practices has a mean of 0.46 (out of 1) and standard deviation of 0.10.  Even without any controls we would still have 80 percent power to detect a change of approximately 5.5 percentage points in the proportion of desirable management practices that are implemented – and power to detect even smaller impacts once additional controls are used. Given the intensity of the intervention and the evidence from India, we expect at least this much of a change in management practices.\\r\\nSecond, consider our power to detect an increase in productivity. Labor productivity at baseline has a mean of 30.76 and standard deviation of 18.29. Labor productivity here is annual sales (in millions of Colombian pesos) per employee, so 30.76 indicates sales per worker of approx..US$14,600. We will have this data at a monthly level, with 12 months pre-intervention, and 12 months post-intervention. Assuming an autocorrelation of 0.5 then gives us power of 95.1 percent to detect a 10% increase in productivity, again without taking into account power gains from the random assignment within matched triplets. This allows us to detect an effect smaller than the size measured in Bloom et al. (2013), whilst allowing room for attrition to potentially reduce the sample slightly. Taken together we view these calculations as indicating we have sufficient power to detect meaningful treatment effects of interest.\\r\\n',\n",
       " 'Background: In our preliminary research for this project in September 2013, we worked with the MOLISA Labor Safety officials to estimate the number of firms that would be affected by the new hazardous chemical storage regulation and the share of firms complying with the current version of the regulation, which is considered to be outdated.  MOLISA has yet to complete its pre-regulation study, so the numbers they gave us our ballpark estimates.  According to their current inspection records, only 8% of affected firms are complying with the existing regulations.  MOLISA did not have a population size of affected firms, but did provide us with a list of the industrial sectors that would be covered by the new chemical storage regulation, including a wide range of industries from chemical producers to paint manufacturers to garment companies.  Using this list, we matched these sectors to the list of registered firms in the Hanoi metropolitan area from the National Tax Authority database.  This matching exercise produced 5,200 operations that would be affected by new chemical storage guidelines.   The Tax Authority list also includes information on size (annual revenue), four digit ISIC code, and gender of the business owner/manager.   This sample frame is preliminary, because the sectors of affected firms may shift after the final pre-regulation study is completed.\\r\\n\\r\\nKey Assumptions: \\r\\n1. Current compliance rates are extremely low (8%), implying that variation in compliance is also quite low and the expected effect size of each additional treatment will be reasonably large (after all, we are measuring growth from a near zero level).  \\r\\n\\r\\n2. To keep the power calculations tractable, we conceptualize the empirical analysis as three separate tests:  H1 (Information) = T1&gt;C; H2 (Participation)= T2&gt;T1; H3 (Legitimacy)= T3&gt;T2.  \\r\\n\\r\\n3. We calculate our estimated treatment effects based on two sources: 1) theoretical literature on the participation-compliance relationship; and 2) observational data from the Vietnam Provincial Competitiveness Index survey on current levels of compliance with labor laws.  From these, we expect the effect size for T1 to be about .22 standard deviations (or a 6 percentage point change in the level of compliance).  Conservatively, we estimate the effect size of participation (T2) to be about the same (6 points).  Based on the theoretical literature, we estimate the effect size of legitimacy to be twice that of information alone (.44 standard deviations or 12 percentage points). \\r\\n\\r\\n4. Further, using observational data from we estimate that explained variation from our three blocking variables (size, narrow sector, and gender) to be about 10%.\\r\\nCalculation: Using the Optimal Design software to measure effects with 5% statistical significance and with 80% power, we calculate that we would need about 522 observations in the sample.  To account for potential non-response and to provide some cushion, we conservatively estimate 600 observations for both the control group and T1 (See Figure 1).  Repeating this exercise for the T2, we employ the same estimated treatment effect, requiring 300 additional observations (we used 400).  For H3, the legitimacy treatment, the larger effect size means that we require only 133 observations to reach 80% power (See Figure 2).  To be conservative, maintain simplicity, and to allow room for a study of heterogeneous effects with the blocking variables, we maintained the same 600 observations as \\r\\n',\n",
       " '',\n",
       " '',\n",
       " 'Sample size will be calculated using Epi Info® version 6.0, setting the type- I error (α) at 0.05 and the power (1- β) at 0.8, data from previous studies. According to these values and at 95% confidence interval, a minimal sample size of 40 patients was accepted to reach statistically accepted figure. Therefore, a total number of 50 patients for each group will be recruited in this study. ',\n",
       " 'The Minimum Detectable Effect Size for the number of new hormonal contraceptive clients (main outcome) is 0.19 standard deviations based on alpha=0.05 and power=80%.',\n",
       " 'To calculate the minimum detectable effect size (MDES), we used standard assumptions, including a statistical significance level of 0.05 and statistical power of 0.80. In prior unpublished work with SFUSD four year olds, we found that sites explain approximately 35 percent of the variation in spring test scores. We used this figure in our MDES estimation, and we also assumed that our robust set of pre-treatment covariates explains another 15 percent of the variation in outcomes. Based on these assumptions and our sample of 440 parents across 31 sites, we estimate that we can detect effects of approximately 0.20 standard deviations. \\r\\n',\n",
       " '',\n",
       " '',\n",
       " 'Given our chosen sample sizes (N = 400 subjects for each of our experimental conditions), our experiment is sufficiently powered to detect meaningful effect sizes with statistical precision. In particular, power calculations (Pearson’s chi-squared test of difference in proportions) indicate that our experiment will be able to detect a difference of 9.8 percentage points between treatment group and control group, assuming the following: (a) alpha = 0.05, (b) power = 0.8, and (c) proportion in favor of organ payments in the control group = 50 percent. Because we regard smaller differences as not being of academic or practical importance, we consider the minimal detectable effect reported above as being satisfactory.',\n",
       " '',\n",
       " '',\n",
       " 'As an initial test of program impacts of the program, we will compare pre- and post-test results for tests given to the students who participated in the program as follows:  \\r\\nSi,t - Si,t+1 = α + βT + γXi + δR + εi\\t\\t\\t\\t\\t(1)\\r\\nwhere i refers to an individual, S is the score of the test delivered before the program (time t) and after the program (time t+1), T is a matrix of dummy variables for which treatment an individual belonged to, X is a matrix of individual controls, R is a matrix of region and school dummies, and ε is the error term. This estimation will test for the changes in knowledge of hard and soft skills. \\r\\nTo test the differential effects of each program on the hypotheses presented in Section 4 and Table 2, we will run the following intention to treat (ITT) regression model:\\r\\nYi = α + βT + γXi + δR + εi\\t\\t\\t\\t\\t\\t(2)\\r\\nwhere i refers to an individual, Y is the outcome of interest, T is a matrix of dummy variables for which treatment an individual belonged to, X is a matrix of individual controls, R is a matrix of region and school dummies, and ε is the error term. The standard errors will be clustered at the school of origin level. \\r\\nIn addition to the outcomes in Equation 2, we will also explore the effect of a number of heterogeneities as discussed in Section 4 and Table 2. This will be done using the following regression model:\\r\\nYi = α + βT + λT*H + ωH + γXi + δR + εi\\t\\t\\t\\t(3)\\r\\nwhich includes the addition of the interaction term H, which is the heterogeneity of interest. H will be represented as a dummy variable and will also be included as a control in the regression. Again, standard errors will be clustered at the school of origin level.\\r\\nA final analysis will focus on social network effects. Students were randomly placed into classrooms with other students. The interactions that likely occurred within the classrooms could affect what is commonly referred to as the strong and weak ties of individuals. To test for this, a social network analysis approach will be used. This analysis will include individual and similarity tests. The individual test will use the following regression model:\\r\\nYi = α + βT + γXi + δR + φX-i + εi\\t\\t\\t\\t\\t(4)\\r\\nThe difference between this test and Equation 2 is that the characteristics of the other students in the class, X-i, have been included. These characteristics will allow for a test of the role of other student characteristics in outcomes for student i. \\r\\nFollowing Fafchamps and Soderbom (forthcoming), we will also look at the difference between student i and the other students in the same classroom though a distance measure as follows:\\r\\n|Yi – Ŷ-i|= α + βT + γXi + δR + εi\\t\\t\\t\\t\\t(5)\\r\\nwhere Ŷ-i  is the average outcome of all other students in the class of student i. This will test for whether there is an increase or decrease in outcome differences between those in the same classrooms. \\r\\n',\n",
       " '',\n",
       " 'There is no clustering in the assignment of treatment. We have 80% power to detect a 50% reduction in annual accident rates (based on 2009/10 insurance claims data) between the main message groups and the control group.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The schedule of minimum detectable effect size (MDES) vs Power and MDES vs Intracluster correlation using Optimal Design for continuous variables is in Figure 8. Assuming 12 individuals per cluster and a 5% significance level, the MDES for standard power ranges between 0.8 and 0.85 are between 0.15 and 0.2 SDs.  Similarly, the design is robust to a range of large intra-cluster correlation values (Figure 9) as a result of the large number of independent clusters we built into the design. \\r\\n\\r\\nWe also have power for binary outcomes. For example, diarrhea incidence last week in our baseline survey was 19%. Assuming a power of 0.9, significance of 0.05, we find a MDES of 4 percentage points (a reduction to 15% prevalence) for our sample size.  \\r\\n\\r\\n',\n",
       " '',\n",
       " 'See documents.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We assumed that we would seek to detect a change in probability of compliance from 0.5 to 0.7. For an alpha level of 0.05, power of 0.8, an intracluster correlation of 0.05, we required 144 cases per arm and an average cluster size of 9. ',\n",
       " 'As this is a proof-of-concept study to assess the feasibility of implementing a complex intervention (i.e. a system for distribution of vouchers for sachet water), the numbers of households above are not based on a power calculation.  ',\n",
       " 'Sample size was calculated using Epi Info® version 6.0, setting the type- I error (α) at 0.05 and the power (1- β) at 0.8, data from previous studies (5-7). According to these values and at 95% confidence interval, a minimal sample size of 60 patients was accepted to reach statistically accepted figure. Therefore, a total number of 76 patients were recruited in this study.',\n",
       " '15% increase in self reported drinking (0.310 st dev)',\n",
       " '0.75 day shift in patient adherence (per 2 weeks of treatment). 0.41 st deviations',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Analysis of past data indicates that if letters are sent out for approximately 6 months, this will allow us to detect a 6.3% reduction in re-attendance rates (i.e. a reduction in re-attendance rates from 25.9% to 24.3%). \\r\\n\\r\\nThe power calculations were based on data from April 2013 to March 2014, including all adult A&amp;E Attendances that could potentially have been seen in Primary Care, or who may not have needed to come to A&amp;E (as determined by the code ‘No Investigation No Significant  Treatment’). In this data set there are a total of 42,657 attendances. Out of these, 30,720 are first attendances and 11,937 are re-attendances. Around 25.9% of avoidable first attendances are followed by a further avoidable attendance. The calculations are run for a size of test of 5% and a power of 80%. Two trial arms are assumed (one treatment, one control). \\r\\n\\r\\n\\r\\n',\n",
       " 'In the pilot study, we observed effects of roughly 0.2 standard deviations (sd) for experimental game outcomes from a simple information provision treatment. To conduct power calculations for the full study, we take this effect size as the benchmark for the low-intensity treatment; as we increase the treatment intensity, we expect stronger effects (0.25 sd for the medium-intensity and 0.4 sd for high-intensity treatments). Based on these assumptions, power calculations reveal that we will require a total of 2,100 respondents, with 500 respondents for the low-intensity treatment, 450 for the medium-intensity treatment, and 500 for the high-intensity treatment (assuming 50 percent take up, though we expect it to be higher), and 650 respondents in the control group. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"Using Bloom's (2005) expression for the MDE, our estimate of the intracluster correlation from baseline data of 0.067, and an estimate of an average of 75 observations per bureaucrat, we estimate that a sample of 572 bureaucrats, or 42,882 observations, will allow us to detect a 5% effect with 95% probability.\",\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'To detect an increase in retention rate from 0.6 to 0.7 at 80% power and 5% significance, we will need 125 clusters and a minimum of 9 midwives per cluster under the assumption that the intra-cluster correlation is 0.1.',\n",
       " 'MDE (A versus CONTROL):\\r\\nMinimum detectable effect size in ETB: 871.69 Birr,\\r\\nMDE/Std.dev. in percent: 22,55 percent,\\r\\nMDE/mean in percent: 29,60 percent;\\r\\n\\r\\n\\r\\nMDE (B versus CONTROL): \\r\\nMinimum detectable effect size in ETB: 871.69 Birr,\\r\\nMDE/Std.dev. in percent: 22,55 percent,\\r\\nMDE/mean in percent: 29,60 percent;\\r\\n\\r\\n\\r\\nMDE (C versus CONTROL): \\r\\nMinimum detectable effect size in ETB: 1062.42 Birr,\\r\\nMDE/Std.dev. in percent: 27,48 percent,\\r\\nMDE/mean in percent: 36,08 percent.\\r\\n',\n",
       " 'We use the method of Blitstein et al. to calculate power and sample size for the cluster randomized trial. Our cluster-randomized trial is powered for a head-to-head comparison of the four arms of the trial. All calculations use the Bonferonni correction to account for the six possible comparisons between all pairs of arms; we derived the expected intracluster correlation coefficient parameter (0.02) from our existing data from the most recent campaign in Mariano Melgar district. We selected our sample size based on the lower bound of participation. The power of our trial depends on the participation achieved under the alternative arms. We are powered at 88.5% to detect an increase of 11% over the level of participation achieved in a previously treated district (66%); anything less would not justify the effort and costs of the interventions.  ',\n",
       " '',\n",
       " 'The sample size calculation is bound by the assumption that 80 points is the average gain in the NAPLAN Reading score over 2 years, therefore around 40 is the average gain in the Reading score over 1 year. For this study we aim to find a difference between the intervention and control groups in the Reading score of 0.3 SDs (22.47 points). An effect sizes of 0.3 SDs can be meaningful at a population level given the reach. In this trial in particular it is an approximate 6 month difference in progress and would represent a “clinically” significant difference in outcomes. \\r\\n\\r\\nRandomisation of 561 children per arm is required to provide 90% power to detect a minimum difference of 0.3 standard deviations on the NAPLAN ‘Reading’ scores at grade 3, allowing for an average intra-class correlation coefficient of 0.08 and an average cluster size of 17. To allow for a potential attrition rate of 20% of children by the time children are in grade 3, 700 children per arm (1400 in total) will be required in the study. This sample size also allows for a retention rate of 8% of clusters.  \\r\\n',\n",
       " '',\n",
       " 'TBD',\n",
       " 'See pre-analysis plan',\n",
       " 'Assuming 80 percent power, 5 percent size, and an intra-village correlation in outcomes of 0.15 or less, our design permits a 0.2 or better minimum detectable effect size for outcomes measured at the individual level.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"MDE's for Monthly Exposure to Improved Equipment:\\r\\n\\r\\nUpper bound: 0.01 std. deviations for Skills Test scores; 0.42% Employment change; 1.7 USD monthly income change\\r\\n\\r\\nLower Bound: 0.0056 Std. deviations for skills test scores; 0.24% Employment change and 0.94 USD monthly income change \",\n",
       " '',\n",
       " '',\n",
       " \"We are finalizing this calculation because we still don't know how the sample will divide in terms of larger and smaller educational communities and we have very little information on likely intra-class correlation coefficients. At this point, we anticipate being able to detect impacts of approximately MDI = 6.2 points on a grade 2 Spanish comprehension test with standard deviation of 38.8, or MDE = 0.16. If the mean score on this test is 60, then this would be an MDI of just over 10%.\",\n",
       " '',\n",
       " '',\n",
       " 'See analysis plan.',\n",
       " 'MDE (OSH versus CONTROL), Outcome Variable: Business profits (Soure: Indonesia Family Life Survey 2007), Minimum detectable effect size: 0.2925 M Rupiah, MDE/Std.dev. in percent: 22,55 percent, MDE/mean in percent: 25,52 percent\\r\\n\\r\\n\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'With an expected 40% participation rate and 10% attrition by the time of the endline survey, our goal is to detect an ITT impact of the program of at least 0.12 SD on different indicators of parental beliefs and practices, and child development. ',\n",
       " '',\n",
       " 'Assuming a sample size of 600 (with half the households in the treatment group and half in the control), α = 0.05 and power = 0.8, and given that we can explain roughly 60% of the variation in households’ water usage in any given year with the previous year’s usage, the estimated minimum detectable effect is 0.145 standard deviations.',\n",
       " '',\n",
       " 'Our calculations suggest that we will be able to detect relatively small effects. Using the number of clients who requested assistance in 2013-14 (5,932) and with equal assignment between the three experimental conditions, we are able to detect an impact of the training on monthly energy usage as small as 2.5%. In the unlikely scenario of only 25% compliance to treatment, the minimum detectable effect is 10%, keeping us confident that we will have a large enough sample to establish generalizable results. Early indications suggest that after three months of program, compliance is at 32.9% for the onsite and 38.4% for the online group. These numbers were collected prior to implementing the encouragement letters, making it reasonable to expect compliance to increase in the next weeks. The Fuel Fund of Maryland expected the training to have about a 5-7% effect as suggested by previous, non-experimental evaluations. ',\n",
       " '',\n",
       " 'Power calculations were based on a sample size of 10 PHC clinics per arm and 10 SP visits per clinic across all time periods. We calculated the power of a test for post-training differences across arms in the percentage of SPs with correct medications assuming 35% for the control arm, 75% for lecture, and 60% for the other two delivery methods. Under three different assumptions about the random effects for facilities and for SPs, and 0.05 level of significance, the estimated power to detect a 15% difference between the lecture and other delivery arms was at least 0.8. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Of course, final power calculations will depend on the exact feasible sample size (which will be based on how many eligible jobs openings we can identify and constrained by timing considerations due to the law change) and the baseline probability of a call-back in our sample.\\r\\n\\r\\nIn previous audit studies, positive response call-backs have varied widely. Some examples include:\\r\\nLahey (2008): 8-10%\\r\\nOreopolous (2011): 11-16%\\r\\nDeming et al (2014): 8.2%\\r\\nBertrand &amp; Mullainathan (2004): 8%\\r\\nPhillips (2015): 18.7%\\r\\nPager (2004): ~17%  (in person applications)\\r\\nPager et al (2009): 23% (in person applications)\\r\\n\\r\\nThe first 4 audit studies use resumes and mostly college level jobs. The final 3 are more focused on the low-wage, low-skilled sector - Phillips uses both resumes and online applications, Pager and Pager et al use in person job applications. \\r\\n\\r\\nIn a linear model, if we assume a call-back probability of 15% (conservative based on the studies most closely related to ours), a standard deviation of 0.125 (.15*(1-.15)), power=.8 and alpha=0.05 then our minimum detectable effect size for the main effects of our manipulated characteristics (of, e.g., race) is 0.9 percentage points or 6 percent. \\r\\n\\r\\nAs our outcome variable is binary, however, using the same call-back probability of 15% and sample size of 6000, making some simplifying assumptions, ignoring clustering,  and using the calculation described in Demidenko E. (2007), we should have the power to detect a main effect (of, e.g., race) with an odds ratio of 1.217, in a simple bivariate logit regression.  See http://www.dartmouth.edu/~eugened/power-samplesize.php. \\r\\n\\r\\nIn analyses that include interaction effects, power will be reduced.  On the other hand, we also intend to conduct \"within-subjects\" analyses for the businesses that we are able to send applications to in both periods; these analyses should be able obtain greater power with a smaller sample size, although they will be limited only to a subset of the sample.\\r\\n\\r\\nReferences:\\r\\n\\r\\nBertrand, M. and S. Mullainathan (2004). \"Are Emily and Greg more employable than Lakisha and Jamal? A field experiment on labor market discrimination.\" The American Economic Review 94(4): 991-1013\\r\\n\\r\\nDemidenko E. (2007). \"Sample size determination for logistic regression revisited.\" Statistics in Medicine 26:3385-3397\\r\\n\\r\\nDeming, D., N. Yuchtman, A. Abulafi, C. Goldin and L. Katz (2014). \"The value of postsecondary credentials in the labor market: an experimental study\". NBER Working Paper #20528\\r\\n\\r\\nLahey, J. (2008). \"Age, women, and hiring: an experimental study\" The Journal of Human Resources 43(1): 30-56\\r\\n\\r\\nOreopolous, P. (2011). \"Why do skilled immigrants struggle in the labor market? A field experiment with thirteen thousand resumes\" American Economic Journal: Economic Policy 3:148-171\\r\\n\\r\\nPager, D. (2003). \"The Mark of a Criminal record\" American Journal of Sociology 108(5): 937-975\\r\\n\\r\\nPager, D., B. Western, and B. Bonikowski (2009). \"Discrimination in a low-wage labor market: a field experiment\" American Sociological Review 74:777-799\\r\\n\\r\\nPhillips, D. (2015). \"Neighborhood affluence or long commutes: Using a correspondence experiment to test why employers discriminate against applicants from poor neighborhoods\" Unpublished working paper',\n",
       " 'We use two primary outcomes of interest in order to calculate power. Our first outcome is the probability of discontinuation by 6 months, defined as the percentage of women who are not using the original method (method adopted at enrollment) for a continuous period of 6 months. Using Jacaranda’s administrative data, we assume that the method mix at original uptake will reflect Jacaranda family planning clients since October 2013. We thus assume that 10% of our sample will obtain pills (combined or progestin-only), 1.4% male condoms, 28.8% injectables, 41.8% implants, and 18% IUCDs. Assuming an exponential decay in contraceptive continuation and using discontinuation probabilities from the Demographic and Health Surveys, we assume an average probability of discontinuation by 6 months in a sample using this method mix to be 11.9% (KDHS 2008/2009; Ali, Cleland, and Shah 2012; FHI360). We would then have 80% power to detect a decrease in discontinuation at 6 months of 6 percentage points. This change would represent a decrease in the overall probability of discontinuation at 6 months to 5.5%, which would represent a significant reduction in discontinuation. We believe this reduction is plausible, given 50-80% of discontinuation is due to the same types of method-related problems (such as dissatisfaction, inconvenience, side effects or health concerns) that our intervention aims to address (Ali, Cleland, and Shah 2012). \\r\\n\\r\\nOur second outcome is receipt of follow-up care related to contraceptive use by 6 months. Currently, 19% of Jacaranda’s family planning clients return for a second family planning consultation. With 600 women in our study, assuming equal groups of 300 women, we will have 80% power to detect an increase in the probability of returning for care with 6 months of use of 9% points. This change would represent a significant improvement in contraceptive follow-up care, and is believed to be feasible given similar effects sizes on appointment follow-up caused by mHealth reminder interventions in Kenya (Odeny et al. 2012).',\n",
       " '',\n",
       " 'Main Outcome Variable\\t                                          MDE    As % of Mean \\tS.D\\r\\nMeasure of Knowledge\\t                                           0.2\\t0.31\\t               1.07\\r\\nExpenditure on Fertilizers per Acre in rupees\\t         461.4 \\t0.16\\t             2329.31\\r\\nExpenditure on Pesticides per Acre\\t                        185.8\\t0.15\\t              938.02\\r\\nEffect on Information Sources                          \\t 0.1\\t        0.47\\t               0.36\\r\\nImpact on Yield per Acre\\t                                        46.1\\t        0.10\\t               232.9\\r\\n',\n",
       " '',\n",
       " 'Power calculation: Minimum Detectable Effect Size for Main Outcomes :\\r\\n(Accounting for sample design and clustering, what is the minimum detectable effect size for main outcomes. Specify the unit, standard deviation, and percentage)\\r\\nMain Outcome Variables\\t                         MDE\\tAs % of Mean\\tStd. Dev\\r\\nTotal Cotton Harvested (kilogram)\\t       138.09\\t0.08\\t            1153.35\\r\\nGross Income (in rupees)\\t               6391.5\\t0.09\\t            55488.00\\r\\nExpenditure on Fertilizers (in rupees)\\t590.11\\t0.10\\t            4654.19\\r\\nExpenditure on Pesticides (in rupees)\\t345.62\\t0.09\\t             2602.51\\r\\nExpenditure on Seeds (in rupees)\\t      153.25\\t0.05\\t             1253.10\\r\\nExpenditure on Irrigation (in rupees)\\t214.22\\t0.26\\t            1472.40\\r\\n',\n",
       " 'Power calculations using price variation from the pilot suggest that the sample size of 60 markets should be sufficient to detect a change in price equivalent to a pass-through rate of 20% for the 200Ksh subsidy and 10% for the 400Ksh subsidy (note that, for a larger subsidy, a given pass-through rate results in a larger change in absolute price, which is therefore easier to detect statistically).',\n",
       " 'Power Calculations\\r\\nPower calculations for some outcomes of interest are based on the results of the June wave of the 2014 pilot. Calculations of minimum detectable effects assume 10%, 5% or 1% statistical significance, 80% statistical power, a sample size of 5,000 farmers, 50% of non-response rate (also based on the average for the 2014 pilot) and 50% random assignment to priming about rainfall (a crucial element of the experiments). Given these parameters, minimum detectable effects (in absolute value) are given by:\\r\\n|MDE|=(t_(1-κ)+t_alpha ) √(σ^2/p(1-p)   x 4/NxW)  ,\\r\\nWhere t_(1-κ) is the t-statistic associated with confidence level 1-κ, t_α is the t-statistic associated with power α, σ is the standard deviation of the effect, p is the proportion of the 5, observations in the treatment group, N is the number of observations, and W is the number of waves. The term  4/NxW incorporates the 50% non-response rate and the 50% random assignment to priming about rainfall, which divide the effective number of observations by a factor of 4.\\r\\nTables 1 to 3 present computations for the outcomes that most resemble the ones we would like to include the 2015 design, under 10%, 5% and 1% significance levels. Table 4 presents the details of the computations for one of the outcomes as an example.\\r\\n\\r\\nTable 1 – Minimum detectable effects (absolute value) under 10% significance\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n(A) Two waves\\t\\t\\t\\tMinimum Detectable Effect (absolute value)\\r\\n\\t\\tJune \\r\\ncoefficient\\tJune \\r\\nstd. dev.\\tAverage\\tT = 1250\\tT = 1125\\tT = 1000\\tT = 875\\tT = 750\\tT = 625\\tT = 500\\tT = 375\\tT = 250\\r\\nCognitive tasks\\tDigit span\\t0.13\\t0.09\\t0.24\\t0.035\\t0.036\\t0.038\\t0.040\\t0.042\\t0.046\\t0.050\\t0.057\\t0.069\\r\\n\\tStroop\\t0.01\\t0.08\\t0.19\\t0.032\\t0.033\\t0.034\\t0.036\\t0.038\\t0.041\\t0.046\\t0.052\\t0.063\\r\\n\\tGarbled words\\t0.06\\t0.13\\t0.18\\t0.041\\t0.043\\t0.045\\t0.047\\t0.050\\t0.054\\t0.060\\t0.068\\t0.082\\r\\nPrice recall\\tBeans (Week 1)\\t-0.11\\t0.11\\t0.31\\t0.038\\t0.039\\t0.041\\t0.043\\t0.046\\t0.049\\t0.054\\t0.062\\t0.075\\r\\n\\tCorn (Week 1)\\t-0.08\\t0.11\\t0.29\\t0.039\\t0.040\\t0.042\\t0.044\\t0.047\\t0.050\\t0.056\\t0.063\\t0.077\\r\\n\\tGoat (Week 1)\\t0.02\\t0.08\\t0.16\\t0.033\\t0.034\\t0.035\\t0.037\\t0.040\\t0.043\\t0.047\\t0.054\\t0.065\\r\\n\\t\\t\\t\\t\\t\\r\\n\\r\\n\\r\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n(B) Five waves\\t\\t\\t\\tMinimum Detectable Effect (absolute value)\\r\\n\\t\\tJune \\r\\ncoefficient\\tJune \\r\\nstd. dev.\\tAverage\\tT = 1250\\tT = 1125\\tT = 1000\\tT = 875\\tT = 750\\tT = 625\\tT = 500\\tT = 375\\tT = 250\\r\\nCognitive tasks\\tDigit span\\t0.13\\t0.09\\t0.24\\t0.022\\t0.023\\t0.024\\t0.025\\t0.027\\t0.029\\t0.032\\t0.036\\t0.044\\r\\n\\tStroop\\t0.01\\t0.08\\t0.19\\t0.020\\t0.021\\t0.022\\t0.023\\t0.024\\t0.026\\t0.029\\t0.033\\t0.040\\r\\n\\tGarbled words\\t0.06\\t0.13\\t0.18\\t0.026\\t0.027\\t0.028\\t0.030\\t0.032\\t0.034\\t0.038\\t0.043\\t0.052\\r\\nPrice recall\\tBeans (Week 1)\\t-0.11\\t0.11\\t0.31\\t0.024\\t0.025\\t0.026\\t0.027\\t0.029\\t0.031\\t0.034\\t0.039\\t0.047\\r\\n\\tCorn (Week 1)\\t-0.08\\t0.11\\t0.29\\t0.024\\t0.025\\t0.026\\t0.028\\t0.030\\t0.032\\t0.035\\t0.040\\t0.048\\r\\n\\tGoat (Week 1)\\t0.02\\t0.08\\t0.16\\t0.021\\t0.021\\t0.022\\t0.024\\t0.025\\t0.027\\t0.030\\t0.034\\t0.041\\r\\n\\r\\n\\r\\nTable 2 – Minimum detectable effects (absolute value) under 5% significance\\r\\n(A) Two waves\\t\\t\\t\\tMinimum Detectable Effect (absolute value)\\r\\n\\t\\tJune \\r\\ncoefficient\\tJune \\r\\nstd. dev.\\tAverage\\tT = 1250\\tT = 1125\\tT = 1000\\tT = 875\\tT = 750\\tT = 625\\tT = 500\\tT = 375\\tT = 250\\r\\nCognitive tasks\\tDigit span\\t0.13\\t0.09\\t0.24\\t0.039\\t0.041\\t0.043\\t0.045\\t0.048\\t0.052\\t0.057\\t0.065\\t0.078\\r\\n\\tStroop\\t0.01\\t0.08\\t0.19\\t0.036\\t0.037\\t0.039\\t0.041\\t0.043\\t0.047\\t0.051\\t0.059\\t0.071\\r\\n\\tGarbled words\\t0.06\\t0.13\\t0.18\\t0.047\\t0.048\\t0.050\\t0.053\\t0.057\\t0.061\\t0.067\\t0.077\\t0.093\\r\\nPrice recall\\tBeans (Week 1)\\t-0.11\\t0.11\\t0.31\\t0.043\\t0.044\\t0.046\\t0.048\\t0.052\\t0.056\\t0.061\\t0.070\\t0.084\\r\\n\\tCorn (Week 1)\\t-0.08\\t0.11\\t0.29\\t0.043\\t0.045\\t0.047\\t0.050\\t0.053\\t0.057\\t0.063\\t0.071\\t0.086\\r\\n\\tGoat (Week 1)\\t0.02\\t0.08\\t0.16\\t0.037\\t0.038\\t0.040\\t0.042\\t0.045\\t0.048\\t0.053\\t0.061\\t0.073\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n(B) Five waves\\t\\t\\t\\tMinimum Detectable Effect (absolute value)\\r\\n\\t\\tJune \\r\\ncoefficient\\tJune \\r\\nstd. dev.\\tAverage\\tT = 1250\\tT = 1125\\tT = 1000\\tT = 875\\tT = 750\\tT = 625\\tT = 500\\tT = 375\\tT = 250\\r\\nCognitive tasks\\tDigit span\\t0.13\\t0.09\\t0.24\\t0.025\\t0.026\\t0.027\\t0.028\\t0.030\\t0.033\\t0.036\\t0.041\\t0.049\\r\\n\\tStroop\\t0.01\\t0.08\\t0.19\\t0.023\\t0.023\\t0.024\\t0.026\\t0.027\\t0.030\\t0.033\\t0.037\\t0.045\\r\\n\\tGarbled words\\t0.06\\t0.13\\t0.18\\t0.029\\t0.031\\t0.032\\t0.034\\t0.036\\t0.039\\t0.043\\t0.048\\t0.059\\r\\nPrice recall\\tBeans (Week 1)\\t-0.11\\t0.11\\t0.31\\t0.027\\t0.028\\t0.029\\t0.031\\t0.033\\t0.035\\t0.039\\t0.044\\t0.053\\r\\n\\tCorn (Week 1)\\t-0.08\\t0.11\\t0.29\\t0.027\\t0.029\\t0.030\\t0.031\\t0.033\\t0.036\\t0.040\\t0.045\\t0.055\\r\\n\\tGoat (Week 1)\\t0.02\\t0.08\\t0.16\\t0.023\\t0.024\\t0.025\\t0.027\\t0.028\\t0.030\\t0.034\\t0.038\\t0.046\\r\\n\\r\\nTable 3 – Minimum detectable effects (absolute value) under 1% significance\\r\\n(A) Two waves\\t\\t\\t\\tMinimum Detectable Effect (absolute value)\\r\\n\\t\\tJune \\r\\ncoefficient\\tJune \\r\\nstd. dev.\\tAverage\\tT = 1250\\tT = 1125\\tT = 1000\\tT = 875\\tT = 750\\tT = 625\\tT = 500\\tT = 375\\tT = 250\\r\\nCognitive tasks\\tDigit span\\t0.13\\t0.09\\t0.24\\t0.048\\t0.050\\t0.052\\t0.055\\t0.058\\t0.063\\t0.069\\t0.079\\t0.096\\r\\n\\tStroop\\t0.01\\t0.08\\t0.19\\t0.044\\t0.045\\t0.047\\t0.050\\t0.053\\t0.057\\t0.063\\t0.072\\t0.086\\r\\n\\tGarbled words\\t0.06\\t0.13\\t0.18\\t0.057\\t0.059\\t0.062\\t0.065\\t0.069\\t0.075\\t0.082\\t0.094\\t0.113\\r\\nPrice recall\\tBeans (Week 1)\\t-0.11\\t0.11\\t0.31\\t0.052\\t0.054\\t0.056\\t0.059\\t0.063\\t0.068\\t0.075\\t0.085\\t0.103\\r\\n\\tCorn (Week 1)\\t-0.08\\t0.11\\t0.29\\t0.053\\t0.055\\t0.057\\t0.061\\t0.064\\t0.070\\t0.077\\t0.087\\t0.105\\r\\n\\tGoat (Week 1)\\t0.02\\t0.08\\t0.16\\t0.045\\t0.047\\t0.049\\t0.051\\t0.055\\t0.059\\t0.065\\t0.074\\t0.089\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\r\\n(B) Five waves\\t\\t\\t\\tMinimum Detectable Effect (absolute value)\\r\\n\\t\\tJune \\r\\ncoefficient\\tJune \\r\\nstd. dev.\\tAverage\\tT = 1250\\tT = 1125\\tT = 1000\\tT = 875\\tT = 750\\tT = 625\\tT = 500\\tT = 375\\tT = 250\\r\\nCognitive tasks\\tDigit span\\t0.13\\t0.09\\t0.24\\t0.030\\t0.032\\t0.033\\t0.035\\t0.037\\t0.040\\t0.044\\t0.050\\t0.060\\r\\n\\tStroop\\t0.01\\t0.08\\t0.19\\t0.028\\t0.029\\t0.030\\t0.031\\t0.033\\t0.036\\t0.040\\t0.045\\t0.055\\r\\n\\tGarbled words\\t0.06\\t0.13\\t0.18\\t0.036\\t0.037\\t0.039\\t0.041\\t0.044\\t0.047\\t0.052\\t0.059\\t0.072\\r\\nPrice recall\\tBeans (Week 1)\\t-0.11\\t0.11\\t0.31\\t0.033\\t0.034\\t0.036\\t0.037\\t0.040\\t0.043\\t0.047\\t0.054\\t0.065\\r\\n\\tCorn (Week 1)\\t-0.08\\t0.11\\t0.29\\t0.034\\t0.035\\t0.036\\t0.038\\t0.041\\t0.044\\t0.048\\t0.055\\t0.067\\r\\n\\tGoat (Week 1)\\t0.02\\t0.08\\t0.16\\t0.028\\t0.030\\t0.031\\t0.032\\t0.035\\t0.037\\t0.041\\t0.047\\t0.057\\r\\n\\r\\n\\r\\n\\r\\nTable 4 – Example for Digit Span (Week 2) under 1% significance\\r\\nControl group (Uninsured)\\tInsured\\tInsured\\tInsured\\tInsured\\tInsured\\tInsured\\tInsured\\tInsured\\tInsured\\r\\n5000 - Insured\\t1250\\t1125\\t1000\\t875\\t750\\t625\\t500\\t375\\t250\\r\\nWaves\\t2\\t2\\t2\\t2\\t2\\t2\\t2\\t2\\t2\\r\\nt_(1-κ)\\t2.58\\t2.58\\t2.58\\t2.58\\t2.58\\t2.58\\t2.58\\t2.58\\t2.58\\r\\nt_α\\t0.84\\t0.84\\t0.84\\t0.84\\t0.84\\t0.84\\t0.84\\t0.84\\t0.84\\r\\np\\t0.25\\t0.225\\t0.2\\t0.175\\t0.15\\t0.125\\t0.1\\t0.075\\t0.05\\r\\nσ\\t0.0926\\t0.0926\\t0.0926\\t0.0926\\t0.0926\\t0.0926\\t0.0926\\t0.0926\\t0.0926\\r\\nMDE\\t0.048\\t0.050\\t0.052\\t0.055\\t0.058\\t0.063\\t0.069\\t0.079\\t0.096\\r\\n\\r\\nUnder 10% and 5% significance, both the two- and five-wave designs would be able to detect the effects for Digit span, Garbled words, and price recall of beans and corn. The five-wave design would be very close to detecting the effect of the treatment on recall of goat average prices. Under 1% significance, the two-wave design would no longer be able to detect the effect of the treatment on the score of Garbled words, while the five-wave design would still be able to detect it.\\r\\nNone of the two designs would be able to detect the effect of the treatment on Stroop scores in week 1 or on recall of goat prices in week 2. Having said that, the estimated effects for the June wave were very small, so it might as well be that such effects are not statistically significant after the planting stage, when uncertainty about rainfall has been resolved. As an illustration, we estimated a four-fold effect of the treatment on stoop scores in the March wave.\\r\\nIt follows that the number of waves is binding in this design in what comes to detecting the effects of interest, particularly with respect to Garbled words, the one task representing the “focus dividend” of tunneling in our 2014 pilot.\\r\\n',\n",
       " 'We provided the following statement to the funder (the International Growth Centre) prior to the study:\\r\\n\\r\\n\"...we are confident that our high power from the pilot will extend to this scaled-up study. To evaluate this, we have run a bootstrap resampling algorithm; this preserves the intracluster correlation structure of both treatments and outcomes, while allowing us to vary the hypothetical sample size. For the actual effect sizes observed in the first pilot, we can use a sample of just 300 observations and still obtain power of 96.7% for detecting sensitivity to the interest rate, and power of 94.7% for detecting sensitivity to the day of repayment (with alpha of 0.05). (For the intended participating sample of 450, the power rises to over 99% in each case.) Intuitively, this power is generated by the fact that we expose each participant respondent to three separate rotations of the treatment.\\r\\n\\r\\n\"As discussed shortly, our revised design includes 450 participants and 450 controls. We intend to compare participants and controls on a variety of continuous firm-level outcomes (e.g. firm profits). Simple calculations show that we will detect an Intent To Treat effect size of 0.25 standard deviations with power of 96% (again, at alpha of 0.05).\"',\n",
       " '',\n",
       " 'The mean fraction of female BAs majoring in economics (unweighted by treatment school) is 0.04. The minimum detectable change between control and treatment schools in the fraction of female BAs majoring in economics is 0.0072. ',\n",
       " '',\n",
       " '',\n",
       " 'We present the minimum detectable effect (MDE) for each treatment arm on a hypothetical measure of public opinion.  We calculate the MDE for two parameters:\\r\\n1.     The intent-to-treat effect of deliberation plus information.\\r\\n2.     The intent-to-treat effect of information alone.\\r\\n\\r\\nOur design is intended to measure spillover effects (i.e., information flows) within clusters, and we focus here on the MDE for treatment effects that are not contaminated by spillovers, comparing individuals invited to treatment with control individuals in pure control villages.\\r\\n\\r\\nWe calculate MDEs based on a power (κ) of 80% and a significance level (α) of 5%. \\r\\n\\r\\nA key unknown parameter is the intraclass correlation of responses within our clusters.  We estimate this correlation using data from Tanzania’s National Panel Survey (NPS), rounds 1 and 2.  The NPS is uniquely suited to our purposes here, in that it (a) has a clustered sample design, (b) collects information on public opinion, in this case support for the respondent’s member of parliament, and (c) follows the same respondent over time to enable us to calculate variances and intraclass correlations in terms of both levels and changes.  Using the NPS data, we conducted power calculations using a variety of possible outcome measures: MDEs in terms of a binary response variable, and levels and changes of both variables.  Both variables show an intraclass correlation of approximately 0.16.  All calculations below use this parameter value as a conservative estimate of our anticipated MDE.\\r\\n\\r\\nBecause the experimental design proposed above involves unequal divisions of individuals between treatment and control groups (and between various treatment arms), we calculate MDEs by simulation in Stata based on randomly generated numbers with the intraclass correlation found in the NPS and the sample design described above. Each repetition of the simulation produces slightly different standard errors and thus MDEs. We repeated the simulation 20 times and averaged the MDEs over all iterations.\\r\\n\\r\\nResults show that we will be able to detect impacts of the information treatment on public opinion of roughly 7 percentage points in either direction on a binary outcome, and approximately 8 percentage points for the deliberation treatment.\\r\\n\\r\\n',\n",
       " '',\n",
       " 'Sample sizes of about  300 subjects per condition would allow us to detect a 10 percentage point increase in donations with 95% confidence level and 80% power',\n",
       " 'T1 vs C:\\r\\nUnit: municipality (60)\\r\\nEffect size: 0.15\\r\\nICC: 0.03\\r\\nPower:0.8\\r\\n\\r\\nT1 vs T2:\\r\\nUnit: mother leader (270)\\r\\nEffect size: 0.17\\r\\nICC: 0.03\\r\\nPower: 0.80\\r\\n\\r\\n',\n",
       " \"Please refer to attached experiment proposal for additional details. We are sufficiently powered to detect differences in all of our primary endpoints (modern contraceptive use, method mix, family planning knowledge and attitudes, pregnancy within the next 2 years, fertility intentions) over the two year study period. However, we are not likely to be sufficiently powered to detect longer term outcomes related to completed fertility, women's employment, and income, which require longer follow up. With this said, we measure shorter term outcomes, such as women's time use and short-term shifts from informal into formal sector labor, that suggest changes in longer term outcomes, and we begin collecting data for longer term outcomes with the expectation of conducting a longer term follow-up.\",\n",
       " 'Power calculations were conducted for the main outcomes on both the worker and firm side of the experiment. For details, please refer to Table 1 in the Supporting Documents and Materials section.',\n",
       " '',\n",
       " '',\n",
       " 'In the baseline, monthly income per capita is 4301 Ksh (SD=5527).\\r\\nThe minimum detectable effect size in a treatment group of 169 individuals versus 359 in the control group is 1450 Ksh, 26% income increase.\\r\\n\\r\\nThis is enough to detect the massive returns due to pesticide or cattle growing. Pesticides can double yields (Behera and Singh (1999). In qualitative interviews, farmers from this area report that a 5 months bull is worth 8,000 to 10,000 Ksh, while a 3 year bull is worth 60,000 to 100,000 Ksh. In the conservative case of 60,000 (/12 months / average household size of 3.7)=1,351Ksh/month. These sample sizes are thus sufficient to detect the returns to these high-return technologies.',\n",
       " '',\n",
       " 'With a 25% response rate, we can estimate the average and distribution of willingness-to-pay very precisely\\r\\n',\n",
       " 'We ran a small pilot to ensure that our protocol were working and that we were able to create differential effort with our online task. The pilot also allowed us to get an estimate for what the standard deviation will be in our task. Based on 393 pilot participants, the standard deviation of points scored was around 740 and was similar across different treatments. Assuming that this is approximately the standard deviation of each treatment in the experiment and assuming a sample size of 5500 (305 per treatment), there is thus an 80% power to reject the null hypothesis of zero difference in average points between two treatments when the actual difference between the two treatments is 168.1 points.  Assuming instead a sample size of 10,000 (555 per treatment), there is then an 80% power to reject the null hypothesis of zero difference when the actual difference is 124.6 points.\\r\\n\\r\\nBased on our pilot, different treatments can create differences in average points scored by as much as 400-500 points, a difference of which can easily be detected statistically given the preceding calculations.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Modeling Seroquel prescribing according to the distribution of Schedule II controlled substance prescribing, we estimated a minimum detectable effect of 1.5-1.7% of the baseline mean at a sample size of N=5,000 for 1-month and 3-month prescription drug treatments and 30-day equivalents. Because we will have access to control variables like prior prescribing that will improve our statistical power, we believe these estimates are conservative.',\n",
       " 'N/A. We are not estimating a treatment effect, but rather, estimating discount factors.',\n",
       " 'N/A; not relevant here.',\n",
       " '',\n",
       " 'Measuring the effect as the number of additional toilet usages per month and using the standard deviation from the pilot study (7.7), with a sample size of 3000 individuals and based on the sample allocation discussed in section 4.1 we are able to detect an effect of 1.06 between our main comparison discount groups (i.e., discount groups 1 &amp; 3). Similarly we are able to detect an effect of 0.87 between the marketing and non-marketing groups and the one month and the two month groups.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The power calculation was done following a conservative approach, i.e. assuming that the treatment will have a low impact (0.20 standard deviation).',\n",
       " 'pilot study only',\n",
       " '',\n",
       " \"The statistical program G*Power was used to conduct power analysis in order to determine the appropriate sample size. Adhering to Cohen's (1988) guidelines for small (r= 0.1), medium (r= 0.3), and large (r= 0.5) effects, two-tailed alpha of .05 was assumed for all tests.  With 2 groups, 6 measurements, an assumed correlation among repeated measures of 0.3 (typically low in such research; Weiner, Schinka, &amp; Velicer, 2012) as well as a medium effect size (again typical in research on the cognitive effects of mindfulness; Chiesa et al., 2011) and a power of 0.8, the recommended sample size for mixed (repeated-measures and between factors) ANOVA was 56.  As it is recommended that the sample size be a multiple of the number of measurements, a sample of 60 will be sought, 30 per group.\",\n",
       " 'N/A',\n",
       " 'Based on the initial sample and under the hypothesis of perfect compliance, we were able to detect MDE of approximately 0.17 standard deviation.\\r\\nBased on the final sample and taking into consideration imperfect compliance, we are able to detect MDE of approximately 0.25 standard deviation.',\n",
       " '',\n",
       " 'Overall, the impact evaluation has sufficient power to detect MDE between 10.9% and 12.7% across the various sub-groups. For comparison  between youths receiving the two types of training, expected impacts are smaller. For this comparison, the MDE is 12,7%, which allows identifying small effect sizes. Comparisons between the control group and the sample of treated youth not receiving training has slightly better power (MDE of 10.9%). ',\n",
       " '',\n",
       " '',\n",
       " 'The sample size is powered to detect differences between all four treatment groups seen as a whole and the control group, for all the three main outcomes defined above. We adjust for multiple hypothesis testing using the Benferroni correction.\\r\\n\\r\\nWith the planned sample of 3000 observations (distributed as 1000 observations in the control group, and 500 observations in each of the four treatment groups) we can detect effect sizes of 0.2 SD between treatment and control outcomes with a power of 99% and a level of significance of 5%.\\r\\n\\r\\nThe planned sample will also allow us to detect effect sizes of 0.2 SD with a power of 78% and a level of significance of 5%.',\n",
       " 'The sample size (a-list) was powered to detect changes in payment of school fees. We know from baseline that 70% of the parents report that at least one child has been sent away from school due to lack of payment of school fees. This is consistent with the numbers reported to us from established WCM groups in Tororo and Kumi in a pilot study that we conducted April 2015: 70% reported to have been forced to hold children home from school due to the non-payment of school fees. The pilot revealed that, today, only 28% of them had similar problems. With an average of 7 parents on the a-list in each group, and taking into account clustering, we have a power of at least 90% (with a 5% confidence interval) to detect a 20 percentage point reduction in non-payment of schools fees.',\n",
       " 'There are very few studies doing household experiments and, to our knowledge, none of them include children. To inform the power calculations, we therefore used typical standard deviations from the literature on dictator games.\\r\\n\\r\\nThe planned sample size is powered to identify effects on investments in children between all three treatment groups. With the planned sample of 450 observations equally distributed between the three treatments we can defect sizes of 0.4 SD between treatments with a power of 93%.',\n",
       " '',\n",
       " 'We use the results of a pilot study to determine whether our study is sufficiently powered to detect economically meaningful effects. Since we are proposing multiple treatments, we make hypothetical comparisons between different combinations of pairs. Specifically, we compare the “encouragement” condition (T1) with the “Rs. 150 unconditional incentive for referrers” treatment condition (T4). Treatment is assigned at the center level. Because we are comparing pairs of treatments, and because each treatment condition will be assigned to 20 centers, the number of clusters in our calculations below is 40. We focus on three key outcomes of interest: Y1 = 1 if the patient made at least one referral, 0 otherwise; Y2 = N. of referrals made by the patient; Y3 = Number of TB positive referrals made by the patient.  \\r\\n\\r\\nGiven the standard deviation of the outcome variables, the effects found in a pilot study imply the following effect sizes (effect/standard deviation): 0.45 for Y1, 0.58 for Y2, and 0.59 for Y3. \\r\\n\\r\\nThe intra-class correlations within centers from the pilot are as follows: Y1 ICC = 0.07; Y2 ICC = 0.13; Y3 ICC = 0.14. \\r\\nThe minimum detectable effect sizes are 0.31 for Y1, 0.38 for Y2, and 0.39 for Y3 assuming 0.80 power; and 0.36 for Y1, 0.44 for Y2, and 0.45 for Y3 assuming 0.90 power. \\r\\n\\r\\nGiven that the effects we obtained in the pilot are substantially larger than those computed in these power calculations, we conclude that our proposed sample sizes of 20 sites for T0-T9 are appropriate to detect effects of meaningful size.  Note that in the pilot, the incentives conditional on TB test results delivered effects similar in magnitude to those of the encouragement condition. In the full-scale experiment, we have increased the expected value of the conditional reward to match that of the unconditional one, which we anticipate will increase its size effect. \\r\\n',\n",
       " 'In the context of clustered treatment assignment the minimum detectable effect (MDE, Bloom 1984) will vary as a function of the extent of clustering. We calculated a range of MDEs under different clustering scenarios for our primary binary outcome, labor force participation, conditional on the number of clusters (j) the number of subjects per cluster (n) and the degree of clustering (estimated by the intra-cluster correlation coefficient [ICC]). We focus on estimating the MDE for a pre-specified level of power, based on our initial design of j=160 clusters (80 treated, 80 comparison) and n=20 subjects per cluster. \\r\\n\\r\\nPlugging in values for type II error (kappa=0.20), type I error (alpha=0.05), a balanced 50% allocation fraction (P=0.5), the standard deviation of the outcome in the control population (labour force participation rate of 30%, so SD=.3*(1-.3)=.21), and sample size (N=3200), this gives a MDE of 0.03, meaning that we could detect a treatment effect as small as 3 percentage points (33% or 27% in the treated vs. 30% in the control).\\r\\n\\r\\nCluster randomization will increase the MDE because it reduces precision, and this is a function of the degree of clustering, as measured by the intra-cluster correlation (ICC). Effectively, this deflates the precision so we will either need to be satisfied with a larger MDE or a bigger sample to estimate the same MDE. If we revise the scenario above to take into account the clustered design, fixing the clusters again to 80 treated and 80 untreated, increasing the ICC increases the MDE.\\r\\n\\r\\nFor k=160 clusters and n=20 individuals per cluster, the MDE for various ICCs are calculated as:\\r\\n\\r\\nICC=0.00, MDE=0.05\\r\\nICC=0.05, MDE=0.07\\r\\nICC=0.10, MDE=0.08\\r\\nICC=0.20, MDE=0.10\\r\\n\\r\\nFor degrees of clustering typical in social science surveys (between 0.01 and 0.05, Bloom 2005), the present design of 160 clusters and 20 individuals per cluster still provides us with MDEs that seem feasible and relevant (5 to 7 percentage point differences for binary outcomes with baseline proportions of around 0.3).\\r\\n',\n",
       " '',\n",
       " '3.7% (SD of 42g)  for weight of flowers strung. \\r\\n2.1% (SD of Rs. 11.6) for payment for performance on cognitive tasks (which are compensated according to performance). ',\n",
       " '',\n",
       " 'The minimum detectable effect size (MDES) calculations presented here focus on test score outcomes because learning is the primary outcome of interest for the evaluation. We use existing end-of-grade (EOG) test score data from 2012 to calculate EOG test score standard deviations and intracluster correlations for the areas where the intervention will take place.\\r\\n\\r\\nThe main inputs for the MDES calculations are: (1) the percentage of variance explained by the use of covariates in the regression model (R2) is assumed to be 0.1 for schools and 0.5 for students; and (2) the intracluster correlation, which is a measure of the similarity of students between schools versus the total between- and within-school variation, is estimated to be 0.06 based on 2012 EOG reading scores. These calculations also assume 80 percent power, statistical significance at the 5 percent level, and a two-tailed test.\\r\\n\\r\\nWe will compare each of two treatment groups to a third reference group. For this type of comparison, the Dunnett test is the most appropriate test to control Type I error across multiple contrasts. Therefore, we assume that a Dunnett test will be used in the three comparisons studied. \\r\\nAssuming a sample of 180 schools, we will have a student sample of 1,800 students, or 10 students per school.\\r\\n',\n",
       " 'Power calculations in attached analysis plan.',\n",
       " '',\n",
       " 'N/A',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'To achieve a sample size of 200, we conducted several sessions of the experiment with an average of 20 respondents per session. ',\n",
       " 'Considering the following take-up:\\r\\n\\r\\nControl -&gt;100%\\r\\nTreatment -&gt; 40%\\r\\nTreatment 2 -&gt; 80%\\r\\nTreatment 3 -&gt; 95%\\r\\n\\r\\nThen the MDEs when comparing to the control groups are:\\r\\nTreatment 1 --&gt; 0,2524 SD\\t\\r\\nTreatment 2 --&gt; 0,1305 SD\\r\\nTreatment 3 --&gt; 0,1099 SD\\r\\n\\r\\n\\r\\nThe MDs of the Treatment 2 (SMS) compared to the other treatments:\\r\\nTreatment 1 --&gt; 0,2822 SD\\t\\r\\nTreatment 3 --&gt; 0,1430\\r\\n\\r\\nThe MDs of Treatment 3 compared to the Treatment 1 --&gt; 0,2822 SD',\n",
       " 'Power calculation performed before the project start showed that the RD-design had 90% power to identify a reduction of 7.5 sick days per employee per year at a 5% significance level (Type I error). The power calculation was performed in SAS 9.1 using data from a large scale sickness absence project and data from the participaring municipality’s register.',\n",
       " '',\n",
       " 'The chosen sample size of 2000 participants for the experiment ensures that we can detect an effect size of about 0.125 at a significance level of 0.05 with a power of about 0.8. Given that the effect sizes reported by Mani et al. (2013) are between 0.8 of a standard deviation and 1 standard deviation, we can be confident that our sample is sufficiently large to provide us with sufficient statistical power to detect effects.\\r\\n',\n",
       " '',\n",
       " \"This varies by cell.  Our goal is to look at the proportion of subjects that buy (vs not buy) a ticket in a given experimental cell. We then want to test for differences in proportions between cells.  So let's suppose we want to test whether two promotion cells have significantly different purchase responses.  Based on a pilot test, we might expect 2% response when the price is 30% off and 5% response when the price is 50% off.  To test for a significant difference, we would need 1,506 subjects in each of the two cells at 5% significance level and a power level of 0.8.\\r\\n\",\n",
       " '',\n",
       " '',\n",
       " 'In a 2012 study, which recruited a similar population of youth and used identical data sources as the proposed project, baseline covariates explained between 0.1 and 0.5 of the variation in outcomes (less for arrests, more for schooling outcomes). Since we have no reason to suspect that the treatment effect will vary by blocks, we do not account for any variability at the block level. With these assumptions, the overall treatment-control contrast has a minimum detectable effect (MDE) of between 0.05 and 0.08 standard deviations. The across-treatment contrast has an MDE of 0.09 to 0.12 SDs.',\n",
       " \"Since this pre-registration text precedes the running of the pilot and of the full study, I rely on the literature to obtain a rough sense of the adequate sample size. I focus mainly on treatment effects taking direct questioning (condition 1) as the control condition, and each of the other three conditions as separate treatments. I focus on two studies where the sensitive item concerns some form of cheating, and on a general meta-analysis: \\r\\n\\r\\n• Ocantos et al (2012) study vote buying using the ICT. They find that only 2.4% (s.e.=0.6%) of subjects reported receiving an individual gift in echange for their vote during a 2008 election in Nicaragua when asked directly, but 24% (s.e.=5.5%) reported having received such a gift when asked through the ICT. Assuming equal variances for the treatment and control groups, and supposing the variance is numerically equal to that estimated for the treatment group (a conservative choice in this case), power is close to 1.0 even for a sample size as small as 30 (since the effect size is so large).\\r\\n\\r\\n(Note: the formula I'm using, in Latex code, is: \\\\beta=\\\\Phi(\\\\left[|\\\\mu_{t}-\\\\mu_{c}|\\\\sqrt{N}\\\\right]/2\\\\sigma-\\\\Phi^{-1}(1-\\\\alpha/2)), where \\\\beta denotes power, \\\\Phi is the cumulative Normal distribution, \\\\Phi^{-1} is the inverse of such distribution, \\\\sigma is the standard deviation of the outcome for both the treatment and the control groups, N is the sample size, and \\\\alpha is the level of statistical significance (Gerber and Green 2012)).\\r\\n\\r\\n• Van der Heijden et al (2000) compare RRT with direct questioning in both a face-to-face survey and a computer-assisted survey. The proportion of subjects known to have engaged in income fraud who admitted to it was 43% (s.e.=6.8%), 25%(s.e.=4.4%), and 19%(5.8%) respectively for RRT, face-to-face direct questioning, and computer direct questioning. The effect size here is also so large that even 30 subjects suffices to attain power close to 1.0 (assuming, for example, that the standard error of the outcomes is 6.8%, and choosing 43%-25%=18% as the magnitude of the treatment effect).\\r\\n\\r\\n• In a meta-analysis of RRT, Lensvelt-Mulders (2005) find that the mean percent underestimation of a sensitive item using RRT is 38% (s.e.=.099), while it is 42% (s.e.=.099) in face-to-face interviews, 46% (s.e.=.138) in phone interviews, 47% (s.e.=.14) in self-administered questionnaires, and 62% (s.e.=.191) in computer-assisted surveys. Comparing the rate of reporting of the sensitive behavior under RRT with that under self-administered questionnaires, and taking the standard error to be 0.14, a sample size of 75 is necessary to attain power of 0.8.\\r\\n\\r\\nIn sum, while I face considerable uncertainty about effect sizes and variances before running the study, an N of 50 to 70 per treatment condition seems reasonable. It is not clear whether a small pilot study (with 15-30 respondents) would suffice to reduce this uncertainty in a meaningful way. To further improve power, to improve covariate balance, and to reduce the variability, I will estimate treatment effects adding pre-treatment covariates as control variables, and (alternatively) I will implement sequential blocking on pre-treatment covariates (after having collected the data, but without utilizing outcome data for blocking; see Moore and Moore 2011).\",\n",
       " 'The chosen sample size of 1012 effective participants for the experiment ensures that we can detect an effect size of 0.25 at a significance level of 0.05 with a power of about 0.8 for our main behavior measures.\\r\\n\\r\\nFor the manipulation checks and the main effects of the poverty treatment and the conformity treatment we are even able to detect effect sizes below .2  at a significance level of 0.05 with a power of about 0.8.\\r\\n',\n",
       " 'The analysis is best split between comparing control with treatment 1 and treatment 2, and comparing control with treatment 1 and treatment 3\\r\\n\\r\\nFor the first comparison, the MDE for treatment 1 relative to the control is a 10% standard deviation effect with the full sample (with 80% power and an alpha of 5%). (same with comparing the two treatments together).\\r\\n\\r\\nFor the second comparison, the MDE for treatment 1 relative to treatment 3 is a 12% standard deviation effect with the full sample. \\r\\n\\r\\nIn general, it is anticipated that subgroup analysis would be for a subset of more at risk student, about 25% of the full sample.  For this subsample the MDE is approximately 23% of a standard deviation.',\n",
       " 'We have powered our experiment to detect a 0.22 standardized effect size between price × information arms. Since many of the effects we are interested in estimating require receipt of stage 1 reminders, we will allocate only 20 percent of the sample to \"no reminders\". Since the randomization will be conducted at the individual level, we have used the minimum detectable effect formula without clustering in Glennerster and Takavarasha (2013). We have calculated the sample size needed to achieve target power for a single survey round (i.e. assuming one observation per individual) since we wish to estimate short- and long-run impacts separately. We have also scaled up our sample sizes to account for an assumed 10 percent attrition rate. This calculation suggests that we need a total sample size of 3,243, which we have rounded up to 3,500 for budgeting purposes and to account for the fact that some individuals in the first-stage reminder group will need to be used to pilot the BDM mechanism.\\r\\n\\r\\nThis design implies that we have sufficient power to detect a 0.12 standardized effect size between price and information arms, a 0.15 standardized effect size between \"no reminders\" and \"first-stage reminders\", and a 0.14 standardized effect size in terms of the impact of information treatments on willingness-to-pay for reminders. We are also interested in estimating reminder treatment effects conditional on a zero-to-negative willingness-to-pay. We have reasonable power to detect treatment effects when just 20-30 percent of individuals do not positively value reminders. To put these numbers in context, assuming a 50 percent adherence rate in the control group, a 0.2 standardized effect size amounts to a minimum detectable effect of 10 percentage points in terms of adherence',\n",
       " 'The chosen sample size of 972 participants for each of the two experiments ensures that we can detect an effect size of about 0.18 at a significance level of 0.05 with a power of 0.8. \\r\\n',\n",
       " 'The analysis for this study will be divided into two main parts. First, we estimate the effect that the different incentives schemes have on enrollment into JKN. This uses the entire sample. Second, we study whether different incentives schemes attract different individuals and differentially affect individuals’ health seeking behavior. To perform this analysis, we compare families which took up across different treatments. This part of the analysis restricts the sample to taker-uppers.\\r\\n\\r\\nAs a result, we perform two sets of power calculations. Power calculations for enrollment use the entire sample and, in particular, the size of groups assigned to each treatment. Given the number of individuals assigned to each group, we calculate a predicted number of taker-uppers for each treatment group based on the enrollment rates that we saw in the previous pilot. We then use these group sizes for all power calculations related to adverse selection or health seeking behavior.\\r\\n\\r\\nAll power calculations calculate MDEs based on control means and standard deviations from the previous pilot. We assume β=0.80 and α=0.05. All MDEs are expressed as fraction of control group standard deviation.\\r\\n\\r\\nOverall, for the Bandung pilot, MDEs for the enrollment regressions are in the order of 0.10 to 0.20 standard deviations, whereas MDEs for the adverse selection regressions are in the order of 0.20 to 0.40 standard deviations.\\r\\n\\r\\nThe tables (uploaded separately) report the assumptions on take-up rates and MDEs for the different treatment arms and main outcomes of interest. Note that these MDEs are lower bounds for the onsite registration treatment and for the half-subsidy and full-subsidy treatment. These treatments are the same in the Medan and in the Bandung pilot, which means that we will be able to pool together the data from the two sites in the analysis.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'With an expected answer rate of 70%, we have a MDE  of 0.23 standard deviation for the comparison between treatment (2) and treatment (3), and for the comparison between treatment (1) and treatment (2). If there is no statistical difference between treatment (1) and (2), we can pool those two treatments and compare them with treatment (3): in this case we would have a MDE of 0.2 standard deviations.\\r\\nThis is a conservative calculation of the MDE, not accounting for the added precision due to stratification on income category and annual fee.',\n",
       " '',\n",
       " '',\n",
       " 'We have chosen to assign about 600 clients to each treatment and control group. We make the following assumptions: standard deviation in each group=0.6, significance level=0.05, power=0.8, population mean of the control group=0, population mean of the treatment group=0.1. The power calculations were done in Stata. The estimated sample size to detect a minimum effect of 0.1 is 1134 (567 observations per group).\\r\\n',\n",
       " 'Please see page 13 of the Market Design Appendix for power size calculations and expected effect size of the price structure treatment.  \\r\\n\\r\\nFor the under-cutting bid treatment, we expect prices to go down by approximately 1,000 CFA.  This is based on the bidding in the second price auctions, together with the fact that the bidders will be encouraged to reduce their prices through the price-undercutting mechanism.  With an effect size of 1,000 CFA, a standard deviation of 5964, and a sample mean of 16,836, this means that the necessary sample size is 282.  We multiply the sample size by 1.9 since the intra-cluster correlation coefficient is 0.03 and clusters have approximately 30 households in order to be conservative (decisions are made at the household, not cluster level). This gives us a sample size requirement of 535 households.\\r\\n\\r\\nWe expect this price reduction of 1,000 CFA on average to increase take-up of mechanical desludging by  0.085 from 0.455 to .555 (.455 was the mean in our data from an earlier survey sampled from the same areas).  Our data from the prior survey shows that the standard deviation for take-up is 0.49.  This means that for power of .8 on take-up, we need a sample size of 197 (To be conservative, we increase the sample by a multiple of 3 because sampling is by neighborhood-cluster of 25-35 households.  However, these clusters are used for logistical ease.  Decisions are made at the household level, and we do not expect high intra-cluster correlation—intracluster correlation in an earlier survey was calculated as .07.  With clusters of size 30, this generates an inflation factor of 3).  \\r\\n\\r\\nOn average about 50% of households get a desludging over the course of a year, with 50% of those who get at least one desludging getting 2 or more desludgings in a year.  We sample 1000 households with the offer of the negotiation treatment in order to get an expected 500 households offered the treatment and actually needing a desludging over the course of the year (with over 1000 desludgings total expected among those households over the year).  \\r\\n',\n",
       " '',\n",
       " 'pwr.anova.test(k=4,f=.2,sig.level=.05,power=.8, n=NULL)\\r\\n\\r\\nBalanced one-way analysis of variance power calculation\\r\\n             k = 4\\r\\n             n = 69.1257\\r\\n             f = 0.2\\r\\n     sig.level = 0.05\\r\\n         power = 0.8\\r\\n\\r\\nNOTE: n is number in each group',\n",
       " 'Power calculations can be seen in section 3.5.1 of \"IGC_FInal-report_cover2.pdf\" targeting 2016 outcome data.  In the final paper, which will include 2017 data pending receipt, results will be reported analyzing results for 2016 (year 1) and 2017 (year 2) both separately and pooled together.',\n",
       " '',\n",
       " '',\n",
       " 'We calculate the minimum detectable effect size (MDES) in standard deviations for an individual-level trial(voting district) with power = 0.8, alpha = 0.05, covariate R2 = 0.5. We calculate MDES for 3,200 subjects, divided into eight arms. For marginal effects, such as message 1 vs the control, the MDES is 0.14. For our main outcome, registration rates, we assume a baseline registration rate in the control of 50% (before registration drives for the 2014 election in Gauteng, 48% of young voters were registered), so the standard deviation is ~0.5. For marginal effects on registration, we can thus detect changes of ~7.00 percentage points. For a comparison of all treatments to the control, the MDES is 0.1058, so we can detect changes of ~5.29 percentage points. For interactions with marginal effects (e.g. message 1 vs the control by gender), the MDE is 9.9 percentage points. For interactions with marginal effects (e.g. all messages vs the control by gender), the MDE is 7.5 percentage points.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We do not have detailed data with which to perform precise power calculations, but we anticipate that the standard deviation of log winsorized spending in category in the month (in Brazilian reais) will be about about 1.  In a comparison of the two treatment groups (~4000 users each), we have ~77% power with alpha=0.05 to detect a change of 0.06 in the variable (a 6% spending change).  In a comparison of one of the treatment groups (~4000 users) to the control group (~1000 users), we have ~81% power with alpha=0.05 to detect a change of 0.1 in the variable (a 10% spending change).',\n",
       " \"Based on DHS data in the rural areas where our study takes place: \\r\\n\\r\\n(1) Baseline level of mCPR: 12%.\\r\\n\\r\\n(2) ICC at the radio station level clusters: 0.013/\\r\\n\\r\\n(3) ICC at the villages level: 0.06.\\r\\n\\r\\n(4) Detectable treatment effect corresponding to 80% power: 6 percentage points increase in mCPR. \\r\\n\\r\\nUsing simulations on Stata, we test the robustness of power to different levels of baseline mCPR, since this level is reported differently by  different sources. We also test the robustness of power to different levels of ICC.\\r\\n\\r\\nAs expected, power is most sensitive to the radio station level ICC, since it's the highest level of randomization, and the level on which  treatment is assigned and administered. Empirical data suggests however that this ICC level is very low in our sample.\\r\\n\\r\\nActual power will be higher than in this exercise because (1) we will stratify, (2) we will have a panel structure and (3) will control for the baseline level of mCPR and other explanatory variables. The ICC level should be lower after controlling for explanatory variables as some of the differences between regions is due to differences in observables such as education). \\r\\n\\r\\nThere is uncertainty over ICC and the baseline level of mCPR and there is a risk that power is lower than we think it is based on these data and simulations. If that is the case we will only be able to pick up a larger MDE.\\r\\n\\r\\n\\r\\nFor the radio distribution treatment, the randomization is done at the household level and the sample only include women without access to a radio at baseline. We calculated that our sample size will provide sufficient statistical power to detect an impact of 5 percentage points (from 22% to 27%) among women without access to a radio at baseline. \\r\\n\",\n",
       " '',\n",
       " 'Based on prior experience with similare measures and educational treatments we anticipate that the effect size will be large. Our group size of 260 participants will therefore be sufficient in order to generate reliable results for an effect size at 0.80 at a significance level of 0.05 \\r\\n\\r\\nAverage mean = 4,79 (on a 1-7 Likert scale)\\r\\nAverage standard deviation = 1.36\\r\\nSmall (0.08 std) = 0.11; required n at effect size 0.80, significance level of 0.05 =  2450\\r\\nMedium (0.16 std) = 0.22; required n at effect size 0.80, significance level of 0.05 =  613\\r\\nLarge (0.25 std) = 0.34; required n at effect size 0.80, significance level of 0.05 =  251',\n",
       " 'Initial investment readiness has a mean of approximately 3 and standard deviation of 0.75 (on a score out of 5). The minimal detectable effect is a 0.18 increase in investment readiness, assuming an autocorrelation of 0.6. This equates to 0.24 standard deviations:\\r\\nsampsi 3 3.18, n1(172) n2(174) sd1(0.75) pre(1) post(1) r01(0.6)',\n",
       " '30',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Using historical statistics provided by BDT on outreach to Medicaid recipients in Philadelphia and Maryland, preliminary power calculations suggest that the minimum detectable effect size is a 2 percentage point change (34%) or less in enrollment when comparing any two treatment arms, assuming conventional 80% power and 95% confidence intervals.  We assume 4 percent of the control group enrolls in SNAP absent any intervention (standard deviation = .2). This effect size is smaller than effects seen in historical program data and in the literature for similar outreach interventions. \\r\\n\\r\\n\\r\\nUsing the same assumptions noted above, we estimate power to detect differences between treatment arms in average characteristics of those who apply and/or enroll in SNAP. Instead of specifying particular characteristics, we explore power to detect percentage point changes in a standard indicator that half of the control group is assumed to display (e.g. has less than median income). Thus, by construction, the standard deviation of the outcome is .5 for the control group. We find that for comparison of the High Touch and Control groups we are powered to minimum effect sizes of 8.3 percentage points, and for comparison of other any other two study arms we are powered to detect less than 16 percentage point differences. In light of the few studies that examine similar questions average enrollee characteristics, this study appears sufficiently powered to detect meaningful differences in characteristics.  \\r\\n',\n",
       " \"Minimum detectable effects are estimated for a 5 percent level of significance and 80 percent power level. The computations take into account clustering effects at the classroom level and at the school level, and use plausible values for the intra-class correlation coefficients of 0.1 at the classroom level of 0.3 at the school level. With 100 high schools each including two treated/two control 10th grade classes of 30 students (of whom 50 percent are females), and one treated/one control 12th grade classes (of whom 40 percent are female), we estimate a minimal detectable effect size (MDES) (without controlling for covariates) of approximately 10 percent of a standard deviation for 10th grade students and of approximately 14 percent of a standard deviation for 12th grade students. The corresponding MDESs for the subsample of female students are 11 percent and 16 percent respectively.\\r\\n\\r\\nIn the absence of baseline estimates for our outcomes measures of students' perceptions towards science and of attitudes towards women in science, we restrict our computation of minimum detectable effects in natural units to the MDEs for the probability of choosing a science major in the year following the intervention. The MDE for the probability that a 10th grade female students enrolls in a science major in 11th grade is approximately 5 percentage point from a baseline of about 33 percent, which represents a 15 percent increase. This implies that we should be able to detect a treatment effect corresponding to three female students in every two treated classes switching from a non-science to a science major as a result of the intervention. The MDE for the probability that a 12th grade female students enrolls in a undergraduate program with a science major is approximately 7 percentage points from a baseline of about 28 percent, which represents a 25 percent increase This implies that we should be able to detect a treatment effect corresponding to three female students in every four treated classes switching from a non-science to a science major as a result of the intervention.\",\n",
       " 'Using historical data from the electronic medical record at Mount Sinai health system spanning January 1st, 2012 to December 31st, 2013, we performed power calculations by: repeatedly simulating data under an assumed model of the effects of CDS on targeted high-cost (HC) scans, estimating a statistical model on the simulated data, and computing the fraction of simulations in which we were able to reject the null hypothesis of no effect. \\r\\n\\r\\nOur review of observational studies finds that when CDS was implemented in comparable outpatient settings for MR and CT scans, the roll-out of CDS correlated with a 20 to 30% reduction in high cost scan volume (Blackmore et al., 2011; Ip et al., 2014, 2013; Solberg et al., 2010). We therefore examined whether the study was powered to detect a 20% reduction in targeted high cost scans. After 1,000 simulations, we found 80.0% power to detect a 19.7% reduction in our primary outcome, assuming a 95% confidence interval: our minimum detectable effect size is - 4.896 targeted high cost scans associated with visiting provider after 12 months (compared to a control group mean of 24.883 targeted high cost scans per provider). Our average standard error across the 1,000 simulations was 1.723 targeted high cost scans.\\r\\n',\n",
       " 'Cohens` d between 0.15 and 0.25 (financial behavior) (ICC unknown as of today)',\n",
       " '0.23-0.32 Standard Deviations (Bounded by conservative and liberal assumptions)',\n",
       " 'We anticipate that our job search interventions will have impacts on a number of job‐search behaviors, type of employment, duration of unemployment spells, and wages. However, finding full‐time,permanent and formal employment in Addis Ababa is challenging, and thus a change in this single binary outcome will likely be the most challenging impact to detect. Our study has been designed and the sample size chosen with the intention of having adequate power to detect this effect. Our power estimates should therefore be understood as the most conservative, lower bound estimates of the power of our design.\\r\\n\\r\\nWe calculate power through detailed simulation designs (corroborated with analytical results from comparable and simpler designs, run in the software package “Optimal Design”) in the presence of large spillovers (contamination) and possibly high intra‐cluster correlation (ICC) of up to 30%. ICC’s are introduced through the simulation of a cluster specific employment shock. In these “worst case scenarios”, we are able to detect a 5 ppt increase in the probability of employment on a baseline probability of 10% more than 80% of the time, with the size of the test at the 5% significance level. It should be noted that in the binary outcomes framework this effect is equivalent to a one sixth (1/6) standard deviation (sd) standardized effect size, much smaller than the usual rule of thumb of 0.2 sds suggested by Cohen (1998).\\r\\n\\r\\nThere are numerous ways in which we expect to have more power by looking at various other intermediate outcomes, or more easily influenced job‐market outcomes. Recall that the binary model estimates above could be estimated at each period in our high frequency data set, giving us the power to estimate detailed impact trajectories. However if we wanted to look at average outcomes over time we might have considerably more power from pooling all post‐treatment observations. As argued by McKenzie (2011), this is especially useful when outcomes of interest are measured with error or are weakly correlated over time, which could certainly be the case for temporary employment outcomes. When employment is relatively informal, wages and hours worked could be irregular and difficult to recall. At a single snapshot, treated individuals might not be significantly more likely to be employed, but the cumulative effect averaged over a few months might be significantly different.',\n",
       " '',\n",
       " '',\n",
       " 'The sample size of 1,500 firms has been calculated to meet two goals: \\r\\n- High statistical power to detect small changes in E-filing;\\r\\n- Sufficient statistical power to analyze the effect of e-filing on tax compliance costs, firm perception of corruption, behaviors and performances, assuming that the program has sufficient effect on e-filing take up (i.e., e-filing increases at least by 50 percentage points).\\r\\n\\r\\nUsing baseline data on some important outcomes, the power calculation gives the following results for the following outcomes:\\r\\n - Total monthly amount of time spent during in visits to tax committee: mean at baseline : 172 minutes, SD= 73,3, minimum detectable effect when comparing group A and control: 2.9 min (assuming 50pp difference in take up rates); and 5.65 mins when comparing group B and control (assuming a 25% difference in take up). \\r\\n - Direct question on corruption faced by other firms: mean at baseline : 0.18 minutes, SD= 0.38, minimum detectable effect when comparing group A and control: 0.21pp (assuming 50pp difference in take up rates); and 0.41pp when comparing group B and control (assuming a 25% difference in take up). \\r\\n - Indirect question on corruption faced by other firms: mean at baseline : 0.49 minutes, SD= 0.5, minimum detectable effect when comparing group A and control: 0.24pp (assuming 50pp difference in take up rates); and 0.47pp when comparing group B and control (assuming a 25% difference in take up). \\r\\n\\r\\nActual power will be greater once we allow for i) the use of randomization strata fixed effects (Bruhn and McKenzie, 2009); and ii) control for the lagged dependent variable (McKenzie, 2012). As a result, we are confident that the study has sufficient power as implemented to detect effects that are of economically meaningful size',\n",
       " '',\n",
       " 'Grit Test, Big Five Personality Inventory, Study parameters:\\r\\n\\r\\nStudy parameters:\\r\\n\\r\\n        alpha =    0.0500\\r\\n        power =    0.8000\\r\\n            N =       300\\r\\n  N per group =       150\\r\\n           m1 =    3.2000\\r\\n           sd =    0.6000\\r\\n\\r\\nEstimated effect size and experimental-group mean:\\r\\n\\r\\n        delta =    0.1947\\r\\n           m2 =    3.3947\\r\\n\\r\\n\\r\\ni.e., the minimum detectable effect size is 1/3 standard deviations.\\r\\n\\r\\nLocus Control Test (which uses a different scale) will have:\\r\\n\\r\\nStudy parameters:\\r\\n\\r\\n        alpha =    0.0500\\r\\n        power =    0.8000\\r\\n            N =       300\\r\\n  N per group =       150\\r\\n           m1 =   65.0000\\r\\n           sd =   11.0000\\r\\n\\r\\nEstimated effect size and experimental-group mean:\\r\\n\\r\\n        delta =    3.5700\\r\\n           m2 =   68.5700\\r\\n\\r\\ni.e., the minimum detectable effect size is 1/3 standard deviations.\\r\\n',\n",
       " '',\n",
       " 'Since we do not have exact efficiency measures for the specific artisans included in this project, we just use a baseline efficiency measure of 50 per cent and expect a 5 percentage points increase in productivity with a standard deviation of 15 per cent. With an intra-cluster correlation of 5 per cent and average number of artisans per cluster (sub-centre) of 25, we get the required number of clusters of 50 in total (25 sub-centres in control and 25 in treatment group) to ensure the required statistical power to identify the impact of the program with sufficient precision.',\n",
       " \"We used the most recent consumption data from November 2014 to April 2015 from the City of Cape Town’s municipal database to conduct our power calculations. For the power calculations. we chose to use the months for which our study will be conducted in order to allow for seasonality effects as consumption increases in the summer months.  We matched the municipal data with the list of contract accounts we received from the City's printers. We removed those consuming 6 kiloliters/month or below, as well as the 95th percentile to control for outliers due to measurement errors. We then calculated mean consumption over the treatment period last year (December-April).  \\r\\n\\r\\nWe include two power calculations: one where we look at the mean consumption over the treatment period with an unbalanced panel and one where we use the balanced panel. \\r\\n\\r\\nI) With our sample size, we are able to detect a 1.5% change in means per treatment. Assuming our standard deviation is 11.08, our mean is 21.47 kiloliters/month, alpha level is 0.05 and power of .8, the 1.5% detectable difference in means would be able to pick up an effect if the consumption decreases to 21.15 kiloliters/month (a difference of 0.32 kiloliters/month) with a minimum sample size of  18,579 per arm.  We have tried various strategies for the power calculations, yet the strategy is not sensitive to changes in the detectable effect size. \\r\\n\\r\\nWe assume there will be high variability in the effect size across income groups. We will use property values and suburb as covariates in our regression models to decrease the variance.  \\r\\n\\r\\nII) Our power calculations are robust when using the balanced sample (those whose consumption we observe in each month)\\r\\n\\r\\nWith our sample size, we are able to detect a 1.5% change in means per treatment. Assuming our standard deviation is 9.5, our mean is 21.1 kiloliters/month, alpha level is 0.05 and power of .8, a 1.5% detectable difference in means would be able to pick up an effect if the consumption decreases to 20.8 kiloliters/month (a difference of 0.31 kiloliters/month) with a sample size of  14,104 households per arm.  \\r\\n\",\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Randomization for the original trial (AEARCTR-0000889) has already taken place.\\r\\n\\r\\nFor the replication study, the text here is pasted from the original trial (AEARCTR-0000889) but updates the sample sizes for the replication study:\\r\\nWe do not have detailed data with which to perform precise power calculations, but we anticipate that the standard deviation of log winsorized spending in category in the month (in Brazilian reais) will be about about 1. In a comparison of the two treatment groups (~12000 users each), we have ~87% power with alpha=0.05 to detect a change of 0.04 in the variable (a 4% spending change). In a comparison of one of the treatment groups (~12000 users) to the control group (~3000 users), we have ~84% power with alpha=0.05 to detect a change of 0.06 in the variable (a 6% spending change).',\n",
       " '',\n",
       " '',\n",
       " 'The existing literature suggests a response rate around 1%. \\r\\n\\r\\nUnder the null hypothesis of response rate equal to 0%, we compute that a 1% response rate will generate a t-statistics of 10.5 if the sample size is 11000. \\r\\n\\r\\nUnder the null hypothesis of response rate equal to 0.5%, we compute that a 1% response rate will generate a t-statistics of 5.27 if the sample size is 11000. \\r\\n\\r\\nIf we compare two samples with response rate 1% and 2%, the t-statistics of their mean comparison will be 6.11 if the sample size is 11000 in both samples.  ',\n",
       " 'Our sample size is limited by the number of farmer groups that will be treated and the number of members of these groups. The project will build around 42 irrigation schemes. However the financial intervention will be provided to an additional 22 groups. Given these parameters on cluster size and the number of observations within each cluster, we calculate the minimum detectable effects (MDEs) assuming a power of 0.8 and an alpha of 0.1. For both evaluations the main outcome indicator is yield. Our sampling frame will be based on the random selection of 25 households per scheme. To calculate the MDE of household Maize revenue per hectare (MZN/ha), we take the mean (1051), standard deviations (1186) and ICC (0.10) of yields from the Smallholders Survey collected in an adjacent region of Mozambique (Kondylis, Mueller, and Zhu, 2015). With a baseline and one follow up for yield outcomes, we should be able to detect a 18.7% increase in revenue the financial literacy intervention (64 clusters) and 23.8% in the water monitoring intervention (42 clusters). For the financial literacy intervention, the main outcome indicator of interest is proportion of farmers that meet their saving target after one year. We will have farmer level data on savings contributions for each of the on average 40 members of the farmers groups. We assume currently none of the farmers contribute to a common savings pool. The MDE ranges from 0.08 with an ICC of 0.05 to 0.13 with an ICC of 0.15. ',\n",
       " '',\n",
       " 'We assume that the control group orders an average of 1,400 calories at dinner, with a SD of 500.  We assume that the treatment effect of providing calorie information is to reduce calories ordered by 5.8% (this is the effect found by Bollinger et al., (2011).  Setting a 5% threshold for statistical significance, to have 80% power we need a sample size of 1,196.',\n",
       " 'Indicators based on the Daily Court Returns Template:\\r\\nPower calculations have revealed that 58 courts per treatment arm are sufficient to achieve power to 80%. Intra-cluster correlation is not applicable here as we have 1 observation per court. We report 2 scenarios for the correlation between waves (which we expect to be quite high given the monthly nature of the data). We use as benchmark indicator the case clearance rate. Other inputs for the sample power calculation are: 5% significance level, power 80%, baseline probability: 60% (based on data from Sep 2015 DCRT), 6 baseline waves, and 12 follow up waves. Power calculations have confirmed that 58 courts per treatment arm should ensure acceptable level of statistical power.\\r\\n\\r\\nIndicators based on court user satisfaction and employee engagement survey:\\r\\nPower calculations have revealed that 58 courts per treatment arm are sufficient to achieve power to 80% under different levels of the intra-cluster correlation (rho). We use as benchmark indicator the probability of court users that report are satisfied with the court service. Other inputs for the sample power calculation are: 5% significance level, power 80%, baseline probability: 66% (based on data from the baseline), 1 baseline wave, and 2 follow up waves, correlation between waves: 0.6, and that 24 respondents  will be interviewed in each court (as it was indeed the case for the baseline survey already conducted and will be for the follow ups). \\r\\n',\n",
       " 'Ex ante sample size calculations recommended 132 observations per treatment.',\n",
       " '',\n",
       " 'From a cost-benefit analysis it was determined that the Minimum Detectable Effect required for maintaining positive returns over the change in the high school scholarship recipient ranged from 1.8 to 2.8; thus, we are aiming for a MDE of 2-3 percentage points. For MDE calculations we are assuming (1) a yearly discount rate of 12%, (2) as income base the 2012 national minimum wage according to the statistics national institute, (3) high school level educational yearly returns of 5 and 8%, and (4) a 57 years worklife (assuming that the youth starts labor activities at 18 and retires at 65). \\r\\n\\r\\nThe power calculations are based on the dropout rate indicator, as this is our main outcome. The prevalence for dropout rates cursing 2nd and 3rd level of high school in urban areas –where the majority of the pilot eligible schools are concentrated- is 35.10% and 30.82%, respectively. Power estimations suggest a school sample of 610 for female strata and 625 for male strata in 3rd grade of high school (this is the most demanding grade in terms of sample size) in order to get a MDE of 0.03. Based on costs, operation capacity and execution schedule, we selected a sample of 625 treatment and 625 control schools. With this double stratification, disaggregated analysis over the course level and gender can be conducted. The parameters for these calculations are the following: power level (1-β)=80%, confidence level (1-α)=95%, intracluster correlation (ICC=0.133), dropout rate (32.51). \\r\\n\\r\\n',\n",
       " 'Our sample size is limited by the number of communities that will be treated and the number of farmers that will be surveyed in each of the communities. The project will build around 56 irrigation schemes. In each of the communities, we will survey a random sample of in total of 25 farmers, resulting in a total sample of 1,400. Given these parameters on cluster size and the number of observations within each cluster, we calculate the minimum detectable effects (MDEs) assuming a power of 0.8 and an alpha of 0.1. Where there is no information available, we calculate them under potential scenarios of intra-cluster correlation (ICC). Below we present the power calculations for the main indicator directly targeted by the intervention: proportion of small farmers in the eligible area that are selected. The final outcome indicator of interest is yield. \\r\\n\\r\\nProportion of small farmers\\r\\nThe main outcome indicator of interest is proportion of small farmers in the eligible area that are included in the scheme. We will select a random sample of 25 farmers within the eligible area to determine the distribution of cultivated land in the area. From the TIA data we see that in the region around 75% of farmers cultivate 2 or less hectares. We will compare the probabilities of these 19 small farmers to be selected under the two different selection protocols. \\r\\n\\r\\nWithout reliable information on ICC we report the MDEs under a wide range of parameters.  Departing from a scenario where under model B half of the small farmers are included, which yields the most conservative results, the MDE of an increase in small farmers being included ranges from 0.11 -0.31.\\r\\n\\r\\nYield\\r\\n\\r\\nOur sampling frame for yield will be based on the on average 15 households included in the scheme. To calculate the MDE on yield we use data from a Smallholders Survey collected in an adjacent region of Mozambique (Kondylis, Mueller, and Zhu, 2015). Mean maize revenue per hectare (MZN/ha) is 1051, standard deviation 1186 and ICC 0.10. With a baseline and one follow up for yield outcomes we should be able to detect a 20.1% increase in revenue.\\r\\n',\n",
       " 'See attached.',\n",
       " '',\n",
       " 'We propose a set of power calculations based on rough assumptions about the school enrollment rate and distribution of students across grade levels. We assume that the enrollment rate among eligible SPES applicants in the academic year following their program participation is 85%. With a conservative response rate of 70%, a total sample size of 8,000 applicants, with 4,000 assigned to the treatment group and 4,000 to the control group will thus enable us to detect an average 2.9 percentage-point increase in enrollment with 90% power. For subgroups of interest, such as first- and second-year college students, we will have sufficient power to detect an average 5.0 percentage-point increase in enrollment with 90% power, assuming the subgroup composes one-third of our total sample.',\n",
       " '',\n",
       " 'Sample size calculations (for individual randomisation designs) are reported below in 3 scenarios using weight loss in lbs as a main outcome variable. The Baseline, Moderate and High weight loss scenarios relate to there being a 1lb, 1.5lb, and 2lb per week difference between control and treatment groups. Each specifies 0.9 power and a two-sided test. I also test the effects of low or high standard deviation assumptions, using 2lb and 3lb respectively. \\r\\n\\r\\nBaseline \\r\\n(1 lb weight loss difference)\\r\\n44 (low SD 1 lb)\\r\\n190 (med SD 2 lbs)\\r\\n380 (high SD 3 lbs)\\r\\n\\r\\nModerate \\r\\n(1.5 lbs weight loss difference)\\r\\n20\\r\\n76\\r\\n190\\r\\n\\r\\nHigh weight loss \\r\\n(2 lbs weight loss difference)\\r\\n12\\r\\n44\\r\\n96\\r\\n\\r\\nCalculations suggest a sample size of 190 is needed in an individual randomised design in the baseline weight loss scenario with moderate standard deviation across the participants. \\r\\n\\r\\nThese sample size calculations carry a degree of uncertainty, as they require estimates of the mean and standard deviation of weight loss for which data is not readily available; and they assume a full sample and no problematic attrition.\\r\\n',\n",
       " 'The Cash Transfer effects will be determined by measuring differences between the 13 control communes and the 38 beneficiary communes. We will sample 13 communes with 5 village per commune and 16 households per village in the control population. For any of the treatment arms, we will sample 74 villages, with 5 Mother Leader groups per village and 4 households per Mother Leader group. The MDE we calculate for the cash effects is 0.3 standard deviations for the primary outcomes, with power of 0.7 and significance of 10%. The MDE we calculate for the nudge and ML interventions is 0.1762 standard deviations for the primary outcomes, with power of 0.8 and significance at 5%.\\r\\n\\r\\nThe calculations above on Unit Level 2 also control for a fokontany-level covariate that is expected to explain a conservative proportion of the variance (9-10%) among Mother Leader groups and also among Households. The Unit Level 1 calculations also control for a commune-level covariate that is expected to explain a conservative proportion of the variance (10%) among fokontany and also among Households. \\r\\n\\r\\nGiven current lack of data, we opt to use the default/norm estimate of 0.1 ICC. We will be better able to calculate ICC with the completion of data collection for the baseline survey.',\n",
       " 'We have assumed a power of 80% and a significance level of 5% for each test. We have also assumed perfect compliance, which is what we hope to come close to. However, note that a small degree of non-compliance will not hurt power much, which is more sensitive to the number of clusters/communities than to the number of individuals within the cluster. We will make every effort to avoid non-compliance so as to avoid introducing any bias. On this basis and our study design, we will be able to detect improvements larger than 21%-32% of a standard score (for cognition or other similar outcomes – for boys and girls taken together) for any pairwise comparison with the control. For each gender separately the minimum detectable effect lies between 28% and 36% of a standard score.\\r\\nWe have presented MDEs on the basis of a low spatial correlation (0.04), which is the number we found in the rural communities of Colombia (where members of the team implemented a home-visiting intervention) and on the basis of a relatively high spatial correlation of 0.3. Moreover, we have not taken into account that in estimating the impacts we will include baseline variables in the regressions, which can reduce the noise substantially and therefore increase precision. Thus, we view the minimum detectable effects as an upper bound of what we will achieve: in practice we expect to be able to detect even smaller effects.\\r\\n',\n",
       " '',\n",
       " '',\n",
       " 'Nairobi: Data from the Nairobi Cross-Sectional Slum Survey were used to obtain baseline estimates for childbearing and education in Nairobi. Assuming that 15.4% of girls in the violence prevention only arm would have given birth by endline: we would detect a statistically significant difference of 6.3 percentage points between the violence prevention only arm and each of the other three arms. Assuming a correlation coefficient of 0.33, we would detect a statistically significant difference of 0.55 grade of schooling between any two arms. \\r\\n\\r\\nWajir: The estimate of the intra-cluster correlation (ICC) and the baseline estimates for childbearing and education were based on data on the Northeastern Province from the 2008/09 Kenya Demographic and Health Survey. Assuming that 17.6% of girls in the violence prevention only arm would have given birth by endline, we would detect a statistically significant difference of 6.9 percentage points between the violence prevention only arm and each of the other three arms. Assuming a correlation coefficient of 0.26, we would detect a statistically significant difference of 0.49 grade of schooling between any two arms. \\r\\n\\r\\n',\n",
       " '',\n",
       " '',\n",
       " 'Due to the complex design of the study, which layers a randomized saturation design on top of endogenous gateways of varying sizes (different numbers of campaign eligible villages in each parish), it was not feasible to calculate MDEs analytically. Instead, we simulated many different effect sizes and calculated the probability of detecting an effect of each magnitude.\\r\\n\\r\\nWe used Afrobarometer data from Uganda on prior experiences with vote selling as our source for data. We first calculated district averages in vote buying experience from Afrobarometer. Subsequently, we calculated differences in village averages from the district mean for each village in the Afrobarometer data.\\r\\n\\r\\nThen, for each village in our data, we simulated its degree of vote selling by assigning it the relevant district average (if available) or a randomly selected district average (held constant for all villages in the same district) plus a village-level shock drawn randomly from the distribution of calculated differences in village averages. All draws were with replacement.\\r\\n\\r\\nThus, for control villages, their average degree of vote selling was: (district average level + random village deviation), censored below at 0 and above at 1. For treatment villages, we added a set of effects for being treated in terms of a direct treatment effect and a slope effect that rises with the percent of voters in the same parish who are subject to the treatment. For spillover villages - villages in parishes where at least one village is treated, but which are not themselves treated - we added a direct spillover effect plus a slope effect that rises with the percent of voters in the same parish who are subject to the treatment.\\r\\n\\r\\nThen we estimated an ITT equation with an indicator for being a treatment village and an indicator for being a spillover village plus a set of stratum FEs. We clustered at the parish level. We are powered at approximately 80% to detect an ITT direct effect of approximately -0.15 standard deviations and an ITT spillover slope effect (holding the intercept at 0) of about 0.35 standard deviations (that is to say, an effect that is 0 when there is 0% saturation and which rises linearly to 0.35 standard deviations as the percent of voters in a parish who are treated rises to 100%). Since average potential saturation is 45% and average saturation conditional on any treatment is 39%, this equates to a spillover ITT effect of 0.137 standard deviations. Previous studies, e.g. Vicente (2014) have found effects of 0.4 standard deviations, so we feel we are well-powered to measure relevant effects.\\r\\n\\r\\nWe expect that there will be several important differences between our power calculations and the end results. First, our measured outcomes will differ from those used by Afrobarometer. Second, the number of individuals sampled per village differs from Afrobarometer. Third, the assignment of additional spillover villages will differ slightly from the process used for power calculations. ',\n",
       " 'To determine a sufficient sample size we assume a significance level of .05, a power of 0.8, a cluster size of 15 children under 3 and ICC of 0.15',\n",
       " 'N/A',\n",
       " '',\n",
       " '',\n",
       " 'Please see attached analysis plan',\n",
       " 'The trial design provides adequate statistical power. In a very conservative setting assuming an unrealistically high pooled standard deviation (4.2) drawn from an extreme-outcome pre-sample, a two-sided t-test, α=0.05, and power against alternative hypothesis = 0.8, results suggest that the minimum required sample size to detect an effect size of 0.2 (comparison of groups 6 months after the intervention) is 321, meaning 107 for the treatment group and 214 for the control group. Given a sample size of 360 (conservative estimation of sample size reached at the time the final analysis for the RCT is planned) and an allocation ratio of ventures receiving tactical coaching to those of the control group of 1:2, the minimum detectable effect size (MDES) is 0.18.',\n",
       " 'With randomization at the household level and handwashing outcomes at the household-day level, we conduct our power calculation using households as our cluster unit and household-days as the number of observations per cluster. We calculate power using pilot results on number of evening presses (5pm and later) per day.\\r\\n\\r\\nMean: 1.6\\r\\nSD: 4.0\\r\\nICC: 0.04 (but overestimate at 0.15)\\r\\nPower: 0.8\\r\\nSize: 0.95\\r\\n\\r\\nTo detect a standardized effect size of 0.15 with 80% power, we require 1670 household-day observations per treatment arm. For a large standardized effect size of 0.25, we require 600 household-day observations per treatment arm.\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The number of clusters and sample size of adolescent girls needed for the RCD is determined by estimates of minimally detectable effect sizes for the representative set of impact indicators given a statistical power (.80), alpha (.05), intra-class correlation, and effect size variability.  Estimates indicate that 40 communities per arm of the study are required with a minimum of 25 girls per cluster at baseline. Thus, a four-arm study (control and three experimental or program arms) require implementing AGEP in 120 communities and conducting the research in 160 communities. Estimates of cluster number and sample sizes were conducted for different baseline age groups (10-14, 10-16 and 10-19) and scenarios for the number of study arms. Optimal Design Software Version 3.0 for a multi-site randomized trial was used to generate cluster number and sample sizes requirements for the AGEP design. ',\n",
       " 'N/A',\n",
       " 'n/a',\n",
       " '',\n",
       " '',\n",
       " 'Assuming a power of 80%, a significance level of 5% for our estimates, perfect compliance, no attrition, and an intra-cluster correlation (ICC) of 0.05, our sample size was designed to allow us to identify minimum detectable effects of 0.15 SD on the ASQ-3. \\r\\n\\r\\nThe intra-cluster correlation (ICC) from ASQ-3 at baseline, controlling for household wealth and demographics, was 0.08. Following the same assumptions as above and using this updated ICC, we estimated that the subsample of 1,492 children who will be assessed on the Bayley-III, will allow us to identify a minimum detectable effect of 0.22 SD on the Bayley-III (or 0.229 SE assuming 7% attrition). \\r\\n',\n",
       " 'To determine the sample size for our experiment, we focus on three core outcome variables: 1) technology adoption (purchase of lamp) 2) educational achievement (test scores) and 3) female employment. Based on data provided by GiveWatts and test score data from the World Bank Service Delivery Initiative in Tanzania (Bold, Gauthier, Maestad, Svensson, 2011) and following a protocol requiring 80\\\\% power of detecting a significant difference at the two-sided 10\\\\% level, we find that sample of 1800 households would detect a 0.25 standard deviation increase in test scores and female employment and a 0.1 standard deviation increase in technology adoption with 80\\\\% power.\\r\\n\\r\\nThe sample is therefore set to 1800 households. For the administrative reasons set out above, we will conduct a stratified randomized controlled trial, by first randomly selecting 60 schools eligible for the GiveWatts programme, randomizing sets of subsidies between them and then randomly selecting 30 households within the school to be allocated -- again randomly -- a subsidy level for the solar lamp.\\r\\n\\r\\nGiven that there is the possibility of lamp sharing and thus potential spill-over effects in outcomes we decided to add an additional 10 schools to our sample that would serve as pure control schools (without any lamp subsidies). From each of the pure control schools we sampled 30 households. Thus the final study sample consists of 2100 households.',\n",
       " '',\n",
       " 'Minimum detectable effect size is 0.25 of a standard deviation.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Adherence to Checklist Standards (score/max score, %) /\\tMDE= (0.27 SD; 25%)\\r\\nAdherence to IPC practices (safe action/indication) (%) /  MDE= (0.22 SD, 27%)\\r\\nAdherence to Checklist of essential recommended care (%) / MDE=(0.22 SD, 27%) - (subject to budget availability)\\r\\nPrice per Visit (KES) / MDE = (0.27 SD, 20%)\\r\\nQuantity (Monthly patient flow) (Outpatients) /  MDE (0.27 SD, 26%)',\n",
       " '',\n",
       " '',\n",
       " 'We report power calculations for one of the main outcomes: the probability that a worker-firm match generates a job offer to the worker. \\r\\n\\r\\nWe can divide the 1230 worker-firm matches into two groups: a first group of matches where the matched trainee has non-cognitive skills equal or greater than the median trainee, and a second group where the matched trainee has lower than median non-cognitive skills. Based on the actual data from the baseline skills assessments, the sample sizes in each group are the following:\\r\\n\\r\\n(i) 268 Control matches where the matched trainee has lower than median skills\\r\\n(ii) 346 Control matches where the matched trainee has skills that are equal or greater than the median\\r\\n(iii) 264 Treatment matches where the matched trainee has lower than median skills\\r\\n(iv) 352 Treatment matches where the matched trainee has skills that are equal or greater than the median\\r\\n\\r\\nWe expect treatment effects to be heterogeneous, given the nature of the treatment. In particular, we expect the treatment to have a positive impact of the job interview outcomes of trainees that have skills that are equal or higher than the median, and a negative effect on trainees with lower than median skills. Therefore, the relevant comparisons in the analysis are between groups (i) and (iii) on the one hand, and between groups (ii) and (iv) on the other.\\r\\n\\r\\nFor the purpose of power calculations, we consider the minimum detectable impact of the treatment on the probability that a trainee with skills equal or greater than the median receives a job offer. So the comparison is between matches in group (ii) and group (iv) above. Table 1 in the Supporting Documents and Materials section reports the power calculations, and shows how the minimum detectable effect size varies as a function of the proportion of Control matches ending up in a job offer.',\n",
       " '',\n",
       " 'We use Optimal Design Software for power calculations, as well as our own calculation that allows us to include additional details on the design. We originally assumed an intra-cluster correlation of 0.1 (that is the intra-cluster correlation for value added) and that 30% of the variation could be explained by baseline test scores and other covariates (such as age, gender, school and teacher characteristics) and district fix effects. Our main outcomes (the effect of each treatment arm) have a total of 120 clusters (60 controls schools and 60 treatment schools). Additionally, the difference between the treatment effects in both treatment arms also has 120 clusters (60 \"gains\" schools and 60 \"levels\" schools). With 120 clusters and a significance level of 5% we have: a minimum detectable effect size of 0.17 with power of 80%, a minimum detectable effect size of 0.2 with power of 90%, and a minimum detectable effect size of 0.22 with power of 95%. \\r\\n\\r\\nIf we assume a higher intra-cluster correlation (0.3) with 120 clusters and a significance level of 5% we have: a minimum detectable effect size of 0.28 with power of 80%, a minimum detectable effect size of 0.33 with power of 90%, and a minimum detectable effect size of 0.37 with power of 95%.  \\r\\n\\r\\nHowever, based on data from these same schools in previous years, we know that the intra-cluster correlation is 0.15 for Kiswahili, 0.06 for English, and 0.14 for Math. The proportion of the variation that can be explained by baseline test scores and other covariates (such as age, gender, school and teacher characteristics) and district fix effects is 40% for Kiswahili, 36% for English, and 37% for Math. Using the most conservative estimates (0.15 intra-cluster correlation and 36% of the variance explained by baseline characteristics) we have the following numbers. With 120 clusters and a significance level of 5% we have: a minimum detectable effect size of 0.2 with power of 80%, a minimum detectable effect size of 0.24 with power of 90%, and a minimum detectable effect size of 0.26 with power of 95%. \\r\\n\\r\\nSee the attached document for more detailed calculations.\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The agronomy survey suggests an increase in yields from about 4.5 tons/ha to 14 tons/ha. Power calculations to detect ¼ th of such an effect suggests we need about 94 observations in each treatment arm. We therefor propose to run an experiment that involves about 200 observations in a 2x2 factorial design. In such a design, about 100 households will receive information on how to select the best planting materials from the previous harvest. About 100 households will receive information on how to store and handle planting materials between the last harvest and the next planting period. This will be done in such a way that there are 50 households that receive both types of information and 50 households that do not receive any information at all (a control group). ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'no se tienen para el momento de este registro ',\n",
       " '',\n",
       " '',\n",
       " 'The primary outcome of interest for the two randomized is reported expenditure on betting.  Data from earlier piloting showed that the mean weekly expenditure on betting among respondents was 2 USD while the observed standard deviation was 3USD.  For these treatments 50% of subjects are assigned to treatment and 50% assigned to control. With power of 0.9 and a false detection rate of 5% (alpha = 0.05), the minimum detectable effect (MDE) size will depend on how much other covariates or fixed effects are able to explain variation of betting intensity.  If, conservatively, they only explain 10% of variation in reported betting expenditures the MDE will equal 0.235 standard deviations or $0.70.  If we are able to explain up to 50% of variation in betting, the MDE will fall to 0.175 standard deviations or $0.53 in weekly betting expenditures.\\r\\n\\r\\nFor the prime experiments the primary outcome variable of interest will be the revealed measure of demand for betting recorded during the endline.  Participants will be allowed to “purchase” up to four betting tickets, or can keep cash, or any mix of cash and betting.  These primes will divide the full study population into smaller groups with approximately 400 respondents for treatment and control (200 each).   If mean number of desired betting tickets is 2 and standard deviation is 2 then the range of MDE standard deviations will be 0.247-0.332 or mean difference of 0.495-0.664 betting tickets demanded.\\r\\n',\n",
       " '',\n",
       " '',\n",
       " 'MDE for outcomes measured in standard deviations (test size 5%, power 80%, intra-cluster correlation=0.2): 0.2 s.d.\\r\\nMDE for outcomes measured in proportions (test size 5%, power 80%, intra-cluster correlation=0.2): 0.1 (10 percentage points)\\r\\n',\n",
       " 'Used optimal design software.',\n",
       " '',\n",
       " 'Power calculations for the anthropometric outcomes indicate that 47 grams and 2.6 millimeters could be detected with a 70% power.\\r\\n\\r\\nAssumptions used for this calculations include: (i) sample size within cluster of 4, (ii) number of blocks (formed based on segregation variables) equal to 5, (iii) average number of clusters per block of 156, (iv) intra-class correlation equal to 0.108 and (v) an R-squared of 0.1. ',\n",
       " '',\n",
       " 'We have performed power calculations as part of the preparation for the Medicaid waiver and pay-for-success contract specifications. Our power analysis is based on expected effect sizes suggested by previous NFP trials and NFP data on the target population.  We use the effect sizes of a 20% drop in pre-term birth (with a baseline mean rate of preterm birth of .12), 18% reduction in birth spacing of less than 2 years (baseline mean of .14), and a 13% reduction in child injury (baseline mean of .18); we assume that 95% or more of women randomized into the treatment group receive any NFP services and at most 5% of the control group that receives a home visiting program that has as much impact as NFP. NFP plans to serve 4,000 families in South Carolina between January 2016 and January 2020.  Our power analysis suggests that with 4,000 families in the treatment group, a 2:1 T:C ratio (or 2,000 control group families) will achieve 80% or higher chance of detecting statistically significant effects on two out of the three primary outcomes, with the greatest power to detect child injury and the lowest to detect pre-term birth.  We anticipate having substantially greater power for many of the additional outcomes that we will assess for the broader evaluation (e.g. utilization of government benefits or the mother’s subsequent arrests).  We will further develop our plans for these measures during the pilot period.',\n",
       " 'The empirical findings provided support for the conceptual framework, the findings suggest that the average effect of population density over CO2 emissions, when the population density change across time and between countries in LICA, increases by 1%, CO2 emissions increase by about 0.196% and CO2 emissions reduce by about 0.19% and 0.22% for LIMCA UICA respectively, holding all other predictors constant. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Given the available sample, power calculations suggest that we will be able to detect increases of 4 percentage points in child enrollment and decreases of 3 and 8 percentage points for child marriage and wage work, respectively. These minimum detectable effects sizes are calculated based on 0.90 power, a one-sided hypothesis test conducted with a p-value of .05, and assumed intraclass correlations of 0.06, 0.00, and 0.10 for child enrollment, child marriage and wage work, respectively. We note that intraclass correlation values are calculated based on existing pilot data to the extent possible. Based on pilot data, we estimate that 92% of girls will progress to secondary school in the control group, 11% of girls will be married before age 14 in the control group, and 32% of girls in the control group will report wage-earning activities in the past 7 days. ',\n",
       " 'The sample was powered to detect 20% changes in diarrhea incidence.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Assuming there are eight households using unsafe wells in each of 42 villages and a 30% switching rate with the standard binary-only message. A 15 percentage point increase in switching due to the emphasis message could then be detected with probability 0.62 if the intra-village correlation is 0.10, and 0.72 with correlation equal to 0.05.',\n",
       " '',\n",
       " 'Minimum detectable effect size is minimum difference in Student-Family treatment effects that we can detect given our sample size, number of clusters, a power of 0.8 and the intra-cluster correlation in the specific outcome variable at baseline. The sample allows us to obtain a power of 80%, with a significance level of 5%, a minimum detectable effect size of 0.2 standard deviation, intracluster correlation of 0.27, cluster size of 30 and an R2 of 0.26-0.29.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The main comparisons in this experiment are based on investor 2’s whose associated investor 1’s accept the offer. Therefore, investor 1’s take-up rate could not be too low because in this case there would be few investor 2’s in this condition. Also, this take-up rate could not be too high because in this case it would not be possible to detect effects (since average take-up rate cannot be greater than 1). The brokerage firm allowed us to have 150 pairs of investors in our sample. We piloted the offer to expect an average take-up rate of 50% for investor 1’s, so we expected to have 25 investor 2’s in each treatment arm. With this sample size, we expected to have approximately 70% power for tests with significance level of 10% to find effects of at least 30 percentage points in comparisons between either treatment conditions (B or C) and the control group (condition A).',\n",
       " 'Sample size was designed to detect an effect of 0.33 of a standard deviation of a Bayley scale on infant development for either the stimulation only group or the micronutrient supplementation only, against the control group. Similar interventions attained this effect size in efficacy studies in Bangladesh. This sample provided 80% power and 5% significance level, allowing for an attrition rate of 10% with 24 villages per intervention and assuming an intracluster correlation of 0.09 in the outcome. This level of intracluster correlation had been estimated from a sample of rural Mexican children who were part of the evaluation of a conditional cash transfer program. It turned out to be conservative as we had an intracluster correlation of 0.04, conditional on observables, in our baseline sample.',\n",
       " 'A1. Experimental Setup\\t\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t\\t\\t\\t\\r\\n\\tExperiment\\tTreated\\tControl\\tN\\tP\\tRemarks\\r\\n\\t#1\\t1000\\t1000\\t2000\\t 1/2\\t All schools (electricity vs. no electricity)\\r\\n\\t#2\\t45\\t44\\t89\\t 1/2\\t Both vs. Learning Materials Only\\r\\n\\t#3\\t42\\t41\\t83\\t 1/2\\t Scholarship Only vs. Controls\\r\\n\\r\\nMDEs:\\t\\t\\tExperiments\\t\\t\\t\\r\\n\\t\\t\\t#1\\t#2\\t#3\\tσ\\r\\n\\t\\tN\\t1000\\t89\\t83\\t-\\r\\n\\t\\tP\\t 1/2\\t 1/2\\t 1/2\\t-\\r\\n\\t\\tθ_{MDE}\\t0.177\\t0.2077727\\t0.215153566\\t1\\r\\n\\tall school sizes\\tGPA_{raw}\\t0.106\\t0.124569146\\t0.128994309\\t0.600\\r\\n\\t\\tGPA_{wgt}\\t0.112\\t0.1308695\\t0.135518475\\t0.630\\r\\n\\t\\tPass%_{raw}\\t0.036\\t0.042066721\\t0.043561088\\t0.202\\r\\n\\t\\tPass%_{wgt}\\t0.034\\t0.040043742\\t0.041466246\\t0.193\\r\\n\\t\\tRank_{raw}\\t225\\t264.3566863\\t273.7476274\\t1272\\r\\n\\t\\tRank_{wgt}\\t224\\t262.9951518\\t272.3377261\\t1266\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We did a Power Calcualtion in Stata indicating that we needed 300 participants to get significant results with a power of 80 %. We used \"Slider Task\" Gill and Prowse (2012, American Economic Review) and used a standard deviation 5,4 (from the paper) and a difference in mean between the controll and the treatment group on two sliders.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The approximate MDE is e^(.143*2.8) - 1 = 49% increase in zip code level counts.  We find a 31% increase.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We are powered to detect treatment effects on marginal returns to a grant on par with De Mel, McKenzie, Woodruff (2008). ',\n",
       " '',\n",
       " 'Please See Analysis Plan',\n",
       " '',\n",
       " '',\n",
       " 'The minimum detectable effect size is 0.25 standard deviation improvement in primary child outcomes described above (Sample size calculations for a multi-site, cluster-randomized trial showed that the detectable difference between any two study arms for a standardized child assessment with an intra-cluster correlation of 0.1 would be approximately 0.25 standard deviations with 95% confidence and 80% power if we sampled 12 children per CBCC with 50 CBCCs allocated to each arm).',\n",
       " '',\n",
       " '',\n",
       " 'p value &lt;0.05 taken as significant',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'For the full primary analysis sample:\\r\\n\\r\\nWJLWI: 0.17 SD\\r\\nWJWA: 0.18 SD\\r\\nTOWRE: 0.18 SD\\r\\nWJPC: 0.17 SD',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'for feasibility study we end up with 14 recruitment for 12 months intervention with 5 time points of measurement; for Phase II clinical trial, we will recruit 40 per each arm; with effect size d=0.8 for balance, two tailed test, power .8 for t-test would require 26 subjects for each group. considering the dropouts, we are aiming 40 for each group.',\n",
       " '',\n",
       " '',\n",
       " 'Accounting for sample design and clustering, the minimum detectable effect size (in standard deviations) for main outcomes is 0.70.\\r\\n•\\tNumber of randomized groups (J): 200\\r\\n•\\tProportion treated: 0.67\\r\\n•\\tNumber of individuals per randomized group (n): 20\\r\\n•\\tIntra-cluster correlation: 0.13\\r\\n',\n",
       " '',\n",
       " '',\n",
       " 'See section 6.7 in PAP.',\n",
       " '',\n",
       " 'See Pre-analysis plan',\n",
       " '',\n",
       " 'Included in grant applications:\\r\\n\\r\\nSince these firms are all operating in the same sector, selling similar products at the same scale, they will be more homogeneous than firms in many standard PSD interventions. This should improve the power of our experiment to detect impacts. Moreover, we believe that unit costs and travel time should be highly correlated over time, and will use multiple weeks of data to further improve power. The baseline data is required to fine-tune these power calculations, as we stand ready to adjust the design as needed if we find that based on the baseline data and initial take-up results that power is lower than anticipated. That said, here are some initial power calculations based on two outcomes that we have used to help guide our preliminary choices on sample size.\\r\\nWe assume take-up of the intervention will be 65% among those who express interest–this is conservative, given Agruppa have found approximately 80% take it up in their initial pilots. Our design at present is then random assignment at the market block level of 30 blocks to treatment and 30 to control, with each block containing 20 firms interested in the intervention, for a total of 600 treated and 600 control firms among the interested (we also have uninterested firms in each block).\\r\\nOur starting point assumptions are that i) key outcomes are likely to be highly autocorrelated (firms that have long travel times today will have long travel times in a month due to geography, mode of transport, etc.); ii) key outcomes will have strong intra-cluster correlations in the cross-section within market blocks (e.g. firms that are all within the same block will charge similar prices and have similar travel times to market); and iii) the intra-cluster correlations will be much weaker in terms of changes (firms within blocks experience different shocks and react differently to the intervention).\\r\\nTo see this, consider the time in hours per week spent to travel to market. In the cross-section at time t, we model this for firm i in block b as:\\r\\n\\r\\nOutcome 1: Reduction in travel time spent by firms to buy goods from the central market\\r\\nAssumptions: Mean weekly travel time of 15 hours (estimated by Agruppa), standard deviation 5 hours, intra-cluster correlation of 0.6 (since firms within markets will have similar travel times). The intervention aims to reduce hours by an average of 5. The ITT is thus 3.25 hours (5*0.65).\\r\\nPower using just a single round of follow-up data:\\r\\nIf randomization was at the individual level, power is 1:\\r\\nsampsi 15 11.75, sd(5) n1(600) n2(600) gives power of 1\\r\\nand we would need only 38 firms in each group to get 80% power\\r\\nsampsi 15 11.75, sd(5) power(0.8)\\r\\nBut with an intra-cluster correlation of 0.6, and 20 firms per market, we need a minimum of 48 blocks (and hence 472 in each treatment group) to achieve 80 percent power.\\r\\nPower using the baseline to improve power:\\r\\nWe assume now that using the baseline hours we have an autocorrelation of 0.7 with follow-up hours, so the residual variance becomes sqrt(1-0.72)*5 = 3.57 hours. We assume that this then reduces the intra-cluster correlation in hours to 0.3 (once the blockb component has been removed). Then we have:\\r\\nsampsi 15 11.75, sd(3.75) power(0.8)\\r\\nsampclus, obsclus(20) rho(.3)\\r\\nGives a minimum of 15 blocks, and 141 treated and 141 control in total needed.\\r\\n',\n",
       " '',\n",
       " '0.5 SD',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Assuming a total traffic of N=6000 (unique) clicks in the recruitment webpage, and a baseline (control) application rate of 6%, we are able to detect a MDE of 0.08 standard deviation.\\r\\nAssuming a baseline (control) show-up ratio to the examination sessions of 40% (of those registered), we are able to detect MDE of approximately 0.25 standard deviation.\\r\\nFor the various test scores, we are able to detect MDE of between 0.30 and 0.35 standard deviation.\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'With an enrollment of about 1,200 HIV-negative individuals at baseline of whom 84 percent participated in all three rounds of sexual diary surveys, the study would have been able to detect: with a probability of more than 90 percent (with a= 0.1), a 15 percent increase in having any vaginal sex during the nine days prior to each of the sexual diaries in response to receiving any incentive, a 15 percent increase in having safe sex—that is, it is equal to one if the respondent had sex with a condom or had no sex at all—during these periods, or a 15 percent decline in the number of days with vaginal sex during these periods. The sample size would have allowed us to detect with a probability of more than 75 percent a 25 percent increase in the probability of using condoms (conditional on having sex) or having condoms at home in response to receiving any incentives; with more than 80 percent probability, the study would have detected a 40 percent reduction in the probability of a woman being pregnant.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Based on the sample sizes above, we are confident we can detect relatively modest changes in the variables above. We are able to detect a 0.13 standard deviation change in outcomes – generally considered a small change – for the overall test of the impact of access to WorkShop’s services. For the group receiving capital access or capital access and marketing, we can detect small to moderate changes in outcomes relative to the control group (0.17 and 0.22 standard deviations respectively). When comparing the treatment arms we can detect moderate effect sizes. Lack of uptake could impact the detectable effect sizes, but we expect high uptake of training and capital access given very high interest in receiving these services among our target population. Depending on market demand, we may not be able to create large opportunities for marketing services. There is a risk that we will fail to detect effects for this specific group but are a) confident in our ability to detect overall effects of WorkShop access and b) believe it is worth trying to measure the impact of marketing services.',\n",
       " '',\n",
       " 'Minimum detectable effect size is 0.17 standard deviations\\r\\nThe natural units will be values on survey questions, or variables constructed from survey questions, such as response time to complete factual questions or concordance of preferences implied by rank-ordering with stated preferences from baseline survey.\\r\\n\\r\\nIf our analysis plan used the standard frequentist framework for hypothesis testing, a study design seeking to compare this many factor combinations would be faced with a serious lack of statistical power—a lack arising from the small number of respondents in each individual treatment arm. This issue would also be compounded by a multiple comparisons problem: the number of tested contrasts would be likely to produce a substantial number of false positives even if there were no true effects. The most commonly used corrections for multiple comparisons—such as the Benjamini-Hochberg method—would substantially increase the study’s sample size and costs. Instead, our approach will address the multiple comparisons issue by adopting a hierarchical Bayesian approach for analyzing the data. The key difference between a Bayesian analysis and a classical analysis is that while the latter creates a long list of contrasts, tests each one separately, and adjusts for multiple comparisons ad hoc, the former estimates all the treatment effects at the same time without requiring them to be independent. In so doing, the statistical precision attained in estimating groups of factor combinations can be “shared” with individual treatment arms that have a common factor.  This turns out to be far more efficient than a classical design, enabling us to test 72 factor combinations with a sample that would otherwise have sufficient power to measure just 16 factor combinations.\\r\\n',\n",
       " '',\n",
       " 'Taking into account correlation of the end point within a village and clustering of the treatment at that level (a intracluster correlation of 0.25 was assumed based on a preliminary survey) and given a baseline immunization rate of 2% in the control group, a sample of 30 villages per treatment arm, with a random sample of 30 households per village (assuming about 1.4 children aged 1-3 years surveyed in each household), was sufficient to obtain 80% power for a 5% level test of a difference of at least five percentage points in the probability of being fully immunised between any two groups (treatment A, treatment B, and comparison).',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'It was estimated that the Minimum Detectible Effect for a sample size of 1,000 (with a quarter for each of the four treatment arms) would be a 0.12 standard deviation change in a standardized dependent variable for a two-tail hypothesis test with statistical significance of 0.05, statistical power of 0.80, an intra-cluster correlation of 0.25, and the proportion of individual variance explained by covariates as 0.10.',\n",
       " 'For measures at the pair level in the trust game, such as the amount sent, we will have 240-300 independent observations to compare the effect of being paired with someone of the same/a different identity (either ethnic or religious affiliation). Based on data from the pilot, with a standard deviation of 12.5 units we will be able to detect a delta in-between 4.05-4.50 with alpha 0.05 and power 0.80.\\r\\nFor measures at the group level in the public goods games such as the contribution, we will have 150 independent observations divided on homogeneous/heterogeneous group composition. Based on data from the pilot, with a standard deviation of 3.6 units we will be able to detect a delta of 1.65 with alpha 0.05 and power 0.80.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'N/A',\n",
       " 'Our power depends on several variables besides effect size. These variables are: the proportion of total variation that is constant within individual (i.e. would be absorbed by a fixed effect), the rate at which drivers complete trips, and whether we use individual fixed effects or instead do pooled OLS. All of these calculations ignore the role of covariates.\\r\\nIn terms of our main outcomes, the standard deviations are:\\r\\n1)\\tReceipt rate: 30 percentage points\\r\\n2)\\tAmount paid at toll: 828 FC (41% of the value of the toll) \\r\\nUnder an assumption that 30% of the variation is constant within individual and an assumption that 65% of drivers complete trips (based on piloting), we simulated our outcomes. In the simulations, our power to detect effects is approximately the following (these are not exact due to the fact that we used simulations, not standard power calculations, because we are not aware of standard calculations that incorporate our design elements):\\r\\n3)\\tLinear effect of 0.05 standard deviations per 25% of the value of the toll cash rebate: \\r\\na.\\tPooled OLS (1), FE (1)\\r\\n4)\\tSpecific dummies for each rebate:\\r\\na.\\t50% of toll: 0.16 standard deviations (OLS); 0.3 standard deviations (FE)\\r\\nb.\\t100% of toll: 0.16 standard deviations (OLS); 0.3 standard deviations (FE)\\r\\n5)\\tCharity: pooled OLS of 0.17 standard deviations, FE of 0.22 standard deviations\\r\\n6)\\tGovernment: pooled OLS of 0.17 standard deviations, FE of 0.22 standard deviations\\r\\n7)\\tWall of pride: pooled OLS of 0.12 standard deviations, FE of 0.17 standard deviations\\r\\n8)\\tSocial norms treatment: pooled OLS of 0.13 standard deviations; cannot be evaluated using FE regressions\\r\\nWe believe that these effects are plausible, since even 1/3 of the standard deviation of receipts received is only 10 percentage points and the incentives are large. We found similar sized effects to those we are powered to detect here in pilot activities.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We used power calculations to determine the sample size, both in terms of the number of His and the number of children in HI, that we would require to be able to detect moderate positive effects of the two programmes on key outcomes, if they were indeed present, with a probability of 80%. For this purpose we considered effects of the programmes on height for age and cognitive development and we defined moderate positive effects as 20% of one standard deviation for HIM as compared to HI and 20% of one standard deviation for HIM+FE as compared to HIM. Because all of the children in our sample are treated by one modality or the other, i.e. they received some sort of early childhood education, the scope for improvement is lower than if we had an untreated control group. \\r\\nFor the power calculations we assumed a moderate intra-cluster correlation co-efficient which was similar to what we observed in the baseline data for cognitive development (0.035 – as measured by ASQ).\\r\\nGiven our assumptions, we calculated that we would require 15 children per cluster (HI) to achieve 80% power at 5% significance level. To allow for attrition between baseline and follow-up data collection (of about 10%), we assessed 17 (whenever there were enough) children per cluster. This led to a target sample size for baseline of 2,000 in 120 clusters (since some His only had 15 or 16 children in the target age range).\\r\\n',\n",
       " 'For our main test of interest, i.e. comparing the behavior of people in the positive and negative demand condition we have a power of .8 to detect standardized effect sizes of .105 at alpha= 0.05. To test for heterogeneous treatment effects by incentives and gender we have a power of .8 to detect effect sizes of .145 at alpha= 0.05 respectively. Finally, to test for heterogeneous responses to demand for the three different games, we can detect effect sizes of .18 with power .8 at alpha= 0.05.\\r\\n',\n",
       " '',\n",
       " 'Not applicable.  Our plan is to estimate willingness-to-pay magnitudes for non-wage work attributes. ',\n",
       " 'See analysis plan. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'With 120 villages, 80 households enrolled in each village, and 30% of children having a case of diarrhea in the past month (UDHS 2011), we expect to have a final sample of 2880 cases of diarrhea (720 per group). Assuming an intra-class correlation (ICC) of .05, we will be able to detect a minimum of an 11-percentage point increase in ORS use between each group.',\n",
       " '9.94 percent.',\n",
       " '',\n",
       " '',\n",
       " 'In Madhya Pradesh, the four treatment categories were randomly assigned across 50 districts, excluding a pilot district, in approximately equal proportions, while across 23 districts in Jharkhand we assigned approximately twice as many districts to the District+Block PayDash and control arms than to the District and Block PayDash arms. This sample size powers us to detect a minimum effect size of 0.187 standard deviations (SD) for comparisons of control to Block+District PayDash (translating into delay decreases of 1.97 days or more in the steps of the payment process under officer purview), of 0.205 SD for comparisons of either control or Block+District PayDash to either Block or District PayDash, and of 0.217 SD for comparisons of Block and District PayDash.',\n",
       " 'Each participant in the treatment group of 172 individuals will receive legal aid from paralegals 2 days valued at 600 Ksh/day*2 days=1,200 Ksh, and from the volunteer advocate 52 days/172 particpants= 0.3 days at 6200 Ksh/day, hence 1,875 Ksh. This corresponds to an overall aid of 3,075 Ksh. Baseline data indicates that yearly household expenses are 78048 Ksh (approximately 1 CAD/capita/day). We are thus interested in detecting an increase of at least 3,075 Ksh on household expenditure, otherwise the benefits, despite being statistically significant, would be less than the costs of the intervention. Statistical power calculations indicate that this sample size is enough to detect such an increase in household expenditures.',\n",
       " 'We do power calculations for two key outcomes that we expect to change as the result of receiving a job offer in the UAE, income and happiness. Happiness is measured from 1 to 10 with 10 being the happiest. So far in our baseline, happiness has a mean of 5.5 and standard deviation of 2. With a power of 0.8 and 95 percent confidence, a sample of 2800 observations will allow us to detect a change in happiness measure of 0.237, or one-tenth of a standard deviation. Income has a mean of 114,051 rupees (or USD 1721) and standard deviation of 79,876. We can detect a change in income of 9365 Rupees (or 8 percent). \\r\\n\\r\\nOne potential threat to the power of our analysis is compliance in the control group in particular. While individuals in the control group do not receive an offer to go to the UAE in the context of our study, they may find other job opportunities with other firms in the UAE or in other developed countries. Unfortunately, we do not have good estimates of the arrival rate for international jobs for this population, but our field work suggests that it is unlikely that they can expect to find another international job placement immediately. Thus, we believe it is important to do a mid-line survey after 6 months; this relatively short-term follow-up maximizes the probability that members in the control group have not yet found another position in a developed country. At the same time, some of these outcomes, such as the negative psychological effects of separation from one’s family may take a longer time, so we want to do a follow-up again at 2 years.  \\r\\n\\r\\n \\r\\n\\r\\n',\n",
       " 'For the jute intervention, we compute the minimum detectable effect for discrete variables generally as a function of the baseline adoption rate.  For smaller initial rates, the minimum detectable effect is smaller in terms of percentage points; for example, if there is 10 percent adoption, an 11 percentage point difference is detectable.  If the initial adoption rate is higher, a larger percentage point difference is needed to identify outcomes, but the percent change need not be as large.\\r\\n\\r\\nFor jute yields, we can identify a 13 percent difference from the control group in any specific arm of the intervention.  Among raffle winners, the difference is 23 percent; among 3rd place winners, 16 percent.  We are more likely to be able to detect the impacts of winning the raffle or coming in 2nd place because they are more likely to redeem coupons.\\r\\n\\r\\nIn general, for a continuous variable the MDE is 0.31 standard deviations.\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'MDEs for treatment effects among females calculated assuming 80 percent power, 5 percent significance. Based on our sample sizes, we will be able to detect a minimum of a 5.3 percentage point decrease in the probability of ever having been pregnant (sd=0.306), a 9.1 percentage point decrease in the probability of ever having had sex (sd=0.476), and an 11.2 percentage point increase in the likelihood of using a condom, conditional on having sex (sd=0.482).',\n",
       " '',\n",
       " '',\n",
       " '0.42 of a standard deviation of home work hours.\\r\\n0.17 of a standard deviation of laundry washing hours.',\n",
       " '',\n",
       " 'Our interventions are expected to reduce knowledge gaps, which in turn increase the adoption of sustainable crop intensification methods such as fertilizer and pesticides among rice farmers. We therefore look at the different in mean yields between farmers that use a particular method and those that do not to get an idea about what effect size to expect. To do so, we restrict ourselves to farm households that reported growing rice in the second season of 2013.\\r\\n\\r\\nWe find that average yields are about 2.11 MT/ha for farmers that report not useing fertilizers. Farmers that use fertilizer report yields of about 3MT/ha, which is an increase of about 42 percent. The pooled standard deviation is about 1.29 MT/ha. We would need about 26 observations in each treatment arm (single sided, 80 percent power and alpha level of 0.05). For pesticide use, we find that farmers that do not report using pesticed get yields of around 2.16 MT/ha, while those that do use get about 2.84, corresponding to an increase of about 31 percent. We would need about 45 observations in each treatment arm to detect such an effect. For recommended practices, we find that farmers that maintain water depth of 10-25 cm during cultivation to effectively control weeds have 41 percent higher yields, and we would need about 40 obseravations to identify such an effect with 80 percent power. Finally, farmers that plant in rows have average yields of about 2.71MT/ha, while those who do not plant in rows attain about 2.17MT/ha. To find this effect, we would need about 68 observations in each treatment arm to detect this effect.\\r\\n\\r\\nThe above are the effects of implementing a particular technology. However, our information treatment is unlikely to encourage all farmers to start using improved inputs or technologies. Therefore, we expect effects to be smaller and settle on a 20 % average increase in yields. To identify such an effect, we need about 110 observations in each treatment arm. ',\n",
       " '',\n",
       " 'See the analysis plan, as well as further information at jonathanweigel.com',\n",
       " '',\n",
       " 'In our first power calculations (before drawing the actual sample) the minimal detectable size for detecting a difference in hiring rates was as follows:\\r\\nLarge firms: sample of 1400 per group, 90% power (effect 10%) and 60% power (effect 5%) \\r\\nSmaller firms: sample of 8000 per group, 42% power (effect 10%) (we do notice that power is too low, but for policy relevance we run this separate experiment for smaller firms)\\r\\n\\r\\nAfter drawing the actual sample, the numbers changed a bit.\\r\\nLarge firms: 2.500 \\r\\nSmaller firms: 7.600 \\r\\nPower 90% (effect 10%) and power 60% (effect 5%) \\r\\nSmaller firms: 40% power (effect 10%) \\r\\nFor small firms power might not be enough, only for large effects or combination of letters. Because of their policy relevance, we did not drop smaller firms from the sample, but instead run a separate experiment on them. ',\n",
       " '',\n",
       " '',\n",
       " 'When we compare the mean support in municipalities in receipt of the information treatment\\r\\nrelative to municipalities not receiving any letters we have power of .8 to detect effect sizes of .21 of a standard deviation at \\x0b=0.05. In our preferred specification including strata fixed\\r\\neffects, Canton fixed effects, as well as additional controls, we will have a power of .8 to detect\\r\\neffect sizes of about .18 of a standard deviation at \\x0b=0.05.\\r\\nWhen we compare the mean support in municipalities in receipt of the information treatment\\r\\nrelative to municipalities which receive the placebo letters, we have power of .8 to detect effect\\r\\nsizes of .22 of a standard deviation at \\x0b=0.05. In our preferred specification including strata\\r\\nfixed effects, Canton fixed effects, as well as additional controls, we will have a power of .8 to\\r\\ndetect effect sizes of .19 of a standard deviation at \\x0b=0.05.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'A sample size of 360 start-ups (given by four cohorts in two years) and 180 start-ups in each arm of the trial is enough to detect a minimum effect size of 0.33 (Cohen’s D) of our outcome variables. This is assuming an R2 0f 0.06 from our previous study (González-Uribe &amp; Leatherbee 2016)  a level of significance of 0.05 and a power of 0.80 on a two-tailed test.',\n",
       " 'Most reasonable power calculations imply that experiment is reasonably-powered to detect a 0.5 standard deviation effect size on main outcomes, on conservative assumptions (i.e., power 0.9). While having two rounds of midline/endline data is helpful, given the high autocorrelation in farming outcomes there is a limit on how much this adds.',\n",
       " '',\n",
       " 'see preanalysis plan.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We conduct power calculations using parameters estimated from the 2011/12 Uganda National Panel Survey (UNPS) data. The ACDP study sample will be a more homogeneous population than the entire Ugandan population, from which the UNPS sample is drawn, as it is restricted by: (1) region and crop, including only maize farmers in eastern Uganda, bean farmers in western Uganda, rice farmers in northern Uganda, and coffee farmers in central Uganda; (2) farmer characteristics, determined by the specific eligibility rules established by ACDP. To approximate the more homogeneous ACDP target population using the UNPS data, we estimate parameters using data from a restricted sample of households farming between 3 and 5 acres, a criterion for ACDP eligibility.  Even the restricted UNPS sample is more heterogeneous than what the ACDP sample will be, and we are therefore confident that our power calculations are conservative. \\r\\n\\r\\nOur power calculations take maize yields as the outcome variable. While outcome variables other than yields are of interest, yields typically exhibit higher coefficients of variation than do outcome measures of input use and other farming practices to be studied in the evaluation. We are thus confident that designing a sample with adequate power for maize yields will give us sufficient power to look at other key indicators and crops as well. We report calculations for two cases in which we assume mean yields of 345 kg/ac, the mean maize yields for farmers in eastern Uganda cultivating 3-5 acres of land in the second season of the 2011/12.  The remaining parameters for the two cases are:\\r\\n(1)\\tExpected parameter case - The standard deviation of yields is assumed to be 300 kg/ac, which is based on the coefficient of variation for bean yields of farmers in western Uganda, and the parish-level intra-cluster correlation is assumed to be 12%, which is just below the village-level intra-cluster correlation for bean yields of farmers in western Uganda (14%);\\r\\n(2) Conservative parameter case - The standard deviation of yields is assumed to be 388 kg/ac, which is based on the coefficient of variation for maize yields of farmers in eastern Uganda, and the parish-level intra-cluster correlation is assumed to be 18%, which was the village-level intra-cluster correlation for maize yields of farmers in eastern Uganda.\\r\\n\\r\\nBased on our power analysis (summarized below), we propose to select our study sample from 5 sub-counties across the four study districts.  In 2 sub-counties, we will randomly select 24 farmer groups (8 with high initial subsidy, 8 with low initial subsidy, and 8 with no subsidy).  In 1 sub-county, we will randomly select 12 farmer groups (4 with high initial subsidy, 4 with low initial subsidy, and 4 with no subsidy).  In 1 sub-county, we will randomly select 32 farmer groups (10 with high initial subsidy, 10 with low initial subsidy, and 12 with no subsidy). In the final sub-county, we will randomly select 27 farmer groups (9 with high initial subsidy, 8 with low initial subsidy, and 10 with no subsidy), yielding 136 clusters overall for our sample.    \\r\\n\\r\\nWe will then randomly select 20 households per farmer organization cluster from among ACDP-eligible households, yielding a total sample size of 2160 households for our main sample of directly treated farmers. \\r\\n\\r\\nOur minimum detectable effect calculations assume a net uptake rate of 75%. At the expected voucher uptake rate of 75%, the proposed design is powered to detect effects of less than half that magnitude (19%); even under our case of conservative assumptions, the study design could detect a minimum effect of 32%.  As long as net uptake of the e-voucher is no lower than 50%, the proposed study design will have adequate power to detect program impacts if ACDP achieves its 50% yield growth goal.  While this yield growth goal is high, it appears achievable in Uganda based on government estimates as well as estimates from experimental trials and on-farm trials of farm inputs in Uganda. We are thus confident that we have adequate power to pick up expected yield changes, as well as changes in the other, less variable, outcome indicators of interest. Moreover, we expect the actual power of the study to be higher than what is estimated here, because we will collect multiple (seasonal) rounds of follow-up data and will ensure high levels of data quality through carefully programmed electronic survey instruments.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Participation MDE: \\r\\n\\r\\n- 5.7 percentage points (baseline 50% participation) when comparing groups B + C to group A\\r\\n- 6.6 percentage points if we are separately comparing group B to group A, and group C to group A.\\r\\n\\r\\nSelection Regression MDE: approximately 3.8 percentage points, for an attribute that is held by 40% of the population.\\r\\n\\r\\nShort-Run Effects Regression MDE: \\r\\n\\r\\n- 0.61 for BMI (mean = 26.3%, SD = 3.9%)\\r\\n- 1.21 for Systolic blood pressure (mean = 120, SD = 7.5)\\r\\n- 0.97 for diastolic blood pressure (mean 80, SD = 6)\\r\\n- 0.23 for absenteeism (mean = 4, SD = 2)',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'MDEs for Math standardized test scores:\\r\\n- 0.106 for awareness vs. control \\r\\n- 0.106 for awareness vs. information\\r\\n- 0.150 for absolute vs. relative information\\r\\n- 0.143 for spillovers on the control group\\r\\n- 0.159 for spillovers on the awareness treatment\\r\\n\\r\\nMDEs for Portuguese standardized test scores:\\r\\n- 0.105 for awareness vs. control \\r\\n- 0.105 for awareness vs. information\\r\\n- 0.148 for absolute vs. relative information\\r\\n- 0.134 for spillovers on the control group\\r\\n- 0.149 for spillovers on the awareness treatment',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'See Analysis Plan',\n",
       " '',\n",
       " '(1) Weight-for-height Z scores: using an intracluster correlation coefficient (ICC) of 0.1 (Fenn, Morris, et al., [2004]), we have 90% power to detect a 0.225 SD change in Z scores (80% power to detect a 0.19 SD change).\\r\\n(2) Under 5 (U5) mortality: Using an ICC of 0.0175 (Mann, Veble et al., [2010]), we have 90% power to detect and 0.45 SD change in U5 mortality (80% power to detect a 0.3 SD change)\\r\\n(3) Childhood diarrhea incidence: Using an ICC of 0.03 (***CITE***) , we have 90% power to detect a 0.06 SD change in incidence of diarrhea (80% power to detect a 0.05 SD change)',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Based on pilot study: 40 observations per group to obtain statistically signi\\x0cficant differences in number of features completed on the task between the groups at the 5% level with a power of 80%.',\n",
       " 'The pregnancy rate of RIF patients in oocyte donation program in our clinic has been rather low (&lt;20%) as compared with good prognosis patients (&gt;75%). Assuming that there is a 50% increase in pregnancy rate with GH administration (i.e. an increase from 20% to 30%), 31 subjects are required in each group to give a test of significance on 0.05, power of 90%, and standard deviation (SD) of 0.6.',\n",
       " 'Our minimum detectable effect (with 80% power and 5% significance) for instructor incentives over the course of the study is 0.17 standard deviations in test scores. \\r\\n\\r\\nOur minimum detectable effect for combined incentives is 0.2 standard deviations. \\r\\n\\r\\nOur minimum detectable effect for differences in incentives is 0.125 standard deviations, since this is a more powerful, within-subject test.',\n",
       " 'Given the panel structure, the study will allow detectable effect size of approximately 0.2 of one standard deviation.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Given the panel structure, the study will allow detectable effect size of approximately 0.2 of one standard deviation.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We use data from the Household Recode of the Demographic Health Survey (DHS) 2005-2006, which includes information on treatment practices for drinking water by the household. We limit our sample to urban households in the State of Andhra Pradesh which provides us with a total of 4102 households. Evidence from this data indicates that less than 50% of households treat their drinking water, and of those that do, usage of chlorine is approximately 0.6%. The reason for such low usage is unclear and could be influenced by factors such as price, availability and awareness. Therefore, we assume that if provided with some awareness of the product and the option of buying it at their door-step, take-up amongt the members of Safa (i.e. study population) could stand between 5-40% (10 to 80 individuals out of 200 population respectively). In fact, a population of 200 individuals, with a statistical power of 80%, will allow us to detect a minimum adoption rate of 4% which correspond to only 6 people. Similarly, a population of 200 individuals, with a statistical power of 90%, will allow us to detect a minimum adoption rate of 5% which correspond to only 10 people.   \\r\\n',\n",
       " 'bootstrapped power calculations available from the authors on request.',\n",
       " '',\n",
       " '.24 Standar Desviation',\n",
       " 'Using estimates from previous studies, it was calculated that 30 schools (15 per trial arm) and 55 students per school for each inter-arm comparison was required to detect a standardised effect size of 0.4 for haemoglobin concentration with 80% power at the 5% significance level.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'India:  Based on a target sample size of 2600 girls (110 clusters of 20 girls each (for a sample of 2400, assuming ~10% refusal rate) we estimate a minimum detectable effect size of 10% up for the outcome of proportion females 15-19 married at endline. \\r\\nData from the 2005/6 Demographic and Health Surveys were used to obtain estimates of the proportion of females 15-19 currently married or in union in the proposed intervention states (Rajasthan, Orissa, Jharkhand and Bihar). Using the proportion of females 15-19 currently married or in union in Orissa (22.7%) as the lower plausible value and the proportion currently married or in union in Bihar as the upper plausible value (45.0%) we estimate that we will have 76% power at 10 clusters per site \\r\\n\\r\\nMalawi: Based on a target sample size of 1000 girls (45 clusters of 20 girls each (for a sample of 900, assuming ~10% refusal rate) we estimate a minimum detectable effect size of 15% up for the outcome of proportion females 12-19 married at endline. \\r\\nData from the 2008 Malawi Census provide estimates of upper and lower plausible values for early marriage in Malawi.  From the Census we find that the proportion of females 12-19 currently married or in union varies from about 5% to 30%. Using these values and assuming a total of 20 girls per GHV will be interviewed, we should have 80% power at 45 clusters (45 GHVs). \\r\\n\\r\\nMali:  Based on a target sample size of 800 girls (40 clusters of 20 girls each) we estimate a minimum detectable effect size of 15% up for the outcome of proportion females 12-19 married at endline.  \\r\\nData from the 2012/3 DHS provide estimates of upper and lower plausible values for early marriage in Mali.  From DHS data we find that the proportion of females 15-19 currently married or in union varies from about 39% to 56%.  Although the numbers for 12-19 will skew lower, we use these values and assume a total of 20 girls per village (EA) will be interviewed. We estimate with n=20 per village/EA we should have &gt;80% power at 40 clusters (villages/EAs). \\r\\n\\r\\nNiger:  Based on a target sample size of 600 girls (30 clusters of 20 girls each) we estimate a minimum detectable effect size of 15% up for the outcome of proportion females 12-19 married at endline.  \\r\\nData from the 2012 DHS provide estimates of upper and lower plausible values for early marriage in Niger.  From DHS data we find that the proportion of females 15-19 currently married or in union in the regions of interest varies from about 58% to 72%.  Although the numbers for 12-19 will skew lower, we use these values and assume a total of 20 girls per village (EA) will be interviewed. We estimate with n=20 per village/EA we should have &gt;90% power at 30 clusters (villages/EAs). \\r\\n\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '.18',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'n/a',\n",
       " 'Power calculations were conducted before the beginning of the trial using Optimal Design software (Spybrook et al. 2009). Based on our previous study of inaccuracies in teacher grading in rural China, we assume R2=0.4 (the correlation between the baseline covariates and the outcome, squared). \\r\\n\\r\\nWith this assumption and for a 5% significance level (alpha = 0.05) and 80% power (beta = 0.8), the “Randomized Trials” option in the Optimal Design software suggests that we will require at least 560 teachers (split between two treatment arms) to detect an effect size of 0.18 SDs and 280 teachers (split between two treatment arms) to detect an effect size of 0.26 SDs. \\r\\n\\r\\nThe above power calculations do not take into account testing multiple hypotheses (comparisons). In particular, during our exploratory analyses, we will test multiple hypotheses. Thus, for tests of average treatment effects, we will report the standard p-value for each test as well as the p-value adjusted for multiple tests (controlling the False Discovery Rate – see Anderson 2008). Tests of heterogeneous treatment effects and mechanisms will each be treated as independent, exploratory hypotheses (and will not be adjusted for multiple hypothesis testing).\\r\\n',\n",
       " '',\n",
       " 'Using data from 2015 EGRA/EGMA assessments in Liberia, we estimate that the intra-cluster correlation in student’s test scores ranges between 0.1 and 0.2 for different grades and skills (with most estimates between 0.15 and 0.25). For all power calculations we use a conservative estimate of ICC at 0.2. Similarly, we estimate the proportion of the variance that is explained by observable characteristics (age, gender, district, and grade) to be between 20-30% (without including baseline test scores). Thus, for all power calculations we conservatively assume that the R-squared of observable student characteristics is 30%.\\r\\n\\r\\nTherefore, the minimum detectable effect size (MDE) with a power of 90%, at a 5% size, testing 10 students per school (in a total of 185 schools – 92 treated) is 0.22 standard deviations (Duflo, Glennerster &amp; Kremer, 2007). Testing 20 students per school, we have an MDE of 0.2. These MDE are estimated under very conservative assumptions (high power, low size level, and conservative ICC and R2 from observable student/school characteristics).\\r\\n\\r\\nAccording to EGMA data from 2015, students in third grade are able to answer, on average, 33.7% of addition questions correctly. Increasing test scores by 0.2 standard deviations would be equal to increasing the average test score from 33.7% to 37.4%. \\r\\n',\n",
       " '',\n",
       " '',\n",
       " 'See proposal. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"Based on previous season's sales and expected benefits from training: 48 agents in control and treatment to obtain statistically significant differences in premiums collected by insurance agents in treatment and control at the 5% level with a power of 80%.\",\n",
       " 'Based on conservative considerations—a G*Power analysis (Faul et al. 2007)—to reach an effect size of 0.2 for a new innovative intervention (Perlick et al. 2010) when a= 0.05 and b = 0.80, would require 28 patients to detect differences in repeated measures in a within-between interaction.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The online platform expects to recruit around 40 new gig workers per month. Based on power simulations using past gig worker data, we requested that the experiment be left in the field for at least seven months, giving us an expected 280 observations. With 257 observations, our simulated MDE for desired quantity with 77% power is .3 standard deviations.\\r\\n\\r\\nDue to planning constraints, however, the online platform was able to make a commitment for only five months in the field (yielding an expected 200 observations). This reduces power: with 200 observations, our simulated MDE for desired quantity (with 79% power) is .35 standard deviations.\\r\\n',\n",
       " 'Cohen’s d MDES (using 5% significance and 80% power levels, assuming an R-squared explained by co-variates of at least 0.3) is calculated as follows:\\r\\nBroad category (Intent-to-treat: all businesses passing the lottery): 0.23\\r\\nNarrow category (Treatment: all businesses passing the lottery and passing the eligibility check): 0.32',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Power calculations will be done after the baseline survey data been collected. This way we can use the correct standard deviations and intra-cluster correlations.',\n",
       " '',\n",
       " '20-35%',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Power=0.8, alpha=0.05\\r\\nControl vs T1+T2: 7.58953% difference in adoption\\r\\nControl vs T1: 8.75019% difference in adoption\\r\\nControl vs T2: 8.697624% difference in adoption\\r\\nT1 vs T2: 9.679689% difference in adoption',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '.12= MDE (unit is percentage point increase in contraceptive use). SD=.31 ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The pairwise comparisons indicate that the study has sufficient power to detect differences in the probability\\r\\nof smoking of a 5-percentage point magnitude or greater compared to the control arm.3 Using this minimum\\r\\ndetectable effect, the study will have 80% power to detect an intervention-related reduction in smoking rates\\r\\nfor the treatment group with a sample size of 72 schools.\\r\\nWe adopted the following assumptions for the calculations:\\r\\n• Type-I error of \\x0b = 0.05.\\r\\n• A plausible range of values for the probability of smoking in the control arm of 5% to 25%, with a mean\\r\\nexpected value of 10%, based on national survey data and our pilot work\\r\\n• An average of 30 participating students per school (geometric mean)',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The sample size was powered to detect changes in number of meals per day, which we believe is an important measure of economic empowerment and wellbeing. Ksoll et al (2016) find treatment effects on this variable in a similar study of VSLA in Malawi (not targeting disabled). They find that one in seven households consumed an extra meal as a result of the treatment, with an average number of meals per day at baseline of 2.65.\\r\\n\\r\\nIn our baseline data, the average number of meals per day is two, and only 20 percent of the participants reported that they had at least three meals the day before the interview. Thus, our sample seems to be poorer than that in Ksoll et al, and we interpret this as the potential for improvement being greater. With an inter-cluster correlation of 0.05, we have a power of at least 90% (with a 5% confidence interval) to detect a 10-percentage point increase in the share of the participants who had at least three meals per day.\\r\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Not available',\n",
       " 'See attached pre-analysis plan',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"* Please, note: conservative estimates\\r\\n\\r\\nTeachers' outcomes - around 0,156 express in terms of effect size - both treatments considered together vs control\\r\\nTeachers' outcomes - around 0,193 express in terms of effect size - each treatment considered separately vs control\\r\\n\\r\\nStudents' outcomes - around 0,084 express in terms of effect size - both treatments considered together vs control\\r\\nStudents' outcomes - around 0,104 express in terms of effect size - each treatment considered separately vs control\\r\\n\",\n",
       " '',\n",
       " 'Please see the pre-analysis plan. ',\n",
       " '',\n",
       " 'Given an intracluster correlation (for the random effects logit latent model used in power analysis simulations) of 0.1 we will be able to detect a 10 percentage point difference in deworming take-up between any incentive treatment arm and the control group, and a 8 percentage point change between any two incentive treatment arms. We can further detect a 7 percentage point difference in deworming take-up within treatment arms between adults who received and did not receive a text message reminder/information about deworming take-up in their community, and a 9 percentage point change in demand between any two arms for adults that did receive the text messaging treatment. ',\n",
       " 'Power calculations, adjusted for pre-treatment covariates and baseline outcome measures. We will be collecting learners’ opt-in responses before randomisation. Binary outcome measure (pass/fail). With power set to 0.80 and alpha set to 0.05, and N = 250 per arm, observable treatment effect =  5.9%, MDES = .141.',\n",
       " '',\n",
       " 'Please see Appendix A in the WorkAdvance report: http://www.mdrc.org/sites/default/files/2016_Workadvance_Final_Web.pdf',\n",
       " '',\n",
       " '',\n",
       " 'Field studies on gift exchange are extremely disperse in their results. Thus, it is impossible to do power calculations without cherry pick.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Sample size calculations assumed a maximum detectable effect size of program in each intervention arm of .1 relative to control villages. Assumptions of baseline marriage rates were based on proportions of women aged 20-24 who were married by age 15 and 18 in the DHS for the region of Khulna. Sample sizes were adjusted assuming an attrition rate of 20 percent between baseline and endline.',\n",
       " '',\n",
       " 'The main outcome of interest is the interaction between treatment factors. \\r\\nWe calculate the minimum detectable effect size assuming a significance level of 0.05, a power of 0.8, n = 720, using a two-way analysis of variance (ANOVA) excluding the control group, resulting in a 3 x 3 design with 80 observations per group. We do this for the two main effects, as well as for the interaction effect. The resulting effect size eta is the square root of the ratio of the variance explained by the respective factor to the error variance.\\r\\nWe calculate the minimum detectable effect size (MDES) of 0.12 assuming an error variance of 1 for main treatment effects, and a MDES of 0.13 for the interaction effect. Further increases of the number of observations per group do not significantly decrease the MDES, with the minimum being slightly below 0.1 for more than 110 observations per group.\\r\\nNote that our analysis will primarily rely on regression models that better fit the distribution of the likely not normally distributed outcome variable of interest, e.g. a (random-effects) Tobit model to account for left-censoring of contributions. This affects power.\\r\\nWith respect to pairwise comparisons with t-tests (or non-parametric Mann-Whitney-U tests), assuming an error probability of 0.05, a power of 0.8, n = 80 per group, an arbitrarily assumed mean of 20 Credits in the control group, we vary the common standard deviations between 10 and 20. This results in minimum detectable differences if contributions in the treatment group range between 24.46 and 28.91 Credits, i.e. if there is a difference between 4.46 and 8.91 to the control, linearly increasing with increased pooled variance. Notably, detecting effects of treatments that we hypothesize to decrease contributions with respect to another group may be problematic when contributions in the respective control group are low. This is because contributions are censored at zero. For lower treatment contributions to be detectable with standard deviations up to 20, the respective contributions in the control group must not be lower than 9 Credits. However, in that case average treated contributions would need to be zero in order for the difference to be detectable with this design.\\r\\nNote that in case of conducting the experiment as a within-subject design, power increases, ceteris paribus.\\r\\n',\n",
       " 'We initially calculated power based on data from research in similar areas in 2015 and from the Afrobarometer and South African Social Attitudes Survey. We then reran calculations based on the baseline and endline data. For varying attrition levels (5-10%), the MDEs are:\\r\\nControl vs Information Message: 0.1358-0.1618\\r\\nInformation Message vs Treatment 1: 0.1529-0.1821\\r\\nInformation Message vs Treatment 2: 0.1561-0.1604\\r\\nControl vs Treatment 1: 0.1544-0.1851\\r\\nControl vs Treatment 2: 0.1588-0.1891',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'See Attached Analysis Plan',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '.25 standard deviations in Height-for-age Z-score',\n",
       " \"MDE for mayor's election variables: 2 percentage points. More details are available on Pre Analysis Plan.\",\n",
       " '',\n",
       " '',\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['Minimum_Detectable_Effect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31c43db1-8d06-403f-b8bd-65b337fd7e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10056, 39)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ce0d6-d9f7-4545-ac3a-8d21a6abc714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Data Science)",
   "language": "python",
   "name": "py311ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
